[2022-06-20 22:44:59,238 I 128931 128931] (raylet) io_service_pool.cc:35: IOServicePool is running with 1 io_service.
[2022-06-20 22:44:59,238 I 128931 128931] (raylet) store_runner.cc:32: Allowing the Plasma store to use up to 200GB of memory.
[2022-06-20 22:44:59,238 I 128931 128931] (raylet) store_runner.cc:48: Starting object store with directory /dev/shm, fallback /tmp/ray, and huge page support disabled
[2022-06-20 22:44:59,238 I 128931 128962] (raylet) dlmalloc.cc:154: create_and_mmap_buffer(200000012296, /dev/shm/plasmaXXXXXX)
[2022-06-20 22:44:59,238 I 128931 128962] (raylet) store.cc:546: ========== Plasma store: =================
Current usage: 0 / 200 GB
- num bytes created total: 0
0 pending objects of total size 0MB
- objects spillable: 0
- bytes spillable: 0
- objects unsealed: 0
- bytes unsealed: 0
- objects in use: 0
- bytes in use: 0
- objects evictable: 0
- bytes evictable: 0

- objects created by worker: 0
- bytes created by worker: 0
- objects restored: 0
- bytes restored: 0
- objects received: 0
- bytes received: 0
- objects errored: 0
- bytes errored: 0

[2022-06-20 22:44:59,239 I 128931 128931] (raylet) grpc_server.cc:105: ObjectManager server started, listening on port 41035.
[2022-06-20 22:44:59,267 I 128931 128931] (raylet) node_manager.cc:333: Initializing NodeManager with ID 7562cb0081c73f4ed2ac21d1956887bd794b724f1b8c157f4e02d603
[2022-06-20 22:44:59,267 I 128931 128931] (raylet) grpc_server.cc:105: NodeManager server started, listening on port 40043.
[2022-06-20 22:44:59,272 I 128931 128989] (raylet) agent_manager.cc:88: Monitor agent process with pid 128988, register timeout 30000ms.
[2022-06-20 22:44:59,661 I 128931 128931] (raylet) raylet.cc:114: Raylet of id, 7562cb0081c73f4ed2ac21d1956887bd794b724f1b8c157f4e02d603 started. Raylet consists of node_manager and object_manager. node_manager address: 10.140.1.109:40043 object_manager address: 10.140.1.109:41035 hostname: 10.140.1.109
[2022-06-20 22:44:59,663 I 128931 128931] (raylet) node_manager.cc:538: [state-dump] Event stats:
[state-dump] 
[state-dump] 
[state-dump] Global stats: 23 total (10 active)
[state-dump] Queueing time: mean = 1.838 ms, max = 34.140 ms, min = 4.069 us, total = 42.267 ms
[state-dump] Execution time:  mean = 1.592 ms, total = 36.624 ms
[state-dump] Event stats:
[state-dump] 	PeriodicalRunner.RunFnPeriodically - 7 total (1 active, 1 running), CPU time: mean = 204.231 us, total = 1.430 ms
[state-dump] 	ObjectManager.UpdateAvailableMemory - 4 total (0 active), CPU time: mean = 2.518 us, total = 10.071 us
[state-dump] 	RayletWorkerPool.deadline_timer.kill_idle_workers - 2 total (1 active), CPU time: mean = 2.082 us, total = 4.164 us
[state-dump] 	UNKNOWN - 1 total (1 active), CPU time: mean = 0.000 s, total = 0.000 s
[state-dump] 	NodeManager.deadline_timer.flush_free_objects - 1 total (1 active), CPU time: mean = 0.000 s, total = 0.000 s
[state-dump] 	InternalPubSubGcsService.grpc_client.GcsSubscriberPoll - 1 total (1 active), CPU time: mean = 0.000 s, total = 0.000 s
[state-dump] 	NodeManager.deadline_timer.debug_state_dump - 1 total (1 active), CPU time: mean = 0.000 s, total = 0.000 s
[state-dump] 	InternalPubSubGcsService.grpc_client.GcsSubscriberCommandBatch - 1 total (1 active), CPU time: mean = 0.000 s, total = 0.000 s
[state-dump] 	NodeInfoGcsService.grpc_client.RegisterNode - 1 total (0 active), CPU time: mean = 486.057 us, total = 486.057 us
[state-dump] 	HeartbeatInfoGcsService.grpc_client.ReportHeartbeat - 1 total (1 active), CPU time: mean = 0.000 s, total = 0.000 s
[state-dump] 	NodeInfoGcsService.grpc_client.GetInternalConfig - 1 total (0 active), CPU time: mean = 34.694 ms, total = 34.694 ms
[state-dump] 	NodeManager.deadline_timer.record_metrics - 1 total (1 active), CPU time: mean = 0.000 s, total = 0.000 s
[state-dump] 	GcsClient.deadline_timer.check_gcs_connection - 1 total (1 active), CPU time: mean = 0.000 s, total = 0.000 s
[state-dump] 
[state-dump] NodeManager:
[state-dump] Node ID: 7562cb0081c73f4ed2ac21d1956887bd794b724f1b8c157f4e02d603
[state-dump] Node name: 10.140.1.109
[state-dump] InitialConfigResources: {CPU: 1280000, node:10.140.1.109: 10000, GPU: 80000, object_store_memory: 2000000000000000, memory: 8693891676160000, accelerator_type:A100: 10000}
[state-dump] ClusterTaskManager:
[state-dump] ========== Node: 7562cb0081c73f4ed2ac21d1956887bd794b724f1b8c157f4e02d603 =================
[state-dump] Infeasible queue length: 0
[state-dump] Schedule queue length: 0
[state-dump] Dispatch queue length: 0
[state-dump] num_waiting_for_resource: 0
[state-dump] num_waiting_for_plasma_memory: 0
[state-dump] num_waiting_for_remote_node_resources: 0
[state-dump] num_worker_not_started_by_job_config_not_exist: 0
[state-dump] num_worker_not_started_by_registration_timeout: 0
[state-dump] num_worker_not_started_by_process_rate_limit: 0
[state-dump] num_tasks_waiting_for_workers: 0
[state-dump] num_cancelled_tasks: 0
[state-dump] cluster_resource_scheduler state: 
[state-dump] Local id: -110938788179330527 Local resources: {object_store_memory: [2000000000000000]/[2000000000000000], node:10.140.1.109: [10000]/[10000], memory: [8693891676160000]/[8693891676160000], CPU: [1280000]/[1280000], accelerator_type:A100: [10000]/[10000], GPU: [10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000]/[10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000]}node id: -110938788179330527{object_store_memory: 2000000000000000/2000000000000000, node:10.140.1.109: 10000/10000, memory: 8693891676160000/8693891676160000, CPU: 1280000/1280000, accelerator_type:A100: 10000/10000, GPU: 80000/80000}
[state-dump] Waiting tasks size: 0
[state-dump] Number of executing tasks: 0
[state-dump] Number of pinned task arguments: 0
[state-dump] Number of total spilled tasks: 0
[state-dump] Number of spilled waiting tasks: 0
[state-dump] Number of spilled unschedulable tasks: 0
[state-dump] Resource usage {
[state-dump] }
[state-dump] Running tasks by scheduling class:
[state-dump] ==================================================
[state-dump] 
[state-dump] ClusterResources:
[state-dump] LocalObjectManager:
[state-dump] - num pinned objects: 0
[state-dump] - pinned objects size: 0
[state-dump] - num objects pending restore: 0
[state-dump] - num objects pending spill: 0
[state-dump] - num bytes pending spill: 0
[state-dump] - cumulative spill requests: 0
[state-dump] - cumulative restore requests: 0
[state-dump] 
[state-dump] ObjectManager:
[state-dump] - num local objects: 0
[state-dump] - num unfulfilled push requests: 0
[state-dump] - num pull requests: 0
[state-dump] - num chunks received total: 0
[state-dump] - num chunks received failed (all): 0
[state-dump] - num chunks received failed / cancelled: 0
[state-dump] - num chunks received failed / plasma error: 0
[state-dump] Event stats:
[state-dump] Global stats: 0 total (0 active)
[state-dump] Queueing time: mean = -nan s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] Execution time:  mean = -nan s, total = 0.000 s
[state-dump] Event stats:
[state-dump] PushManager:
[state-dump] - num pushes in flight: 0
[state-dump] - num chunks in flight: 0
[state-dump] - num chunks remaining: 0
[state-dump] - max chunks allowed: 409
[state-dump] OwnershipBasedObjectDirectory:
[state-dump] - num listeners: 0
[state-dump] - cumulative location updates: 368
[state-dump] - num location updates per second: 3653599871417102368768.000
[state-dump] - num location lookups per second: 2147483647500.000
[state-dump] - num locations added per second: 104000.000
[state-dump] - num locations removed per second: 47188948103056000.000
[state-dump] BufferPool:
[state-dump] - create buffer state map size: 0
[state-dump] PullManager:
[state-dump] - num bytes available for pulled objects: 200000000000
[state-dump] - num bytes being pulled (all): 0
[state-dump] - num bytes being pulled / pinned: 0
[state-dump] - num get request bundles: 0
[state-dump] - num wait request bundles: 0
[state-dump] - num task request bundles: 0
[state-dump] - first get request bundle: N/A
[state-dump] - first wait request bundle: N/A
[state-dump] - first task request bundle: N/A
[state-dump] - num objects queued: 0
[state-dump] - num objects actively pulled (all): 0
[state-dump] - num objects actively pulled / pinned: 0
[state-dump] - num bundles being pulled: 0
[state-dump] - num pull retries: 0
[state-dump] - max timeout seconds: 0
[state-dump] - max timeout request is already processed. No entry.
[state-dump] 
[state-dump] WorkerPool:
[state-dump] - registered jobs: 0
[state-dump] - process_failed_job_config_missing: 0
[state-dump] - process_failed_rate_limited: 0
[state-dump] - process_failed_pending_registration: 0
[state-dump] - process_failed_runtime_env_setup_failed: 0
[state-dump] - num JAVA workers: 0
[state-dump] - num JAVA drivers: 0
[state-dump] - num object spill callbacks queued: 0
[state-dump] - num object restore queued: 0
[state-dump] - num util functions queued: 0
[state-dump] - num PYTHON workers: 0
[state-dump] - num PYTHON drivers: 0
[state-dump] - num object spill callbacks queued: 0
[state-dump] - num object restore queued: 0
[state-dump] - num util functions queued: 0
[state-dump] - num idle workers: 0
[state-dump] TaskDependencyManager:
[state-dump] - task deps map size: 0
[state-dump] - get req map size: 0
[state-dump] - wait req map size: 0
[state-dump] - local objects map size: 0
[state-dump] WaitManager:
[state-dump] - num active wait requests: 0
[state-dump] Subscriber:
[state-dump] Channel WORKER_REF_REMOVED_CHANNEL
[state-dump] - cumulative subscribe requests: 0
[state-dump] - cumulative unsubscribe requests: 0
[state-dump] - active subscribed publishers: 0
[state-dump] - cumulative published messages: 0
[state-dump] - cumulative processed messages: 0
[state-dump] Channel WORKER_OBJECT_EVICTION
[state-dump] - cumulative subscribe requests: 0
[state-dump] - cumulative unsubscribe requests: 0
[state-dump] - active subscribed publishers: 0
[state-dump] - cumulative published messages: 0
[state-dump] - cumulative processed messages: 0
[state-dump] Channel WORKER_OBJECT_LOCATIONS_CHANNEL
[state-dump] - cumulative subscribe requests: 0
[state-dump] - cumulative unsubscribe requests: 0
[state-dump] - active subscribed publishers: 0
[state-dump] - cumulative published messages: 0
[state-dump] - cumulative processed messages: 0
[state-dump] num async plasma notifications: 0
[state-dump] Remote node managers: 
[state-dump] Event stats:
[state-dump] Global stats: 23 total (10 active)
[state-dump] Queueing time: mean = 1.838 ms, max = 34.140 ms, min = 4.069 us, total = 42.267 ms
[state-dump] Execution time:  mean = 1.592 ms, total = 36.624 ms
[state-dump] Event stats:
[state-dump] 	PeriodicalRunner.RunFnPeriodically - 7 total (1 active, 1 running), CPU time: mean = 204.231 us, total = 1.430 ms
[state-dump] 	ObjectManager.UpdateAvailableMemory - 4 total (0 active), CPU time: mean = 2.518 us, total = 10.071 us
[state-dump] 	RayletWorkerPool.deadline_timer.kill_idle_workers - 2 total (1 active), CPU time: mean = 2.082 us, total = 4.164 us
[state-dump] 	UNKNOWN - 1 total (1 active), CPU time: mean = 0.000 s, total = 0.000 s
[state-dump] 	NodeManager.deadline_timer.flush_free_objects - 1 total (1 active), CPU time: mean = 0.000 s, total = 0.000 s
[state-dump] 	InternalPubSubGcsService.grpc_client.GcsSubscriberPoll - 1 total (1 active), CPU time: mean = 0.000 s, total = 0.000 s
[state-dump] 	NodeManager.deadline_timer.debug_state_dump - 1 total (1 active), CPU time: mean = 0.000 s, total = 0.000 s
[state-dump] 	InternalPubSubGcsService.grpc_client.GcsSubscriberCommandBatch - 1 total (1 active), CPU time: mean = 0.000 s, total = 0.000 s
[state-dump] 	NodeInfoGcsService.grpc_client.RegisterNode - 1 total (0 active), CPU time: mean = 486.057 us, total = 486.057 us
[state-dump] 	HeartbeatInfoGcsService.grpc_client.ReportHeartbeat - 1 total (1 active), CPU time: mean = 0.000 s, total = 0.000 s
[state-dump] 	NodeInfoGcsService.grpc_client.GetInternalConfig - 1 total (0 active), CPU time: mean = 34.694 ms, total = 34.694 ms
[state-dump] 	NodeManager.deadline_timer.record_metrics - 1 total (1 active), CPU time: mean = 0.000 s, total = 0.000 s
[state-dump] 	GcsClient.deadline_timer.check_gcs_connection - 1 total (1 active), CPU time: mean = 0.000 s, total = 0.000 s
[state-dump] DebugString() time ms: 0
[state-dump] 
[state-dump] 
[2022-06-20 22:45:00,046 I 128931 128931] (raylet) accessor.cc:599: Received notification for node id = 7562cb0081c73f4ed2ac21d1956887bd794b724f1b8c157f4e02d603, IsAlive = 1
[2022-06-20 22:45:26,244 W 128931 128956] (raylet) metric_exporter.cc:207: [1] Export metrics to agent failed: GrpcUnknown: RPC Error message: Method not found!; RPC Error details: . This won't affect Ray, but you can lose metrics from the cluster.
[2022-06-20 22:45:26,617 I 128931 128931] (raylet) agent_manager.cc:40: HandleRegisterAgent, ip: 10.140.1.109, port: 52124, pid: 128988
[2022-06-20 22:45:59,323 I 128931 128962] (raylet) store.cc:546: ========== Plasma store: =================
Current usage: 0 / 200 GB
- num bytes created total: 0
0 pending objects of total size 0MB
- objects spillable: 0
- bytes spillable: 0
- objects unsealed: 0
- bytes unsealed: 0
- objects in use: 0
- bytes in use: 0
- objects evictable: 0
- bytes evictable: 0

- objects created by worker: 0
- bytes created by worker: 0
- objects restored: 0
- bytes restored: 0
- objects received: 0
- bytes received: 0
- objects errored: 0
- bytes errored: 0

[2022-06-20 22:45:59,679 I 128931 128931] (raylet) node_manager.cc:538: [state-dump] Event stats:
[state-dump] 
[state-dump] 
[state-dump] Global stats: 2044 total (8 active)
[state-dump] Queueing time: mean = 23.980 ms, max = 2.560 s, min = -0.020 s, total = 49.016 s
[state-dump] Execution time:  mean = 3.533 ms, total = 7.222 s
[state-dump] Event stats:
[state-dump] 	ObjectManager.UpdateAvailableMemory - 520 total (0 active), CPU time: mean = 524.387 us, total = 272.681 ms
[state-dump] 	NodeManagerService.grpc_server.RequestResourceReport - 463 total (0 active), CPU time: mean = 1.786 ms, total = 826.961 ms
[state-dump] 	NodeManagerService.grpc_server.UpdateResourceUsage - 461 total (0 active), CPU time: mean = 1.309 ms, total = 603.505 ms
[state-dump] 	RayletWorkerPool.deadline_timer.kill_idle_workers - 263 total (1 active), CPU time: mean = 1.021 ms, total = 268.649 ms
[state-dump] 	NodeManagerService.grpc_server.GetResourceLoad - 58 total (0 active), CPU time: mean = 3.046 ms, total = 176.685 ms
[state-dump] 	HeartbeatInfoGcsService.grpc_client.ReportHeartbeat - 56 total (0 active), CPU time: mean = 2.610 ms, total = 146.150 ms
[state-dump] 	UNKNOWN - 55 total (1 active), CPU time: mean = 5.118 ms, total = 281.468 ms
[state-dump] 	NodeManager.deadline_timer.flush_free_objects - 55 total (1 active), CPU time: mean = 2.386 ms, total = 131.244 ms
[state-dump] 	GcsClient.deadline_timer.check_gcs_connection - 55 total (1 active), CPU time: mean = 2.569 ms, total = 141.310 ms
[state-dump] 	NodeManagerService.grpc_server.GetNodeStats - 23 total (0 active), CPU time: mean = 15.426 ms, total = 354.799 ms
[state-dump] 	NodeManager.deadline_timer.record_metrics - 12 total (1 active), CPU time: mean = 25.176 ms, total = 302.113 ms
[state-dump] 	PeriodicalRunner.RunFnPeriodically - 7 total (0 active), CPU time: mean = 243.532 us, total = 1.705 ms
[state-dump] 	NodeManager.deadline_timer.debug_state_dump - 6 total (1 active), CPU time: mean = 551.939 ms, total = 3.312 s
[state-dump] 	InternalPubSubGcsService.grpc_client.GcsSubscriberCommandBatch - 3 total (0 active), CPU time: mean = 68.436 us, total = 205.309 us
[state-dump] 	NodeInfoGcsService.grpc_client.GetAllNodeInfo - 1 total (0 active), CPU time: mean = 85.179 us, total = 85.179 us
[state-dump] 	NodeInfoGcsService.grpc_client.GetInternalConfig - 1 total (0 active), CPU time: mean = 34.694 ms, total = 34.694 ms
[state-dump] 	JobInfoGcsService.grpc_client.GetAllJobInfo - 1 total (0 active), CPU time: mean = 15.018 us, total = 15.018 us
[state-dump] 	InternalPubSubGcsService.grpc_client.GcsSubscriberPoll - 1 total (1 active), CPU time: mean = 0.000 s, total = 0.000 s
[state-dump] 	NodeManager.deadline_timer.print_event_loop_stats - 1 total (1 active, 1 running), CPU time: mean = 0.000 s, total = 0.000 s
[state-dump] 	NodeInfoGcsService.grpc_client.RegisterNode - 1 total (0 active), CPU time: mean = 486.057 us, total = 486.057 us
[state-dump] 	AgentManagerService.grpc_server.RegisterAgent - 1 total (0 active), CPU time: mean = 367.585 ms, total = 367.585 ms
[state-dump] 
[state-dump] NodeManager:
[state-dump] Node ID: 7562cb0081c73f4ed2ac21d1956887bd794b724f1b8c157f4e02d603
[state-dump] Node name: 10.140.1.109
[state-dump] InitialConfigResources: {CPU: 1280000, node:10.140.1.109: 10000, GPU: 80000, object_store_memory: 2000000000000000, memory: 8693891676160000, accelerator_type:A100: 10000}
[state-dump] ClusterTaskManager:
[state-dump] ========== Node: 7562cb0081c73f4ed2ac21d1956887bd794b724f1b8c157f4e02d603 =================
[state-dump] Infeasible queue length: 0
[state-dump] Schedule queue length: 0
[state-dump] Dispatch queue length: 0
[state-dump] num_waiting_for_resource: 0
[state-dump] num_waiting_for_plasma_memory: 0
[state-dump] num_waiting_for_remote_node_resources: 0
[state-dump] num_worker_not_started_by_job_config_not_exist: 0
[state-dump] num_worker_not_started_by_registration_timeout: 0
[state-dump] num_worker_not_started_by_process_rate_limit: 0
[state-dump] num_tasks_waiting_for_workers: 0
[state-dump] num_cancelled_tasks: 0
[state-dump] cluster_resource_scheduler state: 
[state-dump] Local id: -110938788179330527 Local resources: {object_store_memory: [2000000000000000]/[2000000000000000], node:10.140.1.109: [10000]/[10000], memory: [8693891676160000]/[8693891676160000], CPU: [1280000]/[1280000], accelerator_type:A100: [10000]/[10000], GPU: [10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000]/[10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000]}node id: -110938788179330527{accelerator_type:A100: 10000/10000, node:10.140.1.109: 10000/10000, CPU: 1280000/1280000, GPU: 80000/80000, memory: 8693891676160000/8693891676160000, object_store_memory: 2000000000000000/2000000000000000}
[state-dump] Waiting tasks size: 0
[state-dump] Number of executing tasks: 0
[state-dump] Number of pinned task arguments: 0
[state-dump] Number of total spilled tasks: 0
[state-dump] Number of spilled waiting tasks: 0
[state-dump] Number of spilled unschedulable tasks: 0
[state-dump] Resource usage {
[state-dump] }
[state-dump] Running tasks by scheduling class:
[state-dump] ==================================================
[state-dump] 
[state-dump] ClusterResources:
[state-dump] LocalObjectManager:
[state-dump] - num pinned objects: 0
[state-dump] - pinned objects size: 0
[state-dump] - num objects pending restore: 0
[state-dump] - num objects pending spill: 0
[state-dump] - num bytes pending spill: 0
[state-dump] - cumulative spill requests: 0
[state-dump] - cumulative restore requests: 0
[state-dump] 
[state-dump] ObjectManager:
[state-dump] - num local objects: 0
[state-dump] - num unfulfilled push requests: 0
[state-dump] - num pull requests: 0
[state-dump] - num chunks received total: 0
[state-dump] - num chunks received failed (all): 0
[state-dump] - num chunks received failed / cancelled: 0
[state-dump] - num chunks received failed / plasma error: 0
[state-dump] Event stats:
[state-dump] Global stats: 0 total (0 active)
[state-dump] Queueing time: mean = -nan s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] Execution time:  mean = -nan s, total = 0.000 s
[state-dump] Event stats:
[state-dump] PushManager:
[state-dump] - num pushes in flight: 0
[state-dump] - num chunks in flight: 0
[state-dump] - num chunks remaining: 0
[state-dump] - max chunks allowed: 409
[state-dump] OwnershipBasedObjectDirectory:
[state-dump] - num listeners: 0
[state-dump] - cumulative location updates: 368
[state-dump] - num location updates per second: 0.000
[state-dump] - num location lookups per second: 0.000
[state-dump] - num locations added per second: 0.000
[state-dump] - num locations removed per second: 0.000
[state-dump] BufferPool:
[state-dump] - create buffer state map size: 0
[state-dump] PullManager:
[state-dump] - num bytes available for pulled objects: 200000000000
[state-dump] - num bytes being pulled (all): 0
[state-dump] - num bytes being pulled / pinned: 0
[state-dump] - num get request bundles: 0
[state-dump] - num wait request bundles: 0
[state-dump] - num task request bundles: 0
[state-dump] - first get request bundle: N/A
[state-dump] - first wait request bundle: N/A
[state-dump] - first task request bundle: N/A
[state-dump] - num objects queued: 0
[state-dump] - num objects actively pulled (all): 0
[state-dump] - num objects actively pulled / pinned: 0
[state-dump] - num bundles being pulled: 0
[state-dump] - num pull retries: 0
[state-dump] - max timeout seconds: 0
[state-dump] - max timeout request is already processed. No entry.
[state-dump] 
[state-dump] WorkerPool:
[state-dump] - registered jobs: 0
[state-dump] - process_failed_job_config_missing: 0
[state-dump] - process_failed_rate_limited: 0
[state-dump] - process_failed_pending_registration: 0
[state-dump] - process_failed_runtime_env_setup_failed: 0
[state-dump] - num JAVA workers: 0
[state-dump] - num JAVA drivers: 0
[state-dump] - num object spill callbacks queued: 0
[state-dump] - num object restore queued: 0
[state-dump] - num util functions queued: 0
[state-dump] - num PYTHON workers: 0
[state-dump] - num PYTHON drivers: 0
[state-dump] - num object spill callbacks queued: 0
[state-dump] - num object restore queued: 0
[state-dump] - num util functions queued: 0
[state-dump] - num idle workers: 0
[state-dump] TaskDependencyManager:
[state-dump] - task deps map size: 0
[state-dump] - get req map size: 0
[state-dump] - wait req map size: 0
[state-dump] - local objects map size: 0
[state-dump] WaitManager:
[state-dump] - num active wait requests: 0
[state-dump] Subscriber:
[state-dump] Channel WORKER_REF_REMOVED_CHANNEL
[state-dump] - cumulative subscribe requests: 0
[state-dump] - cumulative unsubscribe requests: 0
[state-dump] - active subscribed publishers: 0
[state-dump] - cumulative published messages: 0
[state-dump] - cumulative processed messages: 0
[state-dump] Channel WORKER_OBJECT_EVICTION
[state-dump] - cumulative subscribe requests: 0
[state-dump] - cumulative unsubscribe requests: 0
[state-dump] - active subscribed publishers: 0
[state-dump] - cumulative published messages: 0
[state-dump] - cumulative processed messages: 0
[state-dump] Channel WORKER_OBJECT_LOCATIONS_CHANNEL
[state-dump] - cumulative subscribe requests: 0
[state-dump] - cumulative unsubscribe requests: 0
[state-dump] - active subscribed publishers: 0
[state-dump] - cumulative published messages: 0
[state-dump] - cumulative processed messages: 0
[state-dump] num async plasma notifications: 0
[state-dump] Remote node managers: 
[state-dump] Event stats:
[state-dump] Global stats: 2044 total (8 active)
[state-dump] Queueing time: mean = 23.980 ms, max = 2.560 s, min = -0.020 s, total = 49.016 s
[state-dump] Execution time:  mean = 3.533 ms, total = 7.222 s
[state-dump] Event stats:
[state-dump] 	ObjectManager.UpdateAvailableMemory - 520 total (0 active), CPU time: mean = 524.387 us, total = 272.681 ms
[state-dump] 	NodeManagerService.grpc_server.RequestResourceReport - 463 total (0 active), CPU time: mean = 1.786 ms, total = 826.961 ms
[state-dump] 	NodeManagerService.grpc_server.UpdateResourceUsage - 461 total (0 active), CPU time: mean = 1.309 ms, total = 603.505 ms
[state-dump] 	RayletWorkerPool.deadline_timer.kill_idle_workers - 263 total (1 active), CPU time: mean = 1.021 ms, total = 268.649 ms
[state-dump] 	NodeManagerService.grpc_server.GetResourceLoad - 58 total (0 active), CPU time: mean = 3.046 ms, total = 176.685 ms
[state-dump] 	HeartbeatInfoGcsService.grpc_client.ReportHeartbeat - 56 total (0 active), CPU time: mean = 2.610 ms, total = 146.150 ms
[state-dump] 	UNKNOWN - 55 total (1 active), CPU time: mean = 5.118 ms, total = 281.468 ms
[state-dump] 	NodeManager.deadline_timer.flush_free_objects - 55 total (1 active), CPU time: mean = 2.386 ms, total = 131.244 ms
[state-dump] 	GcsClient.deadline_timer.check_gcs_connection - 55 total (1 active), CPU time: mean = 2.569 ms, total = 141.310 ms
[state-dump] 	NodeManagerService.grpc_server.GetNodeStats - 23 total (0 active), CPU time: mean = 15.426 ms, total = 354.799 ms
[state-dump] 	NodeManager.deadline_timer.record_metrics - 12 total (1 active), CPU time: mean = 25.176 ms, total = 302.113 ms
[state-dump] 	PeriodicalRunner.RunFnPeriodically - 7 total (0 active), CPU time: mean = 243.532 us, total = 1.705 ms
[state-dump] 	NodeManager.deadline_timer.debug_state_dump - 6 total (1 active), CPU time: mean = 551.939 ms, total = 3.312 s
[state-dump] 	InternalPubSubGcsService.grpc_client.GcsSubscriberCommandBatch - 3 total (0 active), CPU time: mean = 68.436 us, total = 205.309 us
[state-dump] 	NodeInfoGcsService.grpc_client.GetAllNodeInfo - 1 total (0 active), CPU time: mean = 85.179 us, total = 85.179 us
[state-dump] 	NodeInfoGcsService.grpc_client.GetInternalConfig - 1 total (0 active), CPU time: mean = 34.694 ms, total = 34.694 ms
[state-dump] 	JobInfoGcsService.grpc_client.GetAllJobInfo - 1 total (0 active), CPU time: mean = 15.018 us, total = 15.018 us
[state-dump] 	InternalPubSubGcsService.grpc_client.GcsSubscriberPoll - 1 total (1 active), CPU time: mean = 0.000 s, total = 0.000 s
[state-dump] 	NodeManager.deadline_timer.print_event_loop_stats - 1 total (1 active, 1 running), CPU time: mean = 0.000 s, total = 0.000 s
[state-dump] 	NodeInfoGcsService.grpc_client.RegisterNode - 1 total (0 active), CPU time: mean = 486.057 us, total = 486.057 us
[state-dump] 	AgentManagerService.grpc_server.RegisterAgent - 1 total (0 active), CPU time: mean = 367.585 ms, total = 367.585 ms
[state-dump] DebugString() time ms: 0
[state-dump] 
[state-dump] 
[2022-06-20 22:46:59,486 I 128931 128962] (raylet) store.cc:546: ========== Plasma store: =================
Current usage: 0 / 200 GB
- num bytes created total: 0
0 pending objects of total size 0MB
- objects spillable: 0
- bytes spillable: 0
- objects unsealed: 0
- bytes unsealed: 0
- objects in use: 0
- bytes in use: 0
- objects evictable: 0
- bytes evictable: 0

- objects created by worker: 0
- bytes created by worker: 0
- objects restored: 0
- bytes restored: 0
- objects received: 0
- bytes received: 0
- objects errored: 0
- bytes errored: 0

[2022-06-20 22:46:59,680 I 128931 128931] (raylet) node_manager.cc:538: [state-dump] Event stats:
[state-dump] 
[state-dump] 
[state-dump] Global stats: 3918 total (8 active)
[state-dump] Queueing time: mean = 31.635 ms, max = 3.975 s, min = -0.020 s, total = 123.945 s
[state-dump] Execution time:  mean = 4.484 ms, total = 17.570 s
[state-dump] Event stats:
[state-dump] 	ObjectManager.UpdateAvailableMemory - 996 total (0 active), CPU time: mean = 734.071 us, total = 731.135 ms
[state-dump] 	NodeManagerService.grpc_server.RequestResourceReport - 876 total (0 active), CPU time: mean = 3.407 ms, total = 2.985 s
[state-dump] 	NodeManagerService.grpc_server.UpdateResourceUsage - 873 total (0 active), CPU time: mean = 2.498 ms, total = 2.181 s
[state-dump] 	RayletWorkerPool.deadline_timer.kill_idle_workers - 507 total (1 active), CPU time: mean = 2.685 ms, total = 1.361 s
[state-dump] 	NodeManagerService.grpc_server.GetResourceLoad - 115 total (0 active), CPU time: mean = 5.167 ms, total = 594.216 ms
[state-dump] 	HeartbeatInfoGcsService.grpc_client.ReportHeartbeat - 109 total (0 active), CPU time: mean = 2.938 ms, total = 320.248 ms
[state-dump] 	GcsClient.deadline_timer.check_gcs_connection - 108 total (1 active), CPU time: mean = 3.356 ms, total = 362.494 ms
[state-dump] 	UNKNOWN - 107 total (1 active), CPU time: mean = 8.725 ms, total = 933.548 ms
[state-dump] 	NodeManager.deadline_timer.flush_free_objects - 107 total (1 active), CPU time: mean = 3.310 ms, total = 354.133 ms
[state-dump] 	NodeManagerService.grpc_server.GetNodeStats - 67 total (0 active), CPU time: mean = 12.774 ms, total = 855.874 ms
[state-dump] 	NodeManager.deadline_timer.record_metrics - 23 total (1 active), CPU time: mean = 35.726 ms, total = 821.689 ms
[state-dump] 	NodeManager.deadline_timer.debug_state_dump - 12 total (1 active), CPU time: mean = 470.745 ms, total = 5.649 s
[state-dump] 	PeriodicalRunner.RunFnPeriodically - 7 total (0 active), CPU time: mean = 243.532 us, total = 1.705 ms
[state-dump] 	InternalPubSubGcsService.grpc_client.GcsSubscriberCommandBatch - 3 total (0 active), CPU time: mean = 68.436 us, total = 205.309 us
[state-dump] 	NodeManager.deadline_timer.print_event_loop_stats - 2 total (1 active, 1 running), CPU time: mean = 8.129 ms, total = 16.258 ms
[state-dump] 	NodeInfoGcsService.grpc_client.GetAllNodeInfo - 1 total (0 active), CPU time: mean = 85.179 us, total = 85.179 us
[state-dump] 	NodeInfoGcsService.grpc_client.GetInternalConfig - 1 total (0 active), CPU time: mean = 34.694 ms, total = 34.694 ms
[state-dump] 	JobInfoGcsService.grpc_client.GetAllJobInfo - 1 total (0 active), CPU time: mean = 15.018 us, total = 15.018 us
[state-dump] 	InternalPubSubGcsService.grpc_client.GcsSubscriberPoll - 1 total (1 active), CPU time: mean = 0.000 s, total = 0.000 s
[state-dump] 	NodeInfoGcsService.grpc_client.RegisterNode - 1 total (0 active), CPU time: mean = 486.057 us, total = 486.057 us
[state-dump] 	AgentManagerService.grpc_server.RegisterAgent - 1 total (0 active), CPU time: mean = 367.585 ms, total = 367.585 ms
[state-dump] 
[state-dump] NodeManager:
[state-dump] Node ID: 7562cb0081c73f4ed2ac21d1956887bd794b724f1b8c157f4e02d603
[state-dump] Node name: 10.140.1.109
[state-dump] InitialConfigResources: {CPU: 1280000, node:10.140.1.109: 10000, GPU: 80000, object_store_memory: 2000000000000000, memory: 8693891676160000, accelerator_type:A100: 10000}
[state-dump] ClusterTaskManager:
[state-dump] ========== Node: 7562cb0081c73f4ed2ac21d1956887bd794b724f1b8c157f4e02d603 =================
[state-dump] Infeasible queue length: 0
[state-dump] Schedule queue length: 0
[state-dump] Dispatch queue length: 0
[state-dump] num_waiting_for_resource: 0
[state-dump] num_waiting_for_plasma_memory: 0
[state-dump] num_waiting_for_remote_node_resources: 0
[state-dump] num_worker_not_started_by_job_config_not_exist: 0
[state-dump] num_worker_not_started_by_registration_timeout: 0
[state-dump] num_worker_not_started_by_process_rate_limit: 0
[state-dump] num_tasks_waiting_for_workers: 0
[state-dump] num_cancelled_tasks: 0
[state-dump] cluster_resource_scheduler state: 
[state-dump] Local id: -110938788179330527 Local resources: {object_store_memory: [2000000000000000]/[2000000000000000], node:10.140.1.109: [10000]/[10000], memory: [8693891676160000]/[8693891676160000], CPU: [1280000]/[1280000], accelerator_type:A100: [10000]/[10000], GPU: [10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000]/[10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000]}node id: -110938788179330527{node:10.140.1.109: 10000/10000, CPU: 1280000/1280000, object_store_memory: 2000000000000000/2000000000000000, accelerator_type:A100: 10000/10000, memory: 8693891676160000/8693891676160000, GPU: 80000/80000}
[state-dump] Waiting tasks size: 0
[state-dump] Number of executing tasks: 0
[state-dump] Number of pinned task arguments: 0
[state-dump] Number of total spilled tasks: 0
[state-dump] Number of spilled waiting tasks: 0
[state-dump] Number of spilled unschedulable tasks: 0
[state-dump] Resource usage {
[state-dump] }
[state-dump] Running tasks by scheduling class:
[state-dump] ==================================================
[state-dump] 
[state-dump] ClusterResources:
[state-dump] LocalObjectManager:
[state-dump] - num pinned objects: 0
[state-dump] - pinned objects size: 0
[state-dump] - num objects pending restore: 0
[state-dump] - num objects pending spill: 0
[state-dump] - num bytes pending spill: 0
[state-dump] - cumulative spill requests: 0
[state-dump] - cumulative restore requests: 0
[state-dump] 
[state-dump] ObjectManager:
[state-dump] - num local objects: 0
[state-dump] - num unfulfilled push requests: 0
[state-dump] - num pull requests: 0
[state-dump] - num chunks received total: 0
[state-dump] - num chunks received failed (all): 0
[state-dump] - num chunks received failed / cancelled: 0
[state-dump] - num chunks received failed / plasma error: 0
[state-dump] Event stats:
[state-dump] Global stats: 0 total (0 active)
[state-dump] Queueing time: mean = -nan s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] Execution time:  mean = -nan s, total = 0.000 s
[state-dump] Event stats:
[state-dump] PushManager:
[state-dump] - num pushes in flight: 0
[state-dump] - num chunks in flight: 0
[state-dump] - num chunks remaining: 0
[state-dump] - max chunks allowed: 409
[state-dump] OwnershipBasedObjectDirectory:
[state-dump] - num listeners: 0
[state-dump] - cumulative location updates: 368
[state-dump] - num location updates per second: 0.000
[state-dump] - num location lookups per second: 0.000
[state-dump] - num locations added per second: 0.000
[state-dump] - num locations removed per second: 0.000
[state-dump] BufferPool:
[state-dump] - create buffer state map size: 0
[state-dump] PullManager:
[state-dump] - num bytes available for pulled objects: 200000000000
[state-dump] - num bytes being pulled (all): 0
[state-dump] - num bytes being pulled / pinned: 0
[state-dump] - num get request bundles: 0
[state-dump] - num wait request bundles: 0
[state-dump] - num task request bundles: 0
[state-dump] - first get request bundle: N/A
[state-dump] - first wait request bundle: N/A
[state-dump] - first task request bundle: N/A
[state-dump] - num objects queued: 0
[state-dump] - num objects actively pulled (all): 0
[state-dump] - num objects actively pulled / pinned: 0
[state-dump] - num bundles being pulled: 0
[state-dump] - num pull retries: 0
[state-dump] - max timeout seconds: 0
[state-dump] - max timeout request is already processed. No entry.
[state-dump] 
[state-dump] WorkerPool:
[state-dump] - registered jobs: 0
[state-dump] - process_failed_job_config_missing: 0
[state-dump] - process_failed_rate_limited: 0
[state-dump] - process_failed_pending_registration: 0
[state-dump] - process_failed_runtime_env_setup_failed: 0
[state-dump] - num JAVA workers: 0
[state-dump] - num JAVA drivers: 0
[state-dump] - num object spill callbacks queued: 0
[state-dump] - num object restore queued: 0
[state-dump] - num util functions queued: 0
[state-dump] - num PYTHON workers: 0
[state-dump] - num PYTHON drivers: 0
[state-dump] - num object spill callbacks queued: 0
[state-dump] - num object restore queued: 0
[state-dump] - num util functions queued: 0
[state-dump] - num idle workers: 0
[state-dump] TaskDependencyManager:
[state-dump] - task deps map size: 0
[state-dump] - get req map size: 0
[state-dump] - wait req map size: 0
[state-dump] - local objects map size: 0
[state-dump] WaitManager:
[state-dump] - num active wait requests: 0
[state-dump] Subscriber:
[state-dump] Channel WORKER_REF_REMOVED_CHANNEL
[state-dump] - cumulative subscribe requests: 0
[state-dump] - cumulative unsubscribe requests: 0
[state-dump] - active subscribed publishers: 0
[state-dump] - cumulative published messages: 0
[state-dump] - cumulative processed messages: 0
[state-dump] Channel WORKER_OBJECT_EVICTION
[state-dump] - cumulative subscribe requests: 0
[state-dump] - cumulative unsubscribe requests: 0
[state-dump] - active subscribed publishers: 0
[state-dump] - cumulative published messages: 0
[state-dump] - cumulative processed messages: 0
[state-dump] Channel WORKER_OBJECT_LOCATIONS_CHANNEL
[state-dump] - cumulative subscribe requests: 0
[state-dump] - cumulative unsubscribe requests: 0
[state-dump] - active subscribed publishers: 0
[state-dump] - cumulative published messages: 0
[state-dump] - cumulative processed messages: 0
[state-dump] num async plasma notifications: 0
[state-dump] Remote node managers: 
[state-dump] Event stats:
[state-dump] Global stats: 3918 total (8 active)
[state-dump] Queueing time: mean = 31.635 ms, max = 3.975 s, min = -0.020 s, total = 123.945 s
[state-dump] Execution time:  mean = 4.484 ms, total = 17.570 s
[state-dump] Event stats:
[state-dump] 	ObjectManager.UpdateAvailableMemory - 996 total (0 active), CPU time: mean = 734.071 us, total = 731.135 ms
[state-dump] 	NodeManagerService.grpc_server.RequestResourceReport - 876 total (0 active), CPU time: mean = 3.407 ms, total = 2.985 s
[state-dump] 	NodeManagerService.grpc_server.UpdateResourceUsage - 873 total (0 active), CPU time: mean = 2.498 ms, total = 2.181 s
[state-dump] 	RayletWorkerPool.deadline_timer.kill_idle_workers - 507 total (1 active), CPU time: mean = 2.685 ms, total = 1.361 s
[state-dump] 	NodeManagerService.grpc_server.GetResourceLoad - 115 total (0 active), CPU time: mean = 5.167 ms, total = 594.216 ms
[state-dump] 	HeartbeatInfoGcsService.grpc_client.ReportHeartbeat - 109 total (0 active), CPU time: mean = 2.938 ms, total = 320.248 ms
[state-dump] 	GcsClient.deadline_timer.check_gcs_connection - 108 total (1 active), CPU time: mean = 3.356 ms, total = 362.494 ms
[state-dump] 	UNKNOWN - 107 total (1 active), CPU time: mean = 8.725 ms, total = 933.548 ms
[state-dump] 	NodeManager.deadline_timer.flush_free_objects - 107 total (1 active), CPU time: mean = 3.310 ms, total = 354.133 ms
[state-dump] 	NodeManagerService.grpc_server.GetNodeStats - 67 total (0 active), CPU time: mean = 12.774 ms, total = 855.874 ms
[state-dump] 	NodeManager.deadline_timer.record_metrics - 23 total (1 active), CPU time: mean = 35.726 ms, total = 821.689 ms
[state-dump] 	NodeManager.deadline_timer.debug_state_dump - 12 total (1 active), CPU time: mean = 470.745 ms, total = 5.649 s
[state-dump] 	PeriodicalRunner.RunFnPeriodically - 7 total (0 active), CPU time: mean = 243.532 us, total = 1.705 ms
[state-dump] 	InternalPubSubGcsService.grpc_client.GcsSubscriberCommandBatch - 3 total (0 active), CPU time: mean = 68.436 us, total = 205.309 us
[state-dump] 	NodeManager.deadline_timer.print_event_loop_stats - 2 total (1 active, 1 running), CPU time: mean = 8.129 ms, total = 16.258 ms
[state-dump] 	NodeInfoGcsService.grpc_client.GetAllNodeInfo - 1 total (0 active), CPU time: mean = 85.179 us, total = 85.179 us
[state-dump] 	NodeInfoGcsService.grpc_client.GetInternalConfig - 1 total (0 active), CPU time: mean = 34.694 ms, total = 34.694 ms
[state-dump] 	JobInfoGcsService.grpc_client.GetAllJobInfo - 1 total (0 active), CPU time: mean = 15.018 us, total = 15.018 us
[state-dump] 	InternalPubSubGcsService.grpc_client.GcsSubscriberPoll - 1 total (1 active), CPU time: mean = 0.000 s, total = 0.000 s
[state-dump] 	NodeInfoGcsService.grpc_client.RegisterNode - 1 total (0 active), CPU time: mean = 486.057 us, total = 486.057 us
[state-dump] 	AgentManagerService.grpc_server.RegisterAgent - 1 total (0 active), CPU time: mean = 367.585 ms, total = 367.585 ms
[state-dump] DebugString() time ms: 0
[state-dump] 
[state-dump] 
[2022-06-20 22:47:20,086 I 128931 128931] (raylet) node_manager.cc:579: New job has started. Job id 01000000 Driver pid 129188 is dead: 0 driver address: 10.140.1.109
[2022-06-20 22:47:20,106 I 128931 128931] (raylet) worker_pool.cc:635: Job 01000000 already started in worker pool.
[2022-06-20 22:47:20,223 I 128931 128962] (raylet) object_store.cc:35: Object store current usage 8e-09 / 200 GB.
[2022-06-20 22:47:37,367 W 128931 128991] (raylet) node_manager.cc:157: Last heartbeat was sent 5135 ms ago. There might be resource pressure on this node. If heartbeat keeps lagging, this node can be marked as dead mistakenly.
[2022-06-20 22:47:59,670 I 128931 128962] (raylet) store.cc:546: ========== Plasma store: =================
Current usage: 0 / 200 GB
- num bytes created total: 8
0 pending objects of total size 0MB
- objects spillable: 0
- bytes spillable: 0
- objects unsealed: 0
- bytes unsealed: 0
- objects in use: 0
- bytes in use: 0
- objects evictable: 0
- bytes evictable: 0

- objects created by worker: 0
- bytes created by worker: 0
- objects restored: 0
- bytes restored: 0
- objects received: 0
- bytes received: 0
- objects errored: 0
- bytes errored: 0

[2022-06-20 22:47:59,695 I 128931 128931] (raylet) node_manager.cc:538: [state-dump] Event stats:
[state-dump] 
[state-dump] 
[state-dump] Global stats: 5870 total (10 active)
[state-dump] Queueing time: mean = 34.098 ms, max = 3.975 s, min = -0.020 s, total = 200.158 s
[state-dump] Execution time:  mean = 4.757 ms, total = 27.926 s
[state-dump] Event stats:
[state-dump] 	ObjectManager.UpdateAvailableMemory - 1462 total (0 active), CPU time: mean = 936.827 us, total = 1.370 s
[state-dump] 	NodeManagerService.grpc_server.RequestResourceReport - 1284 total (1 active), CPU time: mean = 3.215 ms, total = 4.128 s
[state-dump] 	NodeManagerService.grpc_server.UpdateResourceUsage - 1280 total (0 active), CPU time: mean = 1.972 ms, total = 2.525 s
[state-dump] 	RayletWorkerPool.deadline_timer.kill_idle_workers - 745 total (1 active), CPU time: mean = 2.852 ms, total = 2.124 s
[state-dump] 	NodeManagerService.grpc_server.GetResourceLoad - 172 total (0 active), CPU time: mean = 8.753 ms, total = 1.506 s
[state-dump] 	GcsClient.deadline_timer.check_gcs_connection - 160 total (1 active), CPU time: mean = 3.521 ms, total = 563.318 ms
[state-dump] 	HeartbeatInfoGcsService.grpc_client.ReportHeartbeat - 160 total (0 active), CPU time: mean = 4.265 ms, total = 682.382 ms
[state-dump] 	UNKNOWN - 159 total (1 active), CPU time: mean = 11.009 ms, total = 1.750 s
[state-dump] 	NodeManager.deadline_timer.flush_free_objects - 159 total (1 active), CPU time: mean = 3.513 ms, total = 558.629 ms
[state-dump] 	NodeManagerService.grpc_server.GetNodeStats - 109 total (0 active), CPU time: mean = 21.281 ms, total = 2.320 s
[state-dump] 	NodeManagerService.grpc_server.GetGcsServerAddress - 35 total (0 active), CPU time: mean = 4.753 ms, total = 166.355 ms
[state-dump] 	NodeManagerService.grpc_server.ReportWorkerBacklog - 34 total (0 active), CPU time: mean = 2.833 ms, total = 96.337 ms
[state-dump] 	NodeManager.deadline_timer.record_metrics - 34 total (1 active), CPU time: mean = 50.286 ms, total = 1.710 s
[state-dump] 	CoreWorkerService.grpc_client.GetCoreWorkerStats - 26 total (0 active), CPU time: mean = 15.731 ms, total = 409.016 ms
[state-dump] 	NodeManager.deadline_timer.debug_state_dump - 18 total (1 active), CPU time: mean = 377.202 ms, total = 6.790 s
[state-dump] 	ClientConnection.async_read.ReadBufferAsync - 7 total (1 active), CPU time: mean = 65.778 ms, total = 460.449 ms
[state-dump] 	PeriodicalRunner.RunFnPeriodically - 7 total (0 active), CPU time: mean = 243.532 us, total = 1.705 ms
[state-dump] 	NodeManager.deadline_timer.print_event_loop_stats - 3 total (1 active, 1 running), CPU time: mean = 5.647 ms, total = 16.941 ms
[state-dump] 	InternalPubSubGcsService.grpc_client.GcsSubscriberCommandBatch - 3 total (0 active), CPU time: mean = 68.436 us, total = 205.309 us
[state-dump] 	InternalPubSubGcsService.grpc_client.GcsSubscriberPoll - 2 total (1 active), CPU time: mean = 77.900 ms, total = 155.801 ms
[state-dump] 	AgentManagerService.grpc_server.RegisterAgent - 1 total (0 active), CPU time: mean = 367.585 ms, total = 367.585 ms
[state-dump] 	ObjectManager.ObjectDeleted - 1 total (0 active), CPU time: mean = 10.076 ms, total = 10.076 ms
[state-dump] 	NodeInfoGcsService.grpc_client.RegisterNode - 1 total (0 active), CPU time: mean = 486.057 us, total = 486.057 us
[state-dump] 	NodeInfoGcsService.grpc_client.GetInternalConfig - 1 total (0 active), CPU time: mean = 34.694 ms, total = 34.694 ms
[state-dump] 	Subscriber.HandlePublishedMessage_GCS_JOB_CHANNEL - 1 total (0 active), CPU time: mean = 70.129 ms, total = 70.129 ms
[state-dump] 	NodeManagerService.grpc_server.GetSystemConfig - 1 total (0 active), CPU time: mean = 20.011 ms, total = 20.011 ms
[state-dump] 	ClientConnection.async_write.DoAsyncWrites - 1 total (0 active), CPU time: mean = 4.937 ms, total = 4.937 ms
[state-dump] 	ObjectManager.ObjectAdded - 1 total (0 active), CPU time: mean = 65.150 ms, total = 65.150 ms
[state-dump] 	NodeInfoGcsService.grpc_client.GetAllNodeInfo - 1 total (0 active), CPU time: mean = 85.179 us, total = 85.179 us
[state-dump] 	JobInfoGcsService.grpc_client.AddJob - 1 total (0 active), CPU time: mean = 20.046 ms, total = 20.046 ms
[state-dump] 	JobInfoGcsService.grpc_client.GetAllJobInfo - 1 total (0 active), CPU time: mean = 15.018 us, total = 15.018 us
[state-dump] 
[state-dump] NodeManager:
[state-dump] Node ID: 7562cb0081c73f4ed2ac21d1956887bd794b724f1b8c157f4e02d603
[state-dump] Node name: 10.140.1.109
[state-dump] InitialConfigResources: {CPU: 1280000, node:10.140.1.109: 10000, GPU: 80000, object_store_memory: 2000000000000000, memory: 8693891676160000, accelerator_type:A100: 10000}
[state-dump] ClusterTaskManager:
[state-dump] ========== Node: 7562cb0081c73f4ed2ac21d1956887bd794b724f1b8c157f4e02d603 =================
[state-dump] Infeasible queue length: 0
[state-dump] Schedule queue length: 0
[state-dump] Dispatch queue length: 0
[state-dump] num_waiting_for_resource: 0
[state-dump] num_waiting_for_plasma_memory: 0
[state-dump] num_waiting_for_remote_node_resources: 0
[state-dump] num_worker_not_started_by_job_config_not_exist: 0
[state-dump] num_worker_not_started_by_registration_timeout: 0
[state-dump] num_worker_not_started_by_process_rate_limit: 0
[state-dump] num_tasks_waiting_for_workers: 0
[state-dump] num_cancelled_tasks: 0
[state-dump] cluster_resource_scheduler state: 
[state-dump] Local id: -110938788179330527 Local resources: {object_store_memory: [2000000000000000]/[2000000000000000], node:10.140.1.109: [10000]/[10000], memory: [8693891676160000]/[8693891676160000], CPU: [1280000]/[1280000], accelerator_type:A100: [10000]/[10000], GPU: [10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000]/[10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000]}node id: -110938788179330527{accelerator_type:A100: 10000/10000, CPU: 1280000/1280000, node:10.140.1.109: 10000/10000, GPU: 80000/80000, memory: 8693891676160000/8693891676160000, object_store_memory: 2000000000000000/2000000000000000}
[state-dump] Waiting tasks size: 0
[state-dump] Number of executing tasks: 0
[state-dump] Number of pinned task arguments: 0
[state-dump] Number of total spilled tasks: 0
[state-dump] Number of spilled waiting tasks: 0
[state-dump] Number of spilled unschedulable tasks: 0
[state-dump] Resource usage {
[state-dump] }
[state-dump] Running tasks by scheduling class:
[state-dump] ==================================================
[state-dump] 
[state-dump] ClusterResources:
[state-dump] LocalObjectManager:
[state-dump] - num pinned objects: 0
[state-dump] - pinned objects size: 0
[state-dump] - num objects pending restore: 0
[state-dump] - num objects pending spill: 0
[state-dump] - num bytes pending spill: 0
[state-dump] - cumulative spill requests: 0
[state-dump] - cumulative restore requests: 0
[state-dump] 
[state-dump] ObjectManager:
[state-dump] - num local objects: 0
[state-dump] - num unfulfilled push requests: 0
[state-dump] - num pull requests: 0
[state-dump] - num chunks received total: 0
[state-dump] - num chunks received failed (all): 0
[state-dump] - num chunks received failed / cancelled: 0
[state-dump] - num chunks received failed / plasma error: 0
[state-dump] Event stats:
[state-dump] Global stats: 0 total (0 active)
[state-dump] Queueing time: mean = -nan s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] Execution time:  mean = -nan s, total = 0.000 s
[state-dump] Event stats:
[state-dump] PushManager:
[state-dump] - num pushes in flight: 0
[state-dump] - num chunks in flight: 0
[state-dump] - num chunks remaining: 0
[state-dump] - max chunks allowed: 409
[state-dump] OwnershipBasedObjectDirectory:
[state-dump] - num listeners: 0
[state-dump] - cumulative location updates: 368
[state-dump] - num location updates per second: 0.000
[state-dump] - num location lookups per second: 0.000
[state-dump] - num locations added per second: 0.000
[state-dump] - num locations removed per second: 0.000
[state-dump] BufferPool:
[state-dump] - create buffer state map size: 0
[state-dump] PullManager:
[state-dump] - num bytes available for pulled objects: 200000000000
[state-dump] - num bytes being pulled (all): 0
[state-dump] - num bytes being pulled / pinned: 0
[state-dump] - num get request bundles: 0
[state-dump] - num wait request bundles: 0
[state-dump] - num task request bundles: 0
[state-dump] - first get request bundle: N/A
[state-dump] - first wait request bundle: N/A
[state-dump] - first task request bundle: N/A
[state-dump] - num objects queued: 0
[state-dump] - num objects actively pulled (all): 0
[state-dump] - num objects actively pulled / pinned: 0
[state-dump] - num bundles being pulled: 0
[state-dump] - num pull retries: 0
[state-dump] - max timeout seconds: 0
[state-dump] - max timeout request is already processed. No entry.
[state-dump] 
[state-dump] WorkerPool:
[state-dump] - registered jobs: 1
[state-dump] - process_failed_job_config_missing: 0
[state-dump] - process_failed_rate_limited: 0
[state-dump] - process_failed_pending_registration: 0
[state-dump] - process_failed_runtime_env_setup_failed: 0
[state-dump] - num JAVA workers: 0
[state-dump] - num JAVA drivers: 0
[state-dump] - num object spill callbacks queued: 0
[state-dump] - num object restore queued: 0
[state-dump] - num util functions queued: 0
[state-dump] - num PYTHON workers: 0
[state-dump] - num PYTHON drivers: 1
[state-dump] - num object spill callbacks queued: 0
[state-dump] - num object restore queued: 0
[state-dump] - num util functions queued: 0
[state-dump] - num idle workers: 0
[state-dump] TaskDependencyManager:
[state-dump] - task deps map size: 0
[state-dump] - get req map size: 0
[state-dump] - wait req map size: 0
[state-dump] - local objects map size: 0
[state-dump] WaitManager:
[state-dump] - num active wait requests: 0
[state-dump] Subscriber:
[state-dump] Channel WORKER_REF_REMOVED_CHANNEL
[state-dump] - cumulative subscribe requests: 0
[state-dump] - cumulative unsubscribe requests: 0
[state-dump] - active subscribed publishers: 0
[state-dump] - cumulative published messages: 0
[state-dump] - cumulative processed messages: 0
[state-dump] Channel WORKER_OBJECT_EVICTION
[state-dump] - cumulative subscribe requests: 0
[state-dump] - cumulative unsubscribe requests: 0
[state-dump] - active subscribed publishers: 0
[state-dump] - cumulative published messages: 0
[state-dump] - cumulative processed messages: 0
[state-dump] Channel WORKER_OBJECT_LOCATIONS_CHANNEL
[state-dump] - cumulative subscribe requests: 0
[state-dump] - cumulative unsubscribe requests: 0
[state-dump] - active subscribed publishers: 0
[state-dump] - cumulative published messages: 0
[state-dump] - cumulative processed messages: 0
[state-dump] num async plasma notifications: 0
[state-dump] Remote node managers: 
[state-dump] Event stats:
[state-dump] Global stats: 5870 total (10 active)
[state-dump] Queueing time: mean = 34.098 ms, max = 3.975 s, min = -0.020 s, total = 200.158 s
[state-dump] Execution time:  mean = 4.757 ms, total = 27.926 s
[state-dump] Event stats:
[state-dump] 	ObjectManager.UpdateAvailableMemory - 1462 total (0 active), CPU time: mean = 936.827 us, total = 1.370 s
[state-dump] 	NodeManagerService.grpc_server.RequestResourceReport - 1284 total (1 active), CPU time: mean = 3.215 ms, total = 4.128 s
[state-dump] 	NodeManagerService.grpc_server.UpdateResourceUsage - 1280 total (0 active), CPU time: mean = 1.972 ms, total = 2.525 s
[state-dump] 	RayletWorkerPool.deadline_timer.kill_idle_workers - 745 total (1 active), CPU time: mean = 2.852 ms, total = 2.124 s
[state-dump] 	NodeManagerService.grpc_server.GetResourceLoad - 172 total (0 active), CPU time: mean = 8.753 ms, total = 1.506 s
[state-dump] 	GcsClient.deadline_timer.check_gcs_connection - 160 total (1 active), CPU time: mean = 3.521 ms, total = 563.318 ms
[state-dump] 	HeartbeatInfoGcsService.grpc_client.ReportHeartbeat - 160 total (0 active), CPU time: mean = 4.265 ms, total = 682.382 ms
[state-dump] 	UNKNOWN - 159 total (1 active), CPU time: mean = 11.009 ms, total = 1.750 s
[state-dump] 	NodeManager.deadline_timer.flush_free_objects - 159 total (1 active), CPU time: mean = 3.513 ms, total = 558.629 ms
[state-dump] 	NodeManagerService.grpc_server.GetNodeStats - 109 total (0 active), CPU time: mean = 21.281 ms, total = 2.320 s
[state-dump] 	NodeManagerService.grpc_server.GetGcsServerAddress - 35 total (0 active), CPU time: mean = 4.753 ms, total = 166.355 ms
[state-dump] 	NodeManagerService.grpc_server.ReportWorkerBacklog - 34 total (0 active), CPU time: mean = 2.833 ms, total = 96.337 ms
[state-dump] 	NodeManager.deadline_timer.record_metrics - 34 total (1 active), CPU time: mean = 50.286 ms, total = 1.710 s
[state-dump] 	CoreWorkerService.grpc_client.GetCoreWorkerStats - 26 total (0 active), CPU time: mean = 15.731 ms, total = 409.016 ms
[state-dump] 	NodeManager.deadline_timer.debug_state_dump - 18 total (1 active), CPU time: mean = 377.202 ms, total = 6.790 s
[state-dump] 	ClientConnection.async_read.ReadBufferAsync - 7 total (1 active), CPU time: mean = 65.778 ms, total = 460.449 ms
[state-dump] 	PeriodicalRunner.RunFnPeriodically - 7 total (0 active), CPU time: mean = 243.532 us, total = 1.705 ms
[state-dump] 	NodeManager.deadline_timer.print_event_loop_stats - 3 total (1 active, 1 running), CPU time: mean = 5.647 ms, total = 16.941 ms
[state-dump] 	InternalPubSubGcsService.grpc_client.GcsSubscriberCommandBatch - 3 total (0 active), CPU time: mean = 68.436 us, total = 205.309 us
[state-dump] 	InternalPubSubGcsService.grpc_client.GcsSubscriberPoll - 2 total (1 active), CPU time: mean = 77.900 ms, total = 155.801 ms
[state-dump] 	AgentManagerService.grpc_server.RegisterAgent - 1 total (0 active), CPU time: mean = 367.585 ms, total = 367.585 ms
[state-dump] 	ObjectManager.ObjectDeleted - 1 total (0 active), CPU time: mean = 10.076 ms, total = 10.076 ms
[state-dump] 	NodeInfoGcsService.grpc_client.RegisterNode - 1 total (0 active), CPU time: mean = 486.057 us, total = 486.057 us
[state-dump] 	NodeInfoGcsService.grpc_client.GetInternalConfig - 1 total (0 active), CPU time: mean = 34.694 ms, total = 34.694 ms
[state-dump] 	Subscriber.HandlePublishedMessage_GCS_JOB_CHANNEL - 1 total (0 active), CPU time: mean = 70.129 ms, total = 70.129 ms
[state-dump] 	NodeManagerService.grpc_server.GetSystemConfig - 1 total (0 active), CPU time: mean = 20.011 ms, total = 20.011 ms
[state-dump] 	ClientConnection.async_write.DoAsyncWrites - 1 total (0 active), CPU time: mean = 4.937 ms, total = 4.937 ms
[state-dump] 	ObjectManager.ObjectAdded - 1 total (0 active), CPU time: mean = 65.150 ms, total = 65.150 ms
[state-dump] 	NodeInfoGcsService.grpc_client.GetAllNodeInfo - 1 total (0 active), CPU time: mean = 85.179 us, total = 85.179 us
[state-dump] 	JobInfoGcsService.grpc_client.AddJob - 1 total (0 active), CPU time: mean = 20.046 ms, total = 20.046 ms
[state-dump] 	JobInfoGcsService.grpc_client.GetAllJobInfo - 1 total (0 active), CPU time: mean = 15.018 us, total = 15.018 us
[state-dump] DebugString() time ms: 0
[state-dump] 
[state-dump] 
[2022-06-20 22:48:59,876 I 128931 128962] (raylet) store.cc:546: ========== Plasma store: =================
Current usage: 0 / 200 GB
- num bytes created total: 8
0 pending objects of total size 0MB
- objects spillable: 0
- bytes spillable: 0
- objects unsealed: 0
- bytes unsealed: 0
- objects in use: 0
- bytes in use: 0
- objects evictable: 0
- bytes evictable: 0

- objects created by worker: 0
- bytes created by worker: 0
- objects restored: 0
- bytes restored: 0
- objects received: 0
- bytes received: 0
- objects errored: 0
- bytes errored: 0

[2022-06-20 22:49:00,018 I 128931 128931] (raylet) node_manager.cc:538: [state-dump] Event stats:
[state-dump] 
[state-dump] 
[state-dump] Global stats: 7954 total (11 active)
[state-dump] Queueing time: mean = 33.286 ms, max = 3.975 s, min = -0.067 s, total = 264.754 s
[state-dump] Execution time:  mean = 4.630 ms, total = 36.826 s
[state-dump] Event stats:
[state-dump] 	ObjectManager.UpdateAvailableMemory - 1966 total (0 active), CPU time: mean = 842.248 us, total = 1.656 s
[state-dump] 	NodeManagerService.grpc_server.RequestResourceReport - 1700 total (0 active), CPU time: mean = 2.920 ms, total = 4.965 s
[state-dump] 	NodeManagerService.grpc_server.UpdateResourceUsage - 1695 total (0 active), CPU time: mean = 2.468 ms, total = 4.183 s
[state-dump] 	RayletWorkerPool.deadline_timer.kill_idle_workers - 1001 total (1 active), CPU time: mean = 2.543 ms, total = 2.545 s
[state-dump] 	NodeManagerService.grpc_server.GetResourceLoad - 228 total (0 active), CPU time: mean = 7.299 ms, total = 1.664 s
[state-dump] 	HeartbeatInfoGcsService.grpc_client.ReportHeartbeat - 215 total (1 active), CPU time: mean = 3.477 ms, total = 747.585 ms
[state-dump] 	GcsClient.deadline_timer.check_gcs_connection - 214 total (1 active), CPU time: mean = 3.524 ms, total = 754.191 ms
[state-dump] 	UNKNOWN - 214 total (1 active), CPU time: mean = 12.735 ms, total = 2.725 s
[state-dump] 	NodeManager.deadline_timer.flush_free_objects - 213 total (1 active), CPU time: mean = 3.449 ms, total = 734.687 ms
[state-dump] 	NodeManagerService.grpc_server.GetNodeStats - 153 total (0 active), CPU time: mean = 25.143 ms, total = 3.847 s
[state-dump] 	NodeManagerService.grpc_server.GetGcsServerAddress - 90 total (0 active), CPU time: mean = 4.326 ms, total = 389.298 ms
[state-dump] 	NodeManagerService.grpc_server.ReportWorkerBacklog - 89 total (0 active), CPU time: mean = 3.063 ms, total = 272.584 ms
[state-dump] 	CoreWorkerService.grpc_client.GetCoreWorkerStats - 70 total (0 active), CPU time: mean = 11.537 ms, total = 807.615 ms
[state-dump] 	NodeManager.deadline_timer.record_metrics - 46 total (1 active), CPU time: mean = 56.925 ms, total = 2.619 s
[state-dump] 	NodeManager.deadline_timer.debug_state_dump - 24 total (1 active), CPU time: mean = 317.258 ms, total = 7.614 s
[state-dump] 	ClientConnection.async_read.ReadBufferAsync - 8 total (2 active), CPU time: mean = 57.556 ms, total = 460.449 ms
[state-dump] 	PeriodicalRunner.RunFnPeriodically - 7 total (0 active), CPU time: mean = 243.532 us, total = 1.705 ms
[state-dump] 	NodeManager.deadline_timer.print_event_loop_stats - 4 total (1 active, 1 running), CPU time: mean = 21.522 ms, total = 86.090 ms
[state-dump] 	InternalPubSubGcsService.grpc_client.GcsSubscriberCommandBatch - 3 total (0 active), CPU time: mean = 68.436 us, total = 205.309 us
[state-dump] 	NodeManagerService.grpc_server.GetSystemConfig - 2 total (0 active), CPU time: mean = 12.578 ms, total = 25.156 ms
[state-dump] 	InternalPubSubGcsService.grpc_client.GcsSubscriberPoll - 2 total (1 active), CPU time: mean = 77.900 ms, total = 155.801 ms
[state-dump] 	AgentManagerService.grpc_server.RegisterAgent - 1 total (0 active), CPU time: mean = 367.585 ms, total = 367.585 ms
[state-dump] 	ObjectManager.ObjectDeleted - 1 total (0 active), CPU time: mean = 10.076 ms, total = 10.076 ms
[state-dump] 	NodeInfoGcsService.grpc_client.RegisterNode - 1 total (0 active), CPU time: mean = 486.057 us, total = 486.057 us
[state-dump] 	ClientConnection.async_write.DoAsyncWrites - 1 total (0 active), CPU time: mean = 4.937 ms, total = 4.937 ms
[state-dump] 	Subscriber.HandlePublishedMessage_GCS_JOB_CHANNEL - 1 total (0 active), CPU time: mean = 70.129 ms, total = 70.129 ms
[state-dump] 	ObjectManager.ObjectAdded - 1 total (0 active), CPU time: mean = 65.150 ms, total = 65.150 ms
[state-dump] 	NodeInfoGcsService.grpc_client.GetAllNodeInfo - 1 total (0 active), CPU time: mean = 85.179 us, total = 85.179 us
[state-dump] 	JobInfoGcsService.grpc_client.AddJob - 1 total (0 active), CPU time: mean = 20.046 ms, total = 20.046 ms
[state-dump] 	JobInfoGcsService.grpc_client.GetAllJobInfo - 1 total (0 active), CPU time: mean = 15.018 us, total = 15.018 us
[state-dump] 	NodeInfoGcsService.grpc_client.GetInternalConfig - 1 total (0 active), CPU time: mean = 34.694 ms, total = 34.694 ms
[state-dump] 
[state-dump] NodeManager:
[state-dump] Node ID: 7562cb0081c73f4ed2ac21d1956887bd794b724f1b8c157f4e02d603
[state-dump] Node name: 10.140.1.109
[state-dump] InitialConfigResources: {CPU: 1280000, node:10.140.1.109: 10000, GPU: 80000, object_store_memory: 2000000000000000, memory: 8693891676160000, accelerator_type:A100: 10000}
[state-dump] ClusterTaskManager:
[state-dump] ========== Node: 7562cb0081c73f4ed2ac21d1956887bd794b724f1b8c157f4e02d603 =================
[state-dump] Infeasible queue length: 0
[state-dump] Schedule queue length: 0
[state-dump] Dispatch queue length: 0
[state-dump] num_waiting_for_resource: 0
[state-dump] num_waiting_for_plasma_memory: 0
[state-dump] num_waiting_for_remote_node_resources: 0
[state-dump] num_worker_not_started_by_job_config_not_exist: 0
[state-dump] num_worker_not_started_by_registration_timeout: 0
[state-dump] num_worker_not_started_by_process_rate_limit: 0
[state-dump] num_tasks_waiting_for_workers: 0
[state-dump] num_cancelled_tasks: 0
[state-dump] cluster_resource_scheduler state: 
[state-dump] Local id: -110938788179330527 Local resources: {object_store_memory: [2000000000000000]/[2000000000000000], node:10.140.1.109: [10000]/[10000], memory: [8693891676160000]/[8693891676160000], CPU: [1280000]/[1280000], accelerator_type:A100: [10000]/[10000], GPU: [10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000]/[10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000]}node id: -110938788179330527{object_store_memory: 2000000000000000/2000000000000000, node:10.140.1.109: 10000/10000, GPU: 80000/80000, CPU: 1280000/1280000, memory: 8693891676160000/8693891676160000, accelerator_type:A100: 10000/10000}
[state-dump] Waiting tasks size: 0
[state-dump] Number of executing tasks: 0
[state-dump] Number of pinned task arguments: 0
[state-dump] Number of total spilled tasks: 0
[state-dump] Number of spilled waiting tasks: 0
[state-dump] Number of spilled unschedulable tasks: 0
[state-dump] Resource usage {
[state-dump] }
[state-dump] Running tasks by scheduling class:
[state-dump] ==================================================
[state-dump] 
[state-dump] ClusterResources:
[state-dump] LocalObjectManager:
[state-dump] - num pinned objects: 0
[state-dump] - pinned objects size: 0
[state-dump] - num objects pending restore: 0
[state-dump] - num objects pending spill: 0
[state-dump] - num bytes pending spill: 0
[state-dump] - cumulative spill requests: 0
[state-dump] - cumulative restore requests: 0
[state-dump] 
[state-dump] ObjectManager:
[state-dump] - num local objects: 0
[state-dump] - num unfulfilled push requests: 0
[state-dump] - num pull requests: 0
[state-dump] - num chunks received total: 0
[state-dump] - num chunks received failed (all): 0
[state-dump] - num chunks received failed / cancelled: 0
[state-dump] - num chunks received failed / plasma error: 0
[state-dump] Event stats:
[state-dump] Global stats: 0 total (0 active)
[state-dump] Queueing time: mean = -nan s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] Execution time:  mean = -nan s, total = 0.000 s
[state-dump] Event stats:
[state-dump] PushManager:
[state-dump] - num pushes in flight: 0
[state-dump] - num chunks in flight: 0
[state-dump] - num chunks remaining: 0
[state-dump] - max chunks allowed: 409
[state-dump] OwnershipBasedObjectDirectory:
[state-dump] - num listeners: 0
[state-dump] - cumulative location updates: 368
[state-dump] - num location updates per second: 0.000
[state-dump] - num location lookups per second: 0.000
[state-dump] - num locations added per second: 0.000
[state-dump] - num locations removed per second: 0.000
[state-dump] BufferPool:
[state-dump] - create buffer state map size: 0
[state-dump] PullManager:
[state-dump] - num bytes available for pulled objects: 200000000000
[state-dump] - num bytes being pulled (all): 0
[state-dump] - num bytes being pulled / pinned: 0
[state-dump] - num get request bundles: 0
[state-dump] - num wait request bundles: 0
[state-dump] - num task request bundles: 0
[state-dump] - first get request bundle: N/A
[state-dump] - first wait request bundle: N/A
[state-dump] - first task request bundle: N/A
[state-dump] - num objects queued: 0
[state-dump] - num objects actively pulled (all): 0
[state-dump] - num objects actively pulled / pinned: 0
[state-dump] - num bundles being pulled: 0
[state-dump] - num pull retries: 0
[state-dump] - max timeout seconds: 0
[state-dump] - max timeout request is already processed. No entry.
[state-dump] 
[state-dump] WorkerPool:
[state-dump] - registered jobs: 1
[state-dump] - process_failed_job_config_missing: 0
[state-dump] - process_failed_rate_limited: 0
[state-dump] - process_failed_pending_registration: 0
[state-dump] - process_failed_runtime_env_setup_failed: 0
[state-dump] - num JAVA workers: 0
[state-dump] - num JAVA drivers: 0
[state-dump] - num object spill callbacks queued: 0
[state-dump] - num object restore queued: 0
[state-dump] - num util functions queued: 0
[state-dump] - num PYTHON workers: 0
[state-dump] - num PYTHON drivers: 1
[state-dump] - num object spill callbacks queued: 0
[state-dump] - num object restore queued: 0
[state-dump] - num util functions queued: 0
[state-dump] - num idle workers: 0
[state-dump] TaskDependencyManager:
[state-dump] - task deps map size: 0
[state-dump] - get req map size: 0
[state-dump] - wait req map size: 0
[state-dump] - local objects map size: 0
[state-dump] WaitManager:
[state-dump] - num active wait requests: 0
[state-dump] Subscriber:
[state-dump] Channel WORKER_REF_REMOVED_CHANNEL
[state-dump] - cumulative subscribe requests: 0
[state-dump] - cumulative unsubscribe requests: 0
[state-dump] - active subscribed publishers: 0
[state-dump] - cumulative published messages: 0
[state-dump] - cumulative processed messages: 0
[state-dump] Channel WORKER_OBJECT_EVICTION
[state-dump] - cumulative subscribe requests: 0
[state-dump] - cumulative unsubscribe requests: 0
[state-dump] - active subscribed publishers: 0
[state-dump] - cumulative published messages: 0
[state-dump] - cumulative processed messages: 0
[state-dump] Channel WORKER_OBJECT_LOCATIONS_CHANNEL
[state-dump] - cumulative subscribe requests: 0
[state-dump] - cumulative unsubscribe requests: 0
[state-dump] - active subscribed publishers: 0
[state-dump] - cumulative published messages: 0
[state-dump] - cumulative processed messages: 0
[state-dump] num async plasma notifications: 0
[state-dump] Remote node managers: 
[state-dump] Event stats:
[state-dump] Global stats: 7954 total (11 active)
[state-dump] Queueing time: mean = 33.286 ms, max = 3.975 s, min = -0.067 s, total = 264.754 s
[state-dump] Execution time:  mean = 4.630 ms, total = 36.826 s
[state-dump] Event stats:
[state-dump] 	ObjectManager.UpdateAvailableMemory - 1966 total (0 active), CPU time: mean = 842.248 us, total = 1.656 s
[state-dump] 	NodeManagerService.grpc_server.RequestResourceReport - 1700 total (0 active), CPU time: mean = 2.920 ms, total = 4.965 s
[state-dump] 	NodeManagerService.grpc_server.UpdateResourceUsage - 1695 total (0 active), CPU time: mean = 2.468 ms, total = 4.183 s
[state-dump] 	RayletWorkerPool.deadline_timer.kill_idle_workers - 1001 total (1 active), CPU time: mean = 2.543 ms, total = 2.545 s
[state-dump] 	NodeManagerService.grpc_server.GetResourceLoad - 228 total (0 active), CPU time: mean = 7.299 ms, total = 1.664 s
[state-dump] 	HeartbeatInfoGcsService.grpc_client.ReportHeartbeat - 215 total (1 active), CPU time: mean = 3.477 ms, total = 747.585 ms
[state-dump] 	GcsClient.deadline_timer.check_gcs_connection - 214 total (1 active), CPU time: mean = 3.524 ms, total = 754.191 ms
[state-dump] 	UNKNOWN - 214 total (1 active), CPU time: mean = 12.735 ms, total = 2.725 s
[state-dump] 	NodeManager.deadline_timer.flush_free_objects - 213 total (1 active), CPU time: mean = 3.449 ms, total = 734.687 ms
[state-dump] 	NodeManagerService.grpc_server.GetNodeStats - 153 total (0 active), CPU time: mean = 25.143 ms, total = 3.847 s
[state-dump] 	NodeManagerService.grpc_server.GetGcsServerAddress - 90 total (0 active), CPU time: mean = 4.326 ms, total = 389.298 ms
[state-dump] 	NodeManagerService.grpc_server.ReportWorkerBacklog - 89 total (0 active), CPU time: mean = 3.063 ms, total = 272.584 ms
[state-dump] 	CoreWorkerService.grpc_client.GetCoreWorkerStats - 70 total (0 active), CPU time: mean = 11.537 ms, total = 807.615 ms
[state-dump] 	NodeManager.deadline_timer.record_metrics - 46 total (1 active), CPU time: mean = 56.925 ms, total = 2.619 s
[state-dump] 	NodeManager.deadline_timer.debug_state_dump - 24 total (1 active), CPU time: mean = 317.258 ms, total = 7.614 s
[state-dump] 	ClientConnection.async_read.ReadBufferAsync - 8 total (2 active), CPU time: mean = 57.556 ms, total = 460.449 ms
[state-dump] 	PeriodicalRunner.RunFnPeriodically - 7 total (0 active), CPU time: mean = 243.532 us, total = 1.705 ms
[state-dump] 	NodeManager.deadline_timer.print_event_loop_stats - 4 total (1 active, 1 running), CPU time: mean = 21.522 ms, total = 86.090 ms
[state-dump] 	InternalPubSubGcsService.grpc_client.GcsSubscriberCommandBatch - 3 total (0 active), CPU time: mean = 68.436 us, total = 205.309 us
[state-dump] 	NodeManagerService.grpc_server.GetSystemConfig - 2 total (0 active), CPU time: mean = 12.578 ms, total = 25.156 ms
[state-dump] 	InternalPubSubGcsService.grpc_client.GcsSubscriberPoll - 2 total (1 active), CPU time: mean = 77.900 ms, total = 155.801 ms
[state-dump] 	AgentManagerService.grpc_server.RegisterAgent - 1 total (0 active), CPU time: mean = 367.585 ms, total = 367.585 ms
[state-dump] 	ObjectManager.ObjectDeleted - 1 total (0 active), CPU time: mean = 10.076 ms, total = 10.076 ms
[state-dump] 	NodeInfoGcsService.grpc_client.RegisterNode - 1 total (0 active), CPU time: mean = 486.057 us, total = 486.057 us
[state-dump] 	ClientConnection.async_write.DoAsyncWrites - 1 total (0 active), CPU time: mean = 4.937 ms, total = 4.937 ms
[state-dump] 	Subscriber.HandlePublishedMessage_GCS_JOB_CHANNEL - 1 total (0 active), CPU time: mean = 70.129 ms, total = 70.129 ms
[state-dump] 	ObjectManager.ObjectAdded - 1 total (0 active), CPU time: mean = 65.150 ms, total = 65.150 ms
[state-dump] 	NodeInfoGcsService.grpc_client.GetAllNodeInfo - 1 total (0 active), CPU time: mean = 85.179 us, total = 85.179 us
[state-dump] 	JobInfoGcsService.grpc_client.AddJob - 1 total (0 active), CPU time: mean = 20.046 ms, total = 20.046 ms
[state-dump] 	JobInfoGcsService.grpc_client.GetAllJobInfo - 1 total (0 active), CPU time: mean = 15.018 us, total = 15.018 us
[state-dump] 	NodeInfoGcsService.grpc_client.GetInternalConfig - 1 total (0 active), CPU time: mean = 34.694 ms, total = 34.694 ms
[state-dump] DebugString() time ms: 0
[state-dump] 
[state-dump] 
[2022-06-20 22:49:00,375 I 128931 128931] (raylet) node_manager.cc:579: New job has started. Job id 02000000 Driver pid 129466 is dead: 0 driver address: 10.140.1.109
[2022-06-20 22:49:00,375 I 128931 128931] (raylet) worker_pool.cc:635: Job 02000000 already started in worker pool.
[2022-06-20 22:49:59,045 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 130458, the token 0
[2022-06-20 22:49:59,107 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 130459, the token 1
[2022-06-20 22:49:59,110 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 130460, the token 2
[2022-06-20 22:49:59,111 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 130461, the token 3
[2022-06-20 22:49:59,113 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 130462, the token 4
[2022-06-20 22:49:59,952 I 128931 128962] (raylet) store.cc:546: ========== Plasma store: =================
Current usage: 0.0536805 / 200 GB
- num bytes created total: 53680521
0 pending objects of total size 0MB
- objects spillable: 5
- bytes spillable: 53680505
- objects unsealed: 0
- bytes unsealed: 0
- objects in use: 5
- bytes in use: 53680505
- objects evictable: 0
- bytes evictable: 0

- objects created by worker: 5
- bytes created by worker: 53680505
- objects restored: 0
- bytes restored: 0
- objects received: 0
- bytes received: 0
- objects errored: 0
- bytes errored: 0

[2022-06-20 22:50:00,049 I 128931 128931] (raylet) node_manager.cc:538: [state-dump] Event stats:
[state-dump] 
[state-dump] 
[state-dump] Global stats: 10326 total (12 active)
[state-dump] Queueing time: mean = 34.375 ms, max = 3.975 s, min = -0.067 s, total = 354.958 s
[state-dump] Execution time:  mean = 4.412 ms, total = 45.559 s
[state-dump] Event stats:
[state-dump] 	ObjectManager.UpdateAvailableMemory - 2470 total (0 active), CPU time: mean = 776.472 us, total = 1.918 s
[state-dump] 	NodeManagerService.grpc_server.RequestResourceReport - 2162 total (0 active), CPU time: mean = 2.537 ms, total = 5.485 s
[state-dump] 	NodeManagerService.grpc_server.UpdateResourceUsage - 2155 total (1 active), CPU time: mean = 2.182 ms, total = 4.702 s
[state-dump] 	RayletWorkerPool.deadline_timer.kill_idle_workers - 1259 total (1 active), CPU time: mean = 2.307 ms, total = 2.904 s
[state-dump] 	NodeManagerService.grpc_server.GetResourceLoad - 286 total (0 active), CPU time: mean = 6.648 ms, total = 1.901 s
[state-dump] 	HeartbeatInfoGcsService.grpc_client.ReportHeartbeat - 269 total (0 active), CPU time: mean = 2.856 ms, total = 768.219 ms
[state-dump] 	GcsClient.deadline_timer.check_gcs_connection - 268 total (1 active), CPU time: mean = 3.314 ms, total = 888.152 ms
[state-dump] 	UNKNOWN - 268 total (1 active), CPU time: mean = 12.834 ms, total = 3.439 s
[state-dump] 	NodeManager.deadline_timer.flush_free_objects - 267 total (1 active), CPU time: mean = 3.203 ms, total = 855.168 ms
[state-dump] 	NodeManagerService.grpc_server.GetGcsServerAddress - 203 total (0 active), CPU time: mean = 4.574 ms, total = 928.603 ms
[state-dump] 	NodeManagerService.grpc_server.GetNodeStats - 200 total (0 active), CPU time: mean = 31.879 ms, total = 6.376 s
[state-dump] 	NodeManagerService.grpc_server.ReportWorkerBacklog - 200 total (0 active), CPU time: mean = 2.576 ms, total = 515.151 ms
[state-dump] 	CoreWorkerService.grpc_client.GetCoreWorkerStats - 163 total (0 active), CPU time: mean = 7.203 ms, total = 1.174 s
[state-dump] 	NodeManager.deadline_timer.record_metrics - 57 total (1 active), CPU time: mean = 57.887 ms, total = 3.300 s
[state-dump] 	NodeManager.deadline_timer.debug_state_dump - 29 total (1 active), CPU time: mean = 273.672 ms, total = 7.936 s
[state-dump] 	ClientConnection.async_read.ReadBufferAsync - 14 total (2 active), CPU time: mean = 50.947 ms, total = 713.261 ms
[state-dump] 	PeriodicalRunner.RunFnPeriodically - 7 total (0 active), CPU time: mean = 243.532 us, total = 1.705 ms
[state-dump] 	ObjectManager.ObjectAdded - 7 total (0 active), CPU time: mean = 80.834 ms, total = 565.839 ms
[state-dump] 	NodeManagerService.grpc_server.RequestWorkerLease - 5 total (0 active), CPU time: mean = 48.840 ms, total = 244.201 ms
[state-dump] 	NodeManager.deadline_timer.print_event_loop_stats - 5 total (1 active, 1 running), CPU time: mean = 18.303 ms, total = 91.516 ms
[state-dump] 	NodeManagerService.grpc_server.PinObjectIDs - 5 total (0 active), CPU time: mean = 14.570 ms, total = 72.849 ms
[state-dump] 	InternalPubSubGcsService.grpc_client.GcsSubscriberCommandBatch - 3 total (0 active), CPU time: mean = 68.436 us, total = 205.309 us
[state-dump] 	InternalPubSubGcsService.grpc_client.GcsSubscriberPoll - 3 total (1 active), CPU time: mean = 68.672 ms, total = 206.017 ms
[state-dump] 	CoreWorkerService.grpc_client.UpdateObjectLocationBatch - 3 total (0 active), CPU time: mean = 4.949 ms, total = 14.846 ms
[state-dump] 	ObjectManager.ObjectDeleted - 2 total (0 active), CPU time: mean = 7.597 ms, total = 15.195 ms
[state-dump] 	CoreWorkerService.grpc_client.PubsubCommandBatch - 2 total (0 active), CPU time: mean = 18.468 us, total = 36.936 us
[state-dump] 	Subscriber.HandlePublishedMessage_GCS_JOB_CHANNEL - 2 total (0 active), CPU time: mean = 35.076 ms, total = 70.152 ms
[state-dump] 	NodeManagerService.grpc_server.GetSystemConfig - 2 total (0 active), CPU time: mean = 12.578 ms, total = 25.156 ms
[state-dump] 	JobInfoGcsService.grpc_client.AddJob - 2 total (0 active), CPU time: mean = 17.572 ms, total = 35.143 ms
[state-dump] 	ClientConnection.async_write.DoAsyncWrites - 2 total (0 active), CPU time: mean = 4.915 ms, total = 9.830 ms
[state-dump] 	NodeInfoGcsService.grpc_client.RegisterNode - 1 total (0 active), CPU time: mean = 486.057 us, total = 486.057 us
[state-dump] 	CoreWorkerService.grpc_client.PubsubLongPolling - 1 total (1 active), CPU time: mean = 0.000 s, total = 0.000 s
[state-dump] 	NodeInfoGcsService.grpc_client.GetInternalConfig - 1 total (0 active), CPU time: mean = 34.694 ms, total = 34.694 ms
[state-dump] 	AgentManagerService.grpc_server.RegisterAgent - 1 total (0 active), CPU time: mean = 367.585 ms, total = 367.585 ms
[state-dump] 	NodeInfoGcsService.grpc_client.GetAllNodeInfo - 1 total (0 active), CPU time: mean = 85.179 us, total = 85.179 us
[state-dump] 	JobInfoGcsService.grpc_client.GetAllJobInfo - 1 total (0 active), CPU time: mean = 15.018 us, total = 15.018 us
[state-dump] 
[state-dump] NodeManager:
[state-dump] Node ID: 7562cb0081c73f4ed2ac21d1956887bd794b724f1b8c157f4e02d603
[state-dump] Node name: 10.140.1.109
[state-dump] InitialConfigResources: {CPU: 1280000, node:10.140.1.109: 10000, GPU: 80000, object_store_memory: 2000000000000000, memory: 8693891676160000, accelerator_type:A100: 10000}
[state-dump] ClusterTaskManager:
[state-dump] ========== Node: 7562cb0081c73f4ed2ac21d1956887bd794b724f1b8c157f4e02d603 =================
[state-dump] Infeasible queue length: 0
[state-dump] Schedule queue length: 0
[state-dump] Dispatch queue length: 5
[state-dump] num_waiting_for_resource: 0
[state-dump] num_waiting_for_plasma_memory: 0
[state-dump] num_waiting_for_remote_node_resources: 0
[state-dump] num_worker_not_started_by_job_config_not_exist: 0
[state-dump] num_worker_not_started_by_registration_timeout: 0
[state-dump] num_worker_not_started_by_process_rate_limit: 0
[state-dump] num_tasks_waiting_for_workers: 5
[state-dump] num_cancelled_tasks: 0
[state-dump] cluster_resource_scheduler state: 
[state-dump] Local id: -110938788179330527 Local resources: {object_store_memory: [1999463194950000]/[2000000000000000], node:10.140.1.109: [10000]/[10000], memory: [8693891676160000]/[8693891676160000], CPU: [1280000]/[1280000], accelerator_type:A100: [10000]/[10000], GPU: [10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000]/[10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000]}node id: -110938788179330527{object_store_memory: 1999463194950000/2000000000000000, node:10.140.1.109: 10000/10000, CPU: 1280000/1280000, memory: 8693891676160000/8693891676160000, accelerator_type:A100: 10000/10000, GPU: 80000/80000}
[state-dump] Waiting tasks size: 0
[state-dump] Number of executing tasks: 5
[state-dump] Number of pinned task arguments: 0
[state-dump] Number of total spilled tasks: 0
[state-dump] Number of spilled waiting tasks: 0
[state-dump] Number of spilled unschedulable tasks: 0
[state-dump] Resource usage {
[state-dump] }
[state-dump] Running tasks by scheduling class:
[state-dump]     - {depth=1 function_descriptor={type=PythonFunctionDescriptor, module_name=alpa.pipeline_parallel.stage_profiling, class_name=CompileWorker, function_name=__init__, function_hash=dc0b8d10ee7a46b8bb325dda765e75f7} scheduling_strategy=default_scheduling_strategy {
[state-dump] }
[state-dump]  resource_set={}}: 5/18446744073709551615
[state-dump] ==================================================
[state-dump] 
[state-dump] ClusterResources:
[state-dump] LocalObjectManager:
[state-dump] - num pinned objects: 5
[state-dump] - pinned objects size: 53680505
[state-dump] - num objects pending restore: 0
[state-dump] - num objects pending spill: 0
[state-dump] - num bytes pending spill: 0
[state-dump] - cumulative spill requests: 0
[state-dump] - cumulative restore requests: 0
[state-dump] 
[state-dump] ObjectManager:
[state-dump] - num local objects: 5
[state-dump] - num unfulfilled push requests: 0
[state-dump] - num pull requests: 0
[state-dump] - num chunks received total: 0
[state-dump] - num chunks received failed (all): 0
[state-dump] - num chunks received failed / cancelled: 0
[state-dump] - num chunks received failed / plasma error: 0
[state-dump] Event stats:
[state-dump] Global stats: 0 total (0 active)
[state-dump] Queueing time: mean = -nan s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] Execution time:  mean = -nan s, total = 0.000 s
[state-dump] Event stats:
[state-dump] PushManager:
[state-dump] - num pushes in flight: 0
[state-dump] - num chunks in flight: 0
[state-dump] - num chunks remaining: 0
[state-dump] - max chunks allowed: 409
[state-dump] OwnershipBasedObjectDirectory:
[state-dump] - num listeners: 0
[state-dump] - cumulative location updates: 368
[state-dump] - num location updates per second: 0.000
[state-dump] - num location lookups per second: 0.000
[state-dump] - num locations added per second: 0.000
[state-dump] - num locations removed per second: 0.000
[state-dump] BufferPool:
[state-dump] - create buffer state map size: 0
[state-dump] PullManager:
[state-dump] - num bytes available for pulled objects: 199946319495
[state-dump] - num bytes being pulled (all): 0
[state-dump] - num bytes being pulled / pinned: 0
[state-dump] - num get request bundles: 0
[state-dump] - num wait request bundles: 0
[state-dump] - num task request bundles: 0
[state-dump] - first get request bundle: N/A
[state-dump] - first wait request bundle: N/A
[state-dump] - first task request bundle: N/A
[state-dump] - num objects queued: 0
[state-dump] - num objects actively pulled (all): 0
[state-dump] - num objects actively pulled / pinned: 0
[state-dump] - num bundles being pulled: 0
[state-dump] - num pull retries: 0
[state-dump] - max timeout seconds: 0
[state-dump] - max timeout request is already processed. No entry.
[state-dump] 
[state-dump] WorkerPool:
[state-dump] - registered jobs: 2
[state-dump] - process_failed_job_config_missing: 0
[state-dump] - process_failed_rate_limited: 0
[state-dump] - process_failed_pending_registration: 0
[state-dump] - process_failed_runtime_env_setup_failed: 0
[state-dump] - num JAVA workers: 0
[state-dump] - num JAVA drivers: 0
[state-dump] - num object spill callbacks queued: 0
[state-dump] - num object restore queued: 0
[state-dump] - num util functions queued: 0
[state-dump] - num PYTHON workers: 0
[state-dump] - num PYTHON drivers: 2
[state-dump] - num object spill callbacks queued: 0
[state-dump] - num object restore queued: 0
[state-dump] - num util functions queued: 0
[state-dump] - num idle workers: 0
[state-dump] TaskDependencyManager:
[state-dump] - task deps map size: 0
[state-dump] - get req map size: 0
[state-dump] - wait req map size: 0
[state-dump] - local objects map size: 5
[state-dump] WaitManager:
[state-dump] - num active wait requests: 0
[state-dump] Subscriber:
[state-dump] Channel WORKER_REF_REMOVED_CHANNEL
[state-dump] - cumulative subscribe requests: 0
[state-dump] - cumulative unsubscribe requests: 0
[state-dump] - active subscribed publishers: 0
[state-dump] - cumulative published messages: 0
[state-dump] - cumulative processed messages: 0
[state-dump] Channel WORKER_OBJECT_EVICTION
[state-dump] - cumulative subscribe requests: 5
[state-dump] - cumulative unsubscribe requests: 0
[state-dump] - active subscribed publishers: 1
[state-dump] - cumulative published messages: 0
[state-dump] - cumulative processed messages: 0
[state-dump] Channel WORKER_OBJECT_LOCATIONS_CHANNEL
[state-dump] - cumulative subscribe requests: 0
[state-dump] - cumulative unsubscribe requests: 0
[state-dump] - active subscribed publishers: 0
[state-dump] - cumulative published messages: 0
[state-dump] - cumulative processed messages: 0
[state-dump] num async plasma notifications: 0
[state-dump] Remote node managers: 
[state-dump] Event stats:
[state-dump] Global stats: 10326 total (12 active)
[state-dump] Queueing time: mean = 34.375 ms, max = 3.975 s, min = -0.067 s, total = 354.958 s
[state-dump] Execution time:  mean = 4.412 ms, total = 45.559 s
[state-dump] Event stats:
[state-dump] 	ObjectManager.UpdateAvailableMemory - 2470 total (0 active), CPU time: mean = 776.472 us, total = 1.918 s
[state-dump] 	NodeManagerService.grpc_server.RequestResourceReport - 2162 total (0 active), CPU time: mean = 2.537 ms, total = 5.485 s
[state-dump] 	NodeManagerService.grpc_server.UpdateResourceUsage - 2155 total (1 active), CPU time: mean = 2.182 ms, total = 4.702 s
[state-dump] 	RayletWorkerPool.deadline_timer.kill_idle_workers - 1259 total (1 active), CPU time: mean = 2.307 ms, total = 2.904 s
[state-dump] 	NodeManagerService.grpc_server.GetResourceLoad - 286 total (0 active), CPU time: mean = 6.648 ms, total = 1.901 s
[state-dump] 	HeartbeatInfoGcsService.grpc_client.ReportHeartbeat - 269 total (0 active), CPU time: mean = 2.856 ms, total = 768.219 ms
[state-dump] 	GcsClient.deadline_timer.check_gcs_connection - 268 total (1 active), CPU time: mean = 3.314 ms, total = 888.152 ms
[state-dump] 	UNKNOWN - 268 total (1 active), CPU time: mean = 12.834 ms, total = 3.439 s
[state-dump] 	NodeManager.deadline_timer.flush_free_objects - 267 total (1 active), CPU time: mean = 3.203 ms, total = 855.168 ms
[state-dump] 	NodeManagerService.grpc_server.GetGcsServerAddress - 203 total (0 active), CPU time: mean = 4.574 ms, total = 928.603 ms
[state-dump] 	NodeManagerService.grpc_server.GetNodeStats - 200 total (0 active), CPU time: mean = 31.879 ms, total = 6.376 s
[state-dump] 	NodeManagerService.grpc_server.ReportWorkerBacklog - 200 total (0 active), CPU time: mean = 2.576 ms, total = 515.151 ms
[state-dump] 	CoreWorkerService.grpc_client.GetCoreWorkerStats - 163 total (0 active), CPU time: mean = 7.203 ms, total = 1.174 s
[state-dump] 	NodeManager.deadline_timer.record_metrics - 57 total (1 active), CPU time: mean = 57.887 ms, total = 3.300 s
[state-dump] 	NodeManager.deadline_timer.debug_state_dump - 29 total (1 active), CPU time: mean = 273.672 ms, total = 7.936 s
[state-dump] 	ClientConnection.async_read.ReadBufferAsync - 14 total (2 active), CPU time: mean = 50.947 ms, total = 713.261 ms
[state-dump] 	PeriodicalRunner.RunFnPeriodically - 7 total (0 active), CPU time: mean = 243.532 us, total = 1.705 ms
[state-dump] 	ObjectManager.ObjectAdded - 7 total (0 active), CPU time: mean = 80.834 ms, total = 565.839 ms
[state-dump] 	NodeManagerService.grpc_server.RequestWorkerLease - 5 total (0 active), CPU time: mean = 48.840 ms, total = 244.201 ms
[state-dump] 	NodeManager.deadline_timer.print_event_loop_stats - 5 total (1 active, 1 running), CPU time: mean = 18.303 ms, total = 91.516 ms
[state-dump] 	NodeManagerService.grpc_server.PinObjectIDs - 5 total (0 active), CPU time: mean = 14.570 ms, total = 72.849 ms
[state-dump] 	InternalPubSubGcsService.grpc_client.GcsSubscriberCommandBatch - 3 total (0 active), CPU time: mean = 68.436 us, total = 205.309 us
[state-dump] 	InternalPubSubGcsService.grpc_client.GcsSubscriberPoll - 3 total (1 active), CPU time: mean = 68.672 ms, total = 206.017 ms
[state-dump] 	CoreWorkerService.grpc_client.UpdateObjectLocationBatch - 3 total (0 active), CPU time: mean = 4.949 ms, total = 14.846 ms
[state-dump] 	ObjectManager.ObjectDeleted - 2 total (0 active), CPU time: mean = 7.597 ms, total = 15.195 ms
[state-dump] 	CoreWorkerService.grpc_client.PubsubCommandBatch - 2 total (0 active), CPU time: mean = 18.468 us, total = 36.936 us
[state-dump] 	Subscriber.HandlePublishedMessage_GCS_JOB_CHANNEL - 2 total (0 active), CPU time: mean = 35.076 ms, total = 70.152 ms
[state-dump] 	NodeManagerService.grpc_server.GetSystemConfig - 2 total (0 active), CPU time: mean = 12.578 ms, total = 25.156 ms
[state-dump] 	JobInfoGcsService.grpc_client.AddJob - 2 total (0 active), CPU time: mean = 17.572 ms, total = 35.143 ms
[state-dump] 	ClientConnection.async_write.DoAsyncWrites - 2 total (0 active), CPU time: mean = 4.915 ms, total = 9.830 ms
[state-dump] 	NodeInfoGcsService.grpc_client.RegisterNode - 1 total (0 active), CPU time: mean = 486.057 us, total = 486.057 us
[state-dump] 	CoreWorkerService.grpc_client.PubsubLongPolling - 1 total (1 active), CPU time: mean = 0.000 s, total = 0.000 s
[state-dump] 	NodeInfoGcsService.grpc_client.GetInternalConfig - 1 total (0 active), CPU time: mean = 34.694 ms, total = 34.694 ms
[state-dump] 	AgentManagerService.grpc_server.RegisterAgent - 1 total (0 active), CPU time: mean = 367.585 ms, total = 367.585 ms
[state-dump] 	NodeInfoGcsService.grpc_client.GetAllNodeInfo - 1 total (0 active), CPU time: mean = 85.179 us, total = 85.179 us
[state-dump] 	JobInfoGcsService.grpc_client.GetAllJobInfo - 1 total (0 active), CPU time: mean = 15.018 us, total = 15.018 us
[state-dump] DebugString() time ms: 11
[state-dump] 
[state-dump] 
[2022-06-20 22:51:00,001 I 128931 128962] (raylet) store.cc:546: ========== Plasma store: =================
Current usage: 0.0536805 / 200 GB
- num bytes created total: 53680561
0 pending objects of total size 0MB
- objects spillable: 5
- bytes spillable: 53680505
- objects unsealed: 0
- bytes unsealed: 0
- objects in use: 5
- bytes in use: 53680505
- objects evictable: 0
- bytes evictable: 0

- objects created by worker: 5
- bytes created by worker: 53680505
- objects restored: 0
- bytes restored: 0
- objects received: 0
- bytes received: 0
- objects errored: 0
- bytes errored: 0

[2022-06-20 22:51:00,307 I 128931 128931] (raylet) node_manager.cc:538: [state-dump] Event stats:
[state-dump] 
[state-dump] 
[state-dump] Global stats: 12760 total (16 active)
[state-dump] Queueing time: mean = 42.005 ms, max = 3.975 s, min = -0.067 s, total = 535.983 s
[state-dump] Execution time:  mean = 4.470 ms, total = 57.032 s
[state-dump] Event stats:
[state-dump] 	ObjectManager.UpdateAvailableMemory - 2924 total (0 active), CPU time: mean = 901.602 us, total = 2.636 s
[state-dump] 	NodeManagerService.grpc_server.RequestResourceReport - 2548 total (0 active), CPU time: mean = 2.513 ms, total = 6.404 s
[state-dump] 	NodeManagerService.grpc_server.UpdateResourceUsage - 2541 total (0 active), CPU time: mean = 1.958 ms, total = 4.975 s
[state-dump] 	RayletWorkerPool.deadline_timer.kill_idle_workers - 1493 total (1 active), CPU time: mean = 3.072 ms, total = 4.587 s
[state-dump] 	NodeManagerService.grpc_server.GetGcsServerAddress - 415 total (0 active), CPU time: mean = 2.843 ms, total = 1.180 s
[state-dump] 	NodeManagerService.grpc_server.ReportWorkerBacklog - 412 total (0 active), CPU time: mean = 3.101 ms, total = 1.278 s
[state-dump] 	NodeManagerService.grpc_server.GetResourceLoad - 343 total (0 active), CPU time: mean = 6.000 ms, total = 2.058 s
[state-dump] 	CoreWorkerService.grpc_client.GetCoreWorkerStats - 328 total (0 active), CPU time: mean = 7.326 ms, total = 2.403 s
[state-dump] 	HeartbeatInfoGcsService.grpc_client.ReportHeartbeat - 321 total (0 active), CPU time: mean = 4.234 ms, total = 1.359 s
[state-dump] 	UNKNOWN - 319 total (1 active), CPU time: mean = 13.639 ms, total = 4.351 s
[state-dump] 	GcsClient.deadline_timer.check_gcs_connection - 319 total (1 active), CPU time: mean = 3.496 ms, total = 1.115 s
[state-dump] 	NodeManager.deadline_timer.flush_free_objects - 318 total (1 active), CPU time: mean = 3.496 ms, total = 1.112 s
[state-dump] 	NodeManagerService.grpc_server.GetNodeStats - 240 total (0 active), CPU time: mean = 32.294 ms, total = 7.751 s
[state-dump] 	NodeManager.deadline_timer.record_metrics - 68 total (1 active), CPU time: mean = 64.601 ms, total = 4.393 s
[state-dump] 	ClientConnection.async_read.ReadBufferAsync - 59 total (7 active), CPU time: mean = 16.568 ms, total = 977.490 ms
[state-dump] 	NodeManager.deadline_timer.debug_state_dump - 35 total (1 active), CPU time: mean = 243.770 ms, total = 8.532 s
[state-dump] 	ObjectManager.ObjectAdded - 12 total (0 active), CPU time: mean = 57.012 ms, total = 684.139 ms
[state-dump] 	ObjectManager.ObjectDeleted - 7 total (0 active), CPU time: mean = 3.722 ms, total = 26.054 ms
[state-dump] 	ClientConnection.async_write.DoAsyncWrites - 7 total (0 active), CPU time: mean = 1.404 ms, total = 9.831 ms
[state-dump] 	NodeManagerService.grpc_server.GetSystemConfig - 7 total (0 active), CPU time: mean = 4.335 ms, total = 30.345 ms
[state-dump] 	PeriodicalRunner.RunFnPeriodically - 7 total (0 active), CPU time: mean = 243.532 us, total = 1.705 ms
[state-dump] 	NodeManager.deadline_timer.print_event_loop_stats - 6 total (1 active, 1 running), CPU time: mean = 20.432 ms, total = 122.593 ms
[state-dump] 	NodeManagerService.grpc_server.PinObjectIDs - 5 total (0 active), CPU time: mean = 14.570 ms, total = 72.849 ms
[state-dump] 	NodeManagerService.grpc_server.RequestWorkerLease - 5 total (0 active), CPU time: mean = 48.840 ms, total = 244.201 ms
[state-dump] 	CoreWorkerService.grpc_client.UpdateObjectLocationBatch - 3 total (0 active), CPU time: mean = 4.949 ms, total = 14.846 ms
[state-dump] 	InternalPubSubGcsService.grpc_client.GcsSubscriberCommandBatch - 3 total (0 active), CPU time: mean = 68.436 us, total = 205.309 us
[state-dump] 	InternalPubSubGcsService.grpc_client.GcsSubscriberPoll - 3 total (1 active), CPU time: mean = 68.672 ms, total = 206.017 ms
[state-dump] 	CoreWorkerService.grpc_client.PubsubCommandBatch - 2 total (0 active), CPU time: mean = 18.468 us, total = 36.936 us
[state-dump] 	Subscriber.HandlePublishedMessage_GCS_JOB_CHANNEL - 2 total (0 active), CPU time: mean = 35.076 ms, total = 70.152 ms
[state-dump] 	JobInfoGcsService.grpc_client.AddJob - 2 total (0 active), CPU time: mean = 17.572 ms, total = 35.143 ms
[state-dump] 	AgentManagerService.grpc_server.RegisterAgent - 1 total (0 active), CPU time: mean = 367.585 ms, total = 367.585 ms
[state-dump] 	NodeInfoGcsService.grpc_client.RegisterNode - 1 total (0 active), CPU time: mean = 486.057 us, total = 486.057 us
[state-dump] 	NodeInfoGcsService.grpc_client.GetInternalConfig - 1 total (0 active), CPU time: mean = 34.694 ms, total = 34.694 ms
[state-dump] 	NodeInfoGcsService.grpc_client.GetAllNodeInfo - 1 total (0 active), CPU time: mean = 85.179 us, total = 85.179 us
[state-dump] 	JobInfoGcsService.grpc_client.GetAllJobInfo - 1 total (0 active), CPU time: mean = 15.018 us, total = 15.018 us
[state-dump] 	CoreWorkerService.grpc_client.PubsubLongPolling - 1 total (1 active), CPU time: mean = 0.000 s, total = 0.000 s
[state-dump] 
[state-dump] NodeManager:
[state-dump] Node ID: 7562cb0081c73f4ed2ac21d1956887bd794b724f1b8c157f4e02d603
[state-dump] Node name: 10.140.1.109
[state-dump] InitialConfigResources: {CPU: 1280000, node:10.140.1.109: 10000, GPU: 80000, object_store_memory: 2000000000000000, memory: 8693891676160000, accelerator_type:A100: 10000}
[state-dump] ClusterTaskManager:
[state-dump] ========== Node: 7562cb0081c73f4ed2ac21d1956887bd794b724f1b8c157f4e02d603 =================
[state-dump] Infeasible queue length: 0
[state-dump] Schedule queue length: 0
[state-dump] Dispatch queue length: 0
[state-dump] num_waiting_for_resource: 0
[state-dump] num_waiting_for_plasma_memory: 0
[state-dump] num_waiting_for_remote_node_resources: 0
[state-dump] num_worker_not_started_by_job_config_not_exist: 0
[state-dump] num_worker_not_started_by_registration_timeout: 0
[state-dump] num_worker_not_started_by_process_rate_limit: 0
[state-dump] num_tasks_waiting_for_workers: 0
[state-dump] num_cancelled_tasks: 0
[state-dump] cluster_resource_scheduler state: 
[state-dump] Local id: -110938788179330527 Local resources: {object_store_memory: [1999463194950000]/[2000000000000000], node:10.140.1.109: [10000]/[10000], memory: [8693891676160000]/[8693891676160000], CPU: [1280000]/[1280000], accelerator_type:A100: [10000]/[10000], GPU: [10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000]/[10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000]}node id: -110938788179330527{accelerator_type:A100: 10000/10000, CPU: 1280000/1280000, node:10.140.1.109: 10000/10000, GPU: 80000/80000, memory: 8693891676160000/8693891676160000, object_store_memory: 1999463194950000/2000000000000000}
[state-dump] Waiting tasks size: 0
[state-dump] Number of executing tasks: 5
[state-dump] Number of pinned task arguments: 0
[state-dump] Number of total spilled tasks: 0
[state-dump] Number of spilled waiting tasks: 0
[state-dump] Number of spilled unschedulable tasks: 0
[state-dump] Resource usage {
[state-dump]     - (language=PYTHON actor_or_task=CompileWorker.__init__ pid=130462): {}
[state-dump]     - (language=PYTHON actor_or_task=CompileWorker.__init__ pid=130458): {}
[state-dump]     - (language=PYTHON actor_or_task=CompileWorker.__init__ pid=130459): {}
[state-dump]     - (language=PYTHON actor_or_task=CompileWorker.__init__ pid=130461): {}
[state-dump]     - (language=PYTHON actor_or_task=CompileWorker.__init__ pid=130460): {}
[state-dump] }
[state-dump] Running tasks by scheduling class:
[state-dump]     - {depth=1 function_descriptor={type=PythonFunctionDescriptor, module_name=alpa.pipeline_parallel.stage_profiling, class_name=CompileWorker, function_name=__init__, function_hash=dc0b8d10ee7a46b8bb325dda765e75f7} scheduling_strategy=default_scheduling_strategy {
[state-dump] }
[state-dump]  resource_set={}}: 5/18446744073709551615
[state-dump] ==================================================
[state-dump] 
[state-dump] ClusterResources:
[state-dump] LocalObjectManager:
[state-dump] - num pinned objects: 5
[state-dump] - pinned objects size: 53680505
[state-dump] - num objects pending restore: 0
[state-dump] - num objects pending spill: 0
[state-dump] - num bytes pending spill: 0
[state-dump] - cumulative spill requests: 0
[state-dump] - cumulative restore requests: 0
[state-dump] 
[state-dump] ObjectManager:
[state-dump] - num local objects: 5
[state-dump] - num unfulfilled push requests: 0
[state-dump] - num pull requests: 0
[state-dump] - num chunks received total: 0
[state-dump] - num chunks received failed (all): 0
[state-dump] - num chunks received failed / cancelled: 0
[state-dump] - num chunks received failed / plasma error: 0
[state-dump] Event stats:
[state-dump] Global stats: 0 total (0 active)
[state-dump] Queueing time: mean = -nan s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] Execution time:  mean = -nan s, total = 0.000 s
[state-dump] Event stats:
[state-dump] PushManager:
[state-dump] - num pushes in flight: 0
[state-dump] - num chunks in flight: 0
[state-dump] - num chunks remaining: 0
[state-dump] - max chunks allowed: 409
[state-dump] OwnershipBasedObjectDirectory:
[state-dump] - num listeners: 0
[state-dump] - cumulative location updates: 368
[state-dump] - num location updates per second: 0.000
[state-dump] - num location lookups per second: 0.000
[state-dump] - num locations added per second: 0.000
[state-dump] - num locations removed per second: 0.000
[state-dump] BufferPool:
[state-dump] - create buffer state map size: 0
[state-dump] PullManager:
[state-dump] - num bytes available for pulled objects: 199946319495
[state-dump] - num bytes being pulled (all): 0
[state-dump] - num bytes being pulled / pinned: 0
[state-dump] - num get request bundles: 0
[state-dump] - num wait request bundles: 0
[state-dump] - num task request bundles: 0
[state-dump] - first get request bundle: N/A
[state-dump] - first wait request bundle: N/A
[state-dump] - first task request bundle: N/A
[state-dump] - num objects queued: 0
[state-dump] - num objects actively pulled (all): 0
[state-dump] - num objects actively pulled / pinned: 0
[state-dump] - num bundles being pulled: 0
[state-dump] - num pull retries: 0
[state-dump] - max timeout seconds: 0
[state-dump] - max timeout request is already processed. No entry.
[state-dump] 
[state-dump] WorkerPool:
[state-dump] - registered jobs: 2
[state-dump] - process_failed_job_config_missing: 0
[state-dump] - process_failed_rate_limited: 0
[state-dump] - process_failed_pending_registration: 0
[state-dump] - process_failed_runtime_env_setup_failed: 0
[state-dump] - num JAVA workers: 0
[state-dump] - num JAVA drivers: 0
[state-dump] - num object spill callbacks queued: 0
[state-dump] - num object restore queued: 0
[state-dump] - num util functions queued: 0
[state-dump] - num PYTHON workers: 5
[state-dump] - num PYTHON drivers: 2
[state-dump] - num object spill callbacks queued: 0
[state-dump] - num object restore queued: 0
[state-dump] - num util functions queued: 0
[state-dump] - num idle workers: 0
[state-dump] TaskDependencyManager:
[state-dump] - task deps map size: 0
[state-dump] - get req map size: 0
[state-dump] - wait req map size: 0
[state-dump] - local objects map size: 5
[state-dump] WaitManager:
[state-dump] - num active wait requests: 0
[state-dump] Subscriber:
[state-dump] Channel WORKER_REF_REMOVED_CHANNEL
[state-dump] - cumulative subscribe requests: 0
[state-dump] - cumulative unsubscribe requests: 0
[state-dump] - active subscribed publishers: 0
[state-dump] - cumulative published messages: 0
[state-dump] - cumulative processed messages: 0
[state-dump] Channel WORKER_OBJECT_EVICTION
[state-dump] - cumulative subscribe requests: 5
[state-dump] - cumulative unsubscribe requests: 0
[state-dump] - active subscribed publishers: 1
[state-dump] - cumulative published messages: 0
[state-dump] - cumulative processed messages: 0
[state-dump] Channel WORKER_OBJECT_LOCATIONS_CHANNEL
[state-dump] - cumulative subscribe requests: 0
[state-dump] - cumulative unsubscribe requests: 0
[state-dump] - active subscribed publishers: 0
[state-dump] - cumulative published messages: 0
[state-dump] - cumulative processed messages: 0
[state-dump] num async plasma notifications: 0
[state-dump] Remote node managers: 
[state-dump] Event stats:
[state-dump] Global stats: 12769 total (25 active)
[state-dump] Queueing time: mean = 41.975 ms, max = 3.975 s, min = -0.067 s, total = 535.983 s
[state-dump] Execution time:  mean = 4.466 ms, total = 57.032 s
[state-dump] Event stats:
[state-dump] 	ObjectManager.UpdateAvailableMemory - 2924 total (0 active), CPU time: mean = 901.602 us, total = 2.636 s
[state-dump] 	NodeManagerService.grpc_server.RequestResourceReport - 2549 total (1 active), CPU time: mean = 2.513 ms, total = 6.404 s
[state-dump] 	NodeManagerService.grpc_server.UpdateResourceUsage - 2541 total (0 active), CPU time: mean = 1.958 ms, total = 4.975 s
[state-dump] 	RayletWorkerPool.deadline_timer.kill_idle_workers - 1493 total (1 active), CPU time: mean = 3.072 ms, total = 4.587 s
[state-dump] 	NodeManagerService.grpc_server.GetGcsServerAddress - 422 total (7 active), CPU time: mean = 2.795 ms, total = 1.180 s
[state-dump] 	NodeManagerService.grpc_server.ReportWorkerBacklog - 412 total (0 active), CPU time: mean = 3.101 ms, total = 1.278 s
[state-dump] 	NodeManagerService.grpc_server.GetResourceLoad - 343 total (0 active), CPU time: mean = 6.000 ms, total = 2.058 s
[state-dump] 	CoreWorkerService.grpc_client.GetCoreWorkerStats - 328 total (0 active), CPU time: mean = 7.326 ms, total = 2.403 s
[state-dump] 	HeartbeatInfoGcsService.grpc_client.ReportHeartbeat - 321 total (0 active), CPU time: mean = 4.234 ms, total = 1.359 s
[state-dump] 	UNKNOWN - 319 total (1 active), CPU time: mean = 13.639 ms, total = 4.351 s
[state-dump] 	GcsClient.deadline_timer.check_gcs_connection - 319 total (1 active), CPU time: mean = 3.496 ms, total = 1.115 s
[state-dump] 	NodeManager.deadline_timer.flush_free_objects - 318 total (1 active), CPU time: mean = 3.496 ms, total = 1.112 s
[state-dump] 	NodeManagerService.grpc_server.GetNodeStats - 241 total (1 active), CPU time: mean = 32.160 ms, total = 7.751 s
[state-dump] 	NodeManager.deadline_timer.record_metrics - 68 total (1 active), CPU time: mean = 64.601 ms, total = 4.393 s
[state-dump] 	ClientConnection.async_read.ReadBufferAsync - 59 total (7 active), CPU time: mean = 16.568 ms, total = 977.490 ms
[state-dump] 	NodeManager.deadline_timer.debug_state_dump - 35 total (1 active), CPU time: mean = 243.770 ms, total = 8.532 s
[state-dump] 	ObjectManager.ObjectAdded - 12 total (0 active), CPU time: mean = 57.012 ms, total = 684.139 ms
[state-dump] 	ObjectManager.ObjectDeleted - 7 total (0 active), CPU time: mean = 3.722 ms, total = 26.054 ms
[state-dump] 	ClientConnection.async_write.DoAsyncWrites - 7 total (0 active), CPU time: mean = 1.404 ms, total = 9.831 ms
[state-dump] 	NodeManagerService.grpc_server.GetSystemConfig - 7 total (0 active), CPU time: mean = 4.335 ms, total = 30.345 ms
[state-dump] 	PeriodicalRunner.RunFnPeriodically - 7 total (0 active), CPU time: mean = 243.532 us, total = 1.705 ms
[state-dump] 	NodeManager.deadline_timer.print_event_loop_stats - 6 total (1 active, 1 running), CPU time: mean = 20.432 ms, total = 122.593 ms
[state-dump] 	NodeManagerService.grpc_server.PinObjectIDs - 5 total (0 active), CPU time: mean = 14.570 ms, total = 72.849 ms
[state-dump] 	NodeManagerService.grpc_server.RequestWorkerLease - 5 total (0 active), CPU time: mean = 48.840 ms, total = 244.201 ms
[state-dump] 	CoreWorkerService.grpc_client.UpdateObjectLocationBatch - 3 total (0 active), CPU time: mean = 4.949 ms, total = 14.846 ms
[state-dump] 	InternalPubSubGcsService.grpc_client.GcsSubscriberCommandBatch - 3 total (0 active), CPU time: mean = 68.436 us, total = 205.309 us
[state-dump] 	InternalPubSubGcsService.grpc_client.GcsSubscriberPoll - 3 total (1 active), CPU time: mean = 68.672 ms, total = 206.017 ms
[state-dump] 	CoreWorkerService.grpc_client.PubsubCommandBatch - 2 total (0 active), CPU time: mean = 18.468 us, total = 36.936 us
[state-dump] 	Subscriber.HandlePublishedMessage_GCS_JOB_CHANNEL - 2 total (0 active), CPU time: mean = 35.076 ms, total = 70.152 ms
[state-dump] 	JobInfoGcsService.grpc_client.AddJob - 2 total (0 active), CPU time: mean = 17.572 ms, total = 35.143 ms
[state-dump] 	AgentManagerService.grpc_server.RegisterAgent - 1 total (0 active), CPU time: mean = 367.585 ms, total = 367.585 ms
[state-dump] 	NodeInfoGcsService.grpc_client.RegisterNode - 1 total (0 active), CPU time: mean = 486.057 us, total = 486.057 us
[state-dump] 	NodeInfoGcsService.grpc_client.GetInternalConfig - 1 total (0 active), CPU time: mean = 34.694 ms, total = 34.694 ms
[state-dump] 	NodeInfoGcsService.grpc_client.GetAllNodeInfo - 1 total (0 active), CPU time: mean = 85.179 us, total = 85.179 us
[state-dump] 	JobInfoGcsService.grpc_client.GetAllJobInfo - 1 total (0 active), CPU time: mean = 15.018 us, total = 15.018 us
[state-dump] 	CoreWorkerService.grpc_client.PubsubLongPolling - 1 total (1 active), CPU time: mean = 0.000 s, total = 0.000 s
[state-dump] DebugString() time ms: 248
[state-dump] 
[state-dump] 
[2022-06-20 22:51:42,421 I 128931 128931] (raylet) object_buffer_pool.cc:153: Not enough memory to create requested object 00ffffffffffffffffffffffffffffffffffffff0200000004000000, aborting
[2022-06-20 22:51:42,512 I 128931 128931] (raylet) object_buffer_pool.cc:153: Not enough memory to create requested object 00ffffffffffffffffffffffffffffffffffffff0200000001000000, aborting
[2022-06-20 22:52:00,189 I 128931 128962] (raylet) store.cc:546: ========== Plasma store: =================
Current usage: 0.0536805 / 200 GB
- num bytes created total: 53680561
0 pending objects of total size 0MB
- objects spillable: 0
- bytes spillable: 0
- objects unsealed: 0
- bytes unsealed: 0
- objects in use: 5
- bytes in use: 53680505
- objects evictable: 0
- bytes evictable: 0

- objects created by worker: 5
- bytes created by worker: 53680505
- objects restored: 0
- bytes restored: 0
- objects received: 0
- bytes received: 0
- objects errored: 0
- bytes errored: 0

[2022-06-20 22:52:00,957 I 128931 128931] (raylet) node_manager.cc:538: [state-dump] Event stats:
[state-dump] 
[state-dump] 
[state-dump] Global stats: 15456 total (29 active)
[state-dump] Queueing time: mean = 69.591 ms, max = 61.275 s, min = -0.067 s, total = 1075.603 s
[state-dump] Execution time:  mean = 4.697 ms, total = 72.596 s
[state-dump] Event stats:
[state-dump] 	ObjectManager.UpdateAvailableMemory - 3339 total (3 active), CPU time: mean = 996.628 us, total = 3.328 s
[state-dump] 	NodeManagerService.grpc_server.RequestResourceReport - 2917 total (1 active), CPU time: mean = 3.046 ms, total = 8.886 s
[state-dump] 	NodeManagerService.grpc_server.UpdateResourceUsage - 2907 total (1 active), CPU time: mean = 2.164 ms, total = 6.292 s
[state-dump] 	RayletWorkerPool.deadline_timer.kill_idle_workers - 1707 total (1 active), CPU time: mean = 3.754 ms, total = 6.408 s
[state-dump] 	NodeManagerService.grpc_server.GetGcsServerAddress - 758 total (0 active), CPU time: mean = 2.001 ms, total = 1.517 s
[state-dump] 	NodeManagerService.grpc_server.ReportWorkerBacklog - 754 total (7 active), CPU time: mean = 2.051 ms, total = 1.547 s
[state-dump] 	CoreWorkerService.grpc_client.GetCoreWorkerStats - 608 total (0 active), CPU time: mean = 4.843 ms, total = 2.945 s
[state-dump] 	NodeManagerService.grpc_server.GetResourceLoad - 401 total (0 active), CPU time: mean = 6.178 ms, total = 2.478 s
[state-dump] 	HeartbeatInfoGcsService.grpc_client.ReportHeartbeat - 370 total (1 active), CPU time: mean = 4.540 ms, total = 1.680 s
[state-dump] 	GcsClient.deadline_timer.check_gcs_connection - 368 total (1 active), CPU time: mean = 3.694 ms, total = 1.359 s
[state-dump] 	UNKNOWN - 368 total (1 active), CPU time: mean = 13.753 ms, total = 5.061 s
[state-dump] 	NodeManager.deadline_timer.flush_free_objects - 367 total (1 active), CPU time: mean = 3.838 ms, total = 1.408 s
[state-dump] 	NodeManagerService.grpc_server.GetNodeStats - 280 total (0 active), CPU time: mean = 37.382 ms, total = 10.467 s
[state-dump] 	ClientConnection.async_read.ReadBufferAsync - 99 total (7 active), CPU time: mean = 16.115 ms, total = 1.595 s
[state-dump] 	NodeManager.deadline_timer.record_metrics - 80 total (1 active), CPU time: mean = 73.025 ms, total = 5.842 s
[state-dump] 	NodeManager.deadline_timer.debug_state_dump - 41 total (1 active), CPU time: mean = 225.865 ms, total = 9.260 s
[state-dump] 	ObjectManager.ObjectAdded - 12 total (0 active), CPU time: mean = 57.012 ms, total = 684.139 ms
[state-dump] 	NodeManagerService.grpc_server.GetSystemConfig - 7 total (0 active), CPU time: mean = 4.335 ms, total = 30.345 ms
[state-dump] 	PeriodicalRunner.RunFnPeriodically - 7 total (0 active), CPU time: mean = 243.532 us, total = 1.705 ms
[state-dump] 	ClientConnection.async_write.DoAsyncWrites - 7 total (0 active), CPU time: mean = 1.404 ms, total = 9.831 ms
[state-dump] 	ObjectManager.ObjectDeleted - 7 total (0 active), CPU time: mean = 3.722 ms, total = 26.054 ms
[state-dump] 	NodeManager.deadline_timer.print_event_loop_stats - 7 total (1 active, 1 running), CPU time: mean = 54.480 ms, total = 381.363 ms
[state-dump] 	CoreWorkerService.grpc_client.PubsubCommandBatch - 6 total (0 active), CPU time: mean = 1.651 ms, total = 9.908 ms
[state-dump] 	CoreWorkerService.grpc_client.DirectActorCallArgWaitComplete - 5 total (0 active), CPU time: mean = 3.011 ms, total = 15.053 ms
[state-dump] 	NodeManagerService.grpc_server.PinObjectIDs - 5 total (0 active), CPU time: mean = 14.570 ms, total = 72.849 ms
[state-dump] 	NodeManagerService.grpc_server.RequestWorkerLease - 5 total (0 active), CPU time: mean = 48.840 ms, total = 244.201 ms
[state-dump] 	CoreWorkerService.grpc_client.PubsubLongPolling - 4 total (1 active), CPU time: mean = 63.323 ms, total = 253.290 ms
[state-dump] 	CoreWorkerService.grpc_client.UpdateObjectLocationBatch - 3 total (0 active), CPU time: mean = 4.949 ms, total = 14.846 ms
[state-dump] 	InternalPubSubGcsService.grpc_client.GcsSubscriberCommandBatch - 3 total (0 active), CPU time: mean = 68.436 us, total = 205.309 us
[state-dump] 	InternalPubSubGcsService.grpc_client.GcsSubscriberPoll - 3 total (1 active), CPU time: mean = 68.672 ms, total = 206.017 ms
[state-dump] 	Subscriber.HandlePublishedMessage_GCS_JOB_CHANNEL - 2 total (0 active), CPU time: mean = 35.076 ms, total = 70.152 ms
[state-dump] 	Subscriber.HandlePublishedMessage_WORKER_OBJECT_LOCATIONS_CHANNEL - 2 total (0 active), CPU time: mean = 32.551 ms, total = 65.101 ms
[state-dump] 	JobInfoGcsService.grpc_client.AddJob - 2 total (0 active), CPU time: mean = 17.572 ms, total = 35.143 ms
[state-dump] 	AgentManagerService.grpc_server.RegisterAgent - 1 total (0 active), CPU time: mean = 367.585 ms, total = 367.585 ms
[state-dump] 	NodeInfoGcsService.grpc_client.RegisterNode - 1 total (0 active), CPU time: mean = 486.057 us, total = 486.057 us
[state-dump] 	NodeInfoGcsService.grpc_client.GetInternalConfig - 1 total (0 active), CPU time: mean = 34.694 ms, total = 34.694 ms
[state-dump] 	NodeInfoGcsService.grpc_client.GetAllNodeInfo - 1 total (0 active), CPU time: mean = 85.179 us, total = 85.179 us
[state-dump] 	JobInfoGcsService.grpc_client.GetAllJobInfo - 1 total (0 active), CPU time: mean = 15.018 us, total = 15.018 us
[state-dump] 
[state-dump] NodeManager:
[state-dump] Node ID: 7562cb0081c73f4ed2ac21d1956887bd794b724f1b8c157f4e02d603
[state-dump] Node name: 10.140.1.109
[state-dump] InitialConfigResources: {CPU: 1280000, node:10.140.1.109: 10000, GPU: 80000, object_store_memory: 2000000000000000, memory: 8693891676160000, accelerator_type:A100: 10000}
[state-dump] ClusterTaskManager:
[state-dump] ========== Node: 7562cb0081c73f4ed2ac21d1956887bd794b724f1b8c157f4e02d603 =================
[state-dump] Infeasible queue length: 0
[state-dump] Schedule queue length: 0
[state-dump] Dispatch queue length: 0
[state-dump] num_waiting_for_resource: 0
[state-dump] num_waiting_for_plasma_memory: 0
[state-dump] num_waiting_for_remote_node_resources: 0
[state-dump] num_worker_not_started_by_job_config_not_exist: 0
[state-dump] num_worker_not_started_by_registration_timeout: 0
[state-dump] num_worker_not_started_by_process_rate_limit: 0
[state-dump] num_tasks_waiting_for_workers: 0
[state-dump] num_cancelled_tasks: 0
[state-dump] cluster_resource_scheduler state: 
[state-dump] Local id: -110938788179330527 Local resources: {object_store_memory: [1999463194950000]/[2000000000000000], node:10.140.1.109: [10000]/[10000], memory: [8693891676160000]/[8693891676160000], CPU: [1280000]/[1280000], accelerator_type:A100: [10000]/[10000], GPU: [10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000]/[10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000]}node id: -110938788179330527{CPU: 1280000/1280000, GPU: 80000/80000, node:10.140.1.109: 10000/10000, object_store_memory: 1999463194950000/2000000000000000, accelerator_type:A100: 10000/10000, memory: 8693891676160000/8693891676160000}
[state-dump] Waiting tasks size: 0
[state-dump] Number of executing tasks: 0
[state-dump] Number of pinned task arguments: 0
[state-dump] Number of total spilled tasks: 0
[state-dump] Number of spilled waiting tasks: 0
[state-dump] Number of spilled unschedulable tasks: 0
[state-dump] Resource usage {
[state-dump]     - (language=PYTHON actor_or_task=CompileWorker.__init__ pid=130462): {}
[state-dump]     - (language=PYTHON actor_or_task=CompileWorker.__init__ pid=130458): {}
[state-dump]     - (language=PYTHON actor_or_task=CompileWorker.__init__ pid=130459): {}
[state-dump]     - (language=PYTHON actor_or_task=CompileWorker.__init__ pid=130461): {}
[state-dump]     - (language=PYTHON actor_or_task=CompileWorker.__init__ pid=130460): {}
[state-dump] }
[state-dump] Running tasks by scheduling class:
[state-dump] ==================================================
[state-dump] 
[state-dump] ClusterResources:
[state-dump] LocalObjectManager:
[state-dump] - num pinned objects: 5
[state-dump] - pinned objects size: 53680505
[state-dump] - num objects pending restore: 0
[state-dump] - num objects pending spill: 0
[state-dump] - num bytes pending spill: 0
[state-dump] - cumulative spill requests: 0
[state-dump] - cumulative restore requests: 0
[state-dump] 
[state-dump] ObjectManager:
[state-dump] - num local objects: 5
[state-dump] - num unfulfilled push requests: 0
[state-dump] - num pull requests: 0
[state-dump] - num chunks received total: 0
[state-dump] - num chunks received failed (all): 0
[state-dump] - num chunks received failed / cancelled: 0
[state-dump] - num chunks received failed / plasma error: 0
[state-dump] Event stats:
[state-dump] Global stats: 0 total (0 active)
[state-dump] Queueing time: mean = -nan s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] Execution time:  mean = -nan s, total = 0.000 s
[state-dump] Event stats:
[state-dump] PushManager:
[state-dump] - num pushes in flight: 0
[state-dump] - num chunks in flight: 0
[state-dump] - num chunks remaining: 0
[state-dump] - max chunks allowed: 409
[state-dump] OwnershipBasedObjectDirectory:
[state-dump] - num listeners: 0
[state-dump] - cumulative location updates: 370
[state-dump] - num location updates per second: 0.000
[state-dump] - num location lookups per second: 0.000
[state-dump] - num locations added per second: 0.000
[state-dump] - num locations removed per second: 0.000
[state-dump] BufferPool:
[state-dump] - create buffer state map size: 0
[state-dump] PullManager:
[state-dump] - num bytes available for pulled objects: 199946319495
[state-dump] - num bytes being pulled (all): 0
[state-dump] - num bytes being pulled / pinned: 0
[state-dump] - num get request bundles: 0
[state-dump] - num wait request bundles: 0
[state-dump] - num task request bundles: 0
[state-dump] - first get request bundle: N/A
[state-dump] - first wait request bundle: N/A
[state-dump] - first task request bundle: N/A
[state-dump] - num objects queued: 0
[state-dump] - num objects actively pulled (all): 0
[state-dump] - num objects actively pulled / pinned: 0
[state-dump] - num bundles being pulled: 0
[state-dump] - num pull retries: 0
[state-dump] - max timeout seconds: 0
[state-dump] - max timeout request is already processed. No entry.
[state-dump] 
[state-dump] WorkerPool:
[state-dump] - registered jobs: 2
[state-dump] - process_failed_job_config_missing: 0
[state-dump] - process_failed_rate_limited: 0
[state-dump] - process_failed_pending_registration: 0
[state-dump] - process_failed_runtime_env_setup_failed: 0
[state-dump] - num JAVA workers: 0
[state-dump] - num JAVA drivers: 0
[state-dump] - num object spill callbacks queued: 0
[state-dump] - num object restore queued: 0
[state-dump] - num util functions queued: 0
[state-dump] - num PYTHON workers: 5
[state-dump] - num PYTHON drivers: 2
[state-dump] - num object spill callbacks queued: 0
[state-dump] - num object restore queued: 0
[state-dump] - num util functions queued: 0
[state-dump] - num idle workers: 0
[state-dump] TaskDependencyManager:
[state-dump] - task deps map size: 0
[state-dump] - get req map size: 0
[state-dump] - wait req map size: 0
[state-dump] - local objects map size: 5
[state-dump] WaitManager:
[state-dump] - num active wait requests: 0
[state-dump] Subscriber:
[state-dump] Channel WORKER_REF_REMOVED_CHANNEL
[state-dump] - cumulative subscribe requests: 0
[state-dump] - cumulative unsubscribe requests: 0
[state-dump] - active subscribed publishers: 0
[state-dump] - cumulative published messages: 0
[state-dump] - cumulative processed messages: 0
[state-dump] Channel WORKER_OBJECT_EVICTION
[state-dump] - cumulative subscribe requests: 5
[state-dump] - cumulative unsubscribe requests: 0
[state-dump] - active subscribed publishers: 1
[state-dump] - cumulative published messages: 0
[state-dump] - cumulative processed messages: 0
[state-dump] Channel WORKER_OBJECT_LOCATIONS_CHANNEL
[state-dump] - cumulative subscribe requests: 5
[state-dump] - cumulative unsubscribe requests: 5
[state-dump] - active subscribed publishers: 0
[state-dump] - cumulative published messages: 2
[state-dump] - cumulative processed messages: 2
[state-dump] num async plasma notifications: 0
[state-dump] Remote node managers: 
[state-dump] Event stats:
[state-dump] Global stats: 15457 total (30 active)
[state-dump] Queueing time: mean = 69.587 ms, max = 61.275 s, min = -0.067 s, total = 1075.603 s
[state-dump] Execution time:  mean = 4.697 ms, total = 72.596 s
[state-dump] Event stats:
[state-dump] 	ObjectManager.UpdateAvailableMemory - 3339 total (3 active), CPU time: mean = 996.628 us, total = 3.328 s
[state-dump] 	NodeManagerService.grpc_server.RequestResourceReport - 2917 total (1 active), CPU time: mean = 3.046 ms, total = 8.886 s
[state-dump] 	NodeManagerService.grpc_server.UpdateResourceUsage - 2907 total (1 active), CPU time: mean = 2.164 ms, total = 6.292 s
[state-dump] 	RayletWorkerPool.deadline_timer.kill_idle_workers - 1707 total (1 active), CPU time: mean = 3.754 ms, total = 6.408 s
[state-dump] 	NodeManagerService.grpc_server.GetGcsServerAddress - 758 total (0 active), CPU time: mean = 2.001 ms, total = 1.517 s
[state-dump] 	NodeManagerService.grpc_server.ReportWorkerBacklog - 754 total (7 active), CPU time: mean = 2.051 ms, total = 1.547 s
[state-dump] 	CoreWorkerService.grpc_client.GetCoreWorkerStats - 608 total (0 active), CPU time: mean = 4.843 ms, total = 2.945 s
[state-dump] 	NodeManagerService.grpc_server.GetResourceLoad - 401 total (0 active), CPU time: mean = 6.178 ms, total = 2.478 s
[state-dump] 	HeartbeatInfoGcsService.grpc_client.ReportHeartbeat - 370 total (1 active), CPU time: mean = 4.540 ms, total = 1.680 s
[state-dump] 	GcsClient.deadline_timer.check_gcs_connection - 368 total (1 active), CPU time: mean = 3.694 ms, total = 1.359 s
[state-dump] 	UNKNOWN - 368 total (1 active), CPU time: mean = 13.753 ms, total = 5.061 s
[state-dump] 	NodeManager.deadline_timer.flush_free_objects - 367 total (1 active), CPU time: mean = 3.838 ms, total = 1.408 s
[state-dump] 	NodeManagerService.grpc_server.GetNodeStats - 281 total (1 active), CPU time: mean = 37.249 ms, total = 10.467 s
[state-dump] 	ClientConnection.async_read.ReadBufferAsync - 99 total (7 active), CPU time: mean = 16.115 ms, total = 1.595 s
[state-dump] 	NodeManager.deadline_timer.record_metrics - 80 total (1 active), CPU time: mean = 73.025 ms, total = 5.842 s
[state-dump] 	NodeManager.deadline_timer.debug_state_dump - 41 total (1 active), CPU time: mean = 225.865 ms, total = 9.260 s
[state-dump] 	ObjectManager.ObjectAdded - 12 total (0 active), CPU time: mean = 57.012 ms, total = 684.139 ms
[state-dump] 	NodeManagerService.grpc_server.GetSystemConfig - 7 total (0 active), CPU time: mean = 4.335 ms, total = 30.345 ms
[state-dump] 	PeriodicalRunner.RunFnPeriodically - 7 total (0 active), CPU time: mean = 243.532 us, total = 1.705 ms
[state-dump] 	ClientConnection.async_write.DoAsyncWrites - 7 total (0 active), CPU time: mean = 1.404 ms, total = 9.831 ms
[state-dump] 	ObjectManager.ObjectDeleted - 7 total (0 active), CPU time: mean = 3.722 ms, total = 26.054 ms
[state-dump] 	NodeManager.deadline_timer.print_event_loop_stats - 7 total (1 active, 1 running), CPU time: mean = 54.480 ms, total = 381.363 ms
[state-dump] 	CoreWorkerService.grpc_client.PubsubCommandBatch - 6 total (0 active), CPU time: mean = 1.651 ms, total = 9.908 ms
[state-dump] 	CoreWorkerService.grpc_client.DirectActorCallArgWaitComplete - 5 total (0 active), CPU time: mean = 3.011 ms, total = 15.053 ms
[state-dump] 	NodeManagerService.grpc_server.PinObjectIDs - 5 total (0 active), CPU time: mean = 14.570 ms, total = 72.849 ms
[state-dump] 	NodeManagerService.grpc_server.RequestWorkerLease - 5 total (0 active), CPU time: mean = 48.840 ms, total = 244.201 ms
[state-dump] 	CoreWorkerService.grpc_client.PubsubLongPolling - 4 total (1 active), CPU time: mean = 63.323 ms, total = 253.290 ms
[state-dump] 	CoreWorkerService.grpc_client.UpdateObjectLocationBatch - 3 total (0 active), CPU time: mean = 4.949 ms, total = 14.846 ms
[state-dump] 	InternalPubSubGcsService.grpc_client.GcsSubscriberCommandBatch - 3 total (0 active), CPU time: mean = 68.436 us, total = 205.309 us
[state-dump] 	InternalPubSubGcsService.grpc_client.GcsSubscriberPoll - 3 total (1 active), CPU time: mean = 68.672 ms, total = 206.017 ms
[state-dump] 	Subscriber.HandlePublishedMessage_GCS_JOB_CHANNEL - 2 total (0 active), CPU time: mean = 35.076 ms, total = 70.152 ms
[state-dump] 	Subscriber.HandlePublishedMessage_WORKER_OBJECT_LOCATIONS_CHANNEL - 2 total (0 active), CPU time: mean = 32.551 ms, total = 65.101 ms
[state-dump] 	JobInfoGcsService.grpc_client.AddJob - 2 total (0 active), CPU time: mean = 17.572 ms, total = 35.143 ms
[state-dump] 	AgentManagerService.grpc_server.RegisterAgent - 1 total (0 active), CPU time: mean = 367.585 ms, total = 367.585 ms
[state-dump] 	NodeInfoGcsService.grpc_client.RegisterNode - 1 total (0 active), CPU time: mean = 486.057 us, total = 486.057 us
[state-dump] 	NodeInfoGcsService.grpc_client.GetInternalConfig - 1 total (0 active), CPU time: mean = 34.694 ms, total = 34.694 ms
[state-dump] 	NodeInfoGcsService.grpc_client.GetAllNodeInfo - 1 total (0 active), CPU time: mean = 85.179 us, total = 85.179 us
[state-dump] 	JobInfoGcsService.grpc_client.GetAllJobInfo - 1 total (0 active), CPU time: mean = 15.018 us, total = 15.018 us
[state-dump] DebugString() time ms: 544
[state-dump] 
[state-dump] 
[2022-06-20 22:52:31,210 I 128931 128931] (raylet) node_manager.cc:1343: NodeManager::DisconnectClient, disconnect_type=1, has creation task exception = 0
[2022-06-20 22:52:31,587 I 128931 128931] (raylet) node_manager.cc:1343: NodeManager::DisconnectClient, disconnect_type=1, has creation task exception = 0
[2022-06-20 22:52:31,587 I 128931 128931] (raylet) node_manager.cc:1343: NodeManager::DisconnectClient, disconnect_type=1, has creation task exception = 0
[2022-06-20 22:52:31,678 I 128931 128931] (raylet) node_manager.cc:1343: NodeManager::DisconnectClient, disconnect_type=1, has creation task exception = 0
[2022-06-20 22:52:31,678 I 128931 128931] (raylet) node_manager.cc:1343: NodeManager::DisconnectClient, disconnect_type=1, has creation task exception = 0
[2022-06-20 22:52:32,563 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 837, the token 5
[2022-06-20 22:52:32,582 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 838, the token 6
[2022-06-20 22:52:32,584 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 839, the token 7
[2022-06-20 22:52:32,586 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 840, the token 8
[2022-06-20 22:52:32,587 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 841, the token 9
[2022-06-20 22:53:00,495 I 128931 128962] (raylet) store.cc:546: ========== Plasma store: =================
Current usage: 0.0378867 / 200 GB
- num bytes created total: 91567298
0 pending objects of total size 0MB
- objects spillable: 10
- bytes spillable: 37886737
- objects unsealed: 0
- bytes unsealed: 0
- objects in use: 10
- bytes in use: 37886737
- objects evictable: 0
- bytes evictable: 0

- objects created by worker: 10
- bytes created by worker: 37886737
- objects restored: 0
- bytes restored: 0
- objects received: 0
- bytes received: 0
- objects errored: 0
- bytes errored: 0

[2022-06-20 22:53:00,959 I 128931 128931] (raylet) node_manager.cc:538: [state-dump] Event stats:
[state-dump] 
[state-dump] 
[state-dump] Global stats: 18359 total (11 active)
[state-dump] Queueing time: mean = 92.770 ms, max = 192.884 s, min = -0.067 s, total = 1703.160 s
[state-dump] Execution time:  mean = 4.592 ms, total = 84.295 s
[state-dump] Event stats:
[state-dump] 	ObjectManager.UpdateAvailableMemory - 3827 total (0 active), CPU time: mean = 936.529 us, total = 3.584 s
[state-dump] 	NodeManagerService.grpc_server.RequestResourceReport - 3387 total (0 active), CPU time: mean = 3.195 ms, total = 10.820 s
[state-dump] 	NodeManagerService.grpc_server.UpdateResourceUsage - 3376 total (0 active), CPU time: mean = 1.916 ms, total = 6.469 s
[state-dump] 	RayletWorkerPool.deadline_timer.kill_idle_workers - 1956 total (1 active), CPU time: mean = 3.608 ms, total = 7.057 s
[state-dump] 	NodeManagerService.grpc_server.GetGcsServerAddress - 1024 total (0 active), CPU time: mean = 1.691 ms, total = 1.732 s
[state-dump] 	NodeManagerService.grpc_server.ReportWorkerBacklog - 1020 total (0 active), CPU time: mean = 2.246 ms, total = 2.291 s
[state-dump] 	CoreWorkerService.grpc_client.GetCoreWorkerStats - 813 total (0 active), CPU time: mean = 3.939 ms, total = 3.202 s
[state-dump] 	NodeManagerService.grpc_server.GetResourceLoad - 459 total (0 active), CPU time: mean = 5.967 ms, total = 2.739 s
[state-dump] 	HeartbeatInfoGcsService.grpc_client.ReportHeartbeat - 426 total (0 active), CPU time: mean = 4.178 ms, total = 1.780 s
[state-dump] 	GcsClient.deadline_timer.check_gcs_connection - 422 total (1 active), CPU time: mean = 3.423 ms, total = 1.445 s
[state-dump] 	UNKNOWN - 422 total (1 active), CPU time: mean = 12.731 ms, total = 5.372 s
[state-dump] 	NodeManager.deadline_timer.flush_free_objects - 421 total (1 active), CPU time: mean = 3.538 ms, total = 1.489 s
[state-dump] 	NodeManagerService.grpc_server.GetNodeStats - 324 total (0 active), CPU time: mean = 38.243 ms, total = 12.391 s
[state-dump] 	ClientConnection.async_read.ReadBufferAsync - 134 total (2 active), CPU time: mean = 17.356 ms, total = 2.326 s
[state-dump] 	NodeManager.deadline_timer.record_metrics - 91 total (1 active), CPU time: mean = 68.744 ms, total = 6.256 s
[state-dump] 	NodeManager.deadline_timer.debug_state_dump - 47 total (1 active), CPU time: mean = 203.863 ms, total = 9.582 s
[state-dump] 	CoreWorkerService.grpc_client.PubsubCommandBatch - 36 total (0 active), CPU time: mean = 697.327 us, total = 25.104 ms
[state-dump] 	ObjectManager.ObjectAdded - 22 total (0 active), CPU time: mean = 58.483 ms, total = 1.287 s
[state-dump] 	CoreWorkerService.grpc_client.PubsubLongPolling - 19 total (1 active), CPU time: mean = 68.074 ms, total = 1.293 s
[state-dump] 	CoreWorkerService.grpc_client.UpdateObjectLocationBatch - 18 total (0 active), CPU time: mean = 4.957 ms, total = 89.227 ms
[state-dump] 	NodeManagerService.grpc_server.PinObjectIDs - 15 total (0 active), CPU time: mean = 46.422 ms, total = 696.329 ms
[state-dump] 	ObjectManager.ObjectDeleted - 12 total (0 active), CPU time: mean = 3.440 ms, total = 41.277 ms
[state-dump] 	Subscriber.HandlePublishedMessage_WORKER_OBJECT_EVICTION - 10 total (0 active), CPU time: mean = 29.138 us, total = 291.380 us
[state-dump] 	NodeManagerService.grpc_server.RequestWorkerLease - 10 total (0 active), CPU time: mean = 32.661 ms, total = 326.614 ms
[state-dump] 	NodeManager.deadline_timer.print_event_loop_stats - 8 total (1 active, 1 running), CPU time: mean = 128.867 ms, total = 1.031 s
[state-dump] 	PeriodicalRunner.RunFnPeriodically - 7 total (0 active), CPU time: mean = 243.532 us, total = 1.705 ms
[state-dump] 	NodeManagerService.grpc_server.GetSystemConfig - 7 total (0 active), CPU time: mean = 4.335 ms, total = 30.345 ms
[state-dump] 	ClientConnection.async_write.DoAsyncWrites - 7 total (0 active), CPU time: mean = 1.404 ms, total = 9.831 ms
[state-dump] 	Subscriber.HandlePublishedMessage_GCS_WORKER_DELTA_CHANNEL - 5 total (0 active), CPU time: mean = 1.076 us, total = 5.379 us
[state-dump] 	RuntimeEnvService.grpc_client.GetOrCreateRuntimeEnv - 5 total (0 active), CPU time: mean = 8.817 ms, total = 44.085 ms
[state-dump] 	CoreWorkerService.grpc_client.DirectActorCallArgWaitComplete - 5 total (0 active), CPU time: mean = 3.011 ms, total = 15.053 ms
[state-dump] 	WorkerInfoGcsService.grpc_client.ReportWorkerFailure - 5 total (0 active), CPU time: mean = 9.030 us, total = 45.152 us
[state-dump] 	InternalPubSubGcsService.grpc_client.GcsSubscriberPoll - 5 total (1 active), CPU time: mean = 59.519 ms, total = 297.595 ms
[state-dump] 	InternalPubSubGcsService.grpc_client.GcsSubscriberCommandBatch - 3 total (0 active), CPU time: mean = 68.436 us, total = 205.309 us
[state-dump] 	Subscriber.HandlePublishedMessage_GCS_JOB_CHANNEL - 2 total (0 active), CPU time: mean = 35.076 ms, total = 70.152 ms
[state-dump] 	Subscriber.HandlePublishedMessage_WORKER_OBJECT_LOCATIONS_CHANNEL - 2 total (0 active), CPU time: mean = 32.551 ms, total = 65.101 ms
[state-dump] 	JobInfoGcsService.grpc_client.AddJob - 2 total (0 active), CPU time: mean = 17.572 ms, total = 35.143 ms
[state-dump] 	AgentManagerService.grpc_server.RegisterAgent - 1 total (0 active), CPU time: mean = 367.585 ms, total = 367.585 ms
[state-dump] 	NodeInfoGcsService.grpc_client.GetInternalConfig - 1 total (0 active), CPU time: mean = 34.694 ms, total = 34.694 ms
[state-dump] 	NodeInfoGcsService.grpc_client.GetAllNodeInfo - 1 total (0 active), CPU time: mean = 85.179 us, total = 85.179 us
[state-dump] 	JobInfoGcsService.grpc_client.GetAllJobInfo - 1 total (0 active), CPU time: mean = 15.018 us, total = 15.018 us
[state-dump] 	NodeInfoGcsService.grpc_client.RegisterNode - 1 total (0 active), CPU time: mean = 486.057 us, total = 486.057 us
[state-dump] 
[state-dump] NodeManager:
[state-dump] Node ID: 7562cb0081c73f4ed2ac21d1956887bd794b724f1b8c157f4e02d603
[state-dump] Node name: 10.140.1.109
[state-dump] InitialConfigResources: {CPU: 1280000, node:10.140.1.109: 10000, GPU: 80000, object_store_memory: 2000000000000000, memory: 8693891676160000, accelerator_type:A100: 10000}
[state-dump] ClusterTaskManager:
[state-dump] ========== Node: 7562cb0081c73f4ed2ac21d1956887bd794b724f1b8c157f4e02d603 =================
[state-dump] Infeasible queue length: 0
[state-dump] Schedule queue length: 0
[state-dump] Dispatch queue length: 5
[state-dump] num_waiting_for_resource: 0
[state-dump] num_waiting_for_plasma_memory: 0
[state-dump] num_waiting_for_remote_node_resources: 0
[state-dump] num_worker_not_started_by_job_config_not_exist: 0
[state-dump] num_worker_not_started_by_registration_timeout: 0
[state-dump] num_worker_not_started_by_process_rate_limit: 0
[state-dump] num_tasks_waiting_for_workers: 5
[state-dump] num_cancelled_tasks: 0
[state-dump] cluster_resource_scheduler state: 
[state-dump] Local id: -110938788179330527 Local resources: {object_store_memory: [1999810566390000]/[2000000000000000], node:10.140.1.109: [10000]/[10000], memory: [8693891676160000]/[8693891676160000], CPU: [1230000]/[1280000], accelerator_type:A100: [10000]/[10000], GPU: [0, 0, 0, 0, 0, 10000, 10000, 10000]/[10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000]}node id: -110938788179330527{accelerator_type:A100: 10000/10000, node:10.140.1.109: 10000/10000, CPU: 1230000/1280000, GPU: 30000/80000, memory: 8693891676160000/8693891676160000, object_store_memory: 1999810566390000/2000000000000000}
[state-dump] Waiting tasks size: 0
[state-dump] Number of executing tasks: 5
[state-dump] Number of pinned task arguments: 0
[state-dump] Number of total spilled tasks: 0
[state-dump] Number of spilled waiting tasks: 0
[state-dump] Number of spilled unschedulable tasks: 0
[state-dump] Resource usage {
[state-dump] }
[state-dump] Running tasks by scheduling class:
[state-dump]     - {depth=1 function_descriptor={type=PythonFunctionDescriptor, module_name=alpa.pipeline_parallel.stage_profiling, class_name=HloCostModelProfileWorker, function_name=__init__, function_hash=08df8f84e6504bc9bf96a25773d558b4} scheduling_strategy=default_scheduling_strategy {
[state-dump] }
[state-dump]  resource_set={CPU : 1, GPU : 1, }}: 5/128
[state-dump] ==================================================
[state-dump] 
[state-dump] ClusterResources:
[state-dump] LocalObjectManager:
[state-dump] - num pinned objects: 5
[state-dump] - pinned objects size: 18943361
[state-dump] - num objects pending restore: 0
[state-dump] - num objects pending spill: 0
[state-dump] - num bytes pending spill: 0
[state-dump] - cumulative spill requests: 0
[state-dump] - cumulative restore requests: 0
[state-dump] 
[state-dump] ObjectManager:
[state-dump] - num local objects: 10
[state-dump] - num unfulfilled push requests: 0
[state-dump] - num pull requests: 0
[state-dump] - num chunks received total: 0
[state-dump] - num chunks received failed (all): 0
[state-dump] - num chunks received failed / cancelled: 0
[state-dump] - num chunks received failed / plasma error: 0
[state-dump] Event stats:
[state-dump] Global stats: 6 total (0 active)
[state-dump] Queueing time: mean = 17.216 us, max = 19.189 us, min = 15.950 us, total = 103.297 us
[state-dump] Execution time:  mean = 6.995 us, total = 41.972 us
[state-dump] Event stats:
[state-dump] 	ObjectManager.FreeObjects - 6 total (0 active), CPU time: mean = 6.995 us, total = 41.972 us
[state-dump] PushManager:
[state-dump] - num pushes in flight: 0
[state-dump] - num chunks in flight: 0
[state-dump] - num chunks remaining: 0
[state-dump] - max chunks allowed: 409
[state-dump] OwnershipBasedObjectDirectory:
[state-dump] - num listeners: 0
[state-dump] - cumulative location updates: 370
[state-dump] - num location updates per second: 0.000
[state-dump] - num location lookups per second: 0.000
[state-dump] - num locations added per second: 0.000
[state-dump] - num locations removed per second: 0.000
[state-dump] BufferPool:
[state-dump] - create buffer state map size: 0
[state-dump] PullManager:
[state-dump] - num bytes available for pulled objects: 199962113263
[state-dump] - num bytes being pulled (all): 0
[state-dump] - num bytes being pulled / pinned: 0
[state-dump] - num get request bundles: 0
[state-dump] - num wait request bundles: 0
[state-dump] - num task request bundles: 0
[state-dump] - first get request bundle: N/A
[state-dump] - first wait request bundle: N/A
[state-dump] - first task request bundle: N/A
[state-dump] - num objects queued: 0
[state-dump] - num objects actively pulled (all): 0
[state-dump] - num objects actively pulled / pinned: 0
[state-dump] - num bundles being pulled: 0
[state-dump] - num pull retries: 0
[state-dump] - max timeout seconds: 0
[state-dump] - max timeout request is already processed. No entry.
[state-dump] 
[state-dump] WorkerPool:
[state-dump] - registered jobs: 2
[state-dump] - process_failed_job_config_missing: 0
[state-dump] - process_failed_rate_limited: 0
[state-dump] - process_failed_pending_registration: 0
[state-dump] - process_failed_runtime_env_setup_failed: 0
[state-dump] - num JAVA workers: 0
[state-dump] - num JAVA drivers: 0
[state-dump] - num object spill callbacks queued: 0
[state-dump] - num object restore queued: 0
[state-dump] - num util functions queued: 0
[state-dump] - num PYTHON workers: 0
[state-dump] - num PYTHON drivers: 2
[state-dump] - num object spill callbacks queued: 0
[state-dump] - num object restore queued: 0
[state-dump] - num util functions queued: 0
[state-dump] - num idle workers: 0
[state-dump] TaskDependencyManager:
[state-dump] - task deps map size: 0
[state-dump] - get req map size: 0
[state-dump] - wait req map size: 0
[state-dump] - local objects map size: 10
[state-dump] WaitManager:
[state-dump] - num active wait requests: 0
[state-dump] Subscriber:
[state-dump] Channel WORKER_REF_REMOVED_CHANNEL
[state-dump] - cumulative subscribe requests: 0
[state-dump] - cumulative unsubscribe requests: 0
[state-dump] - active subscribed publishers: 0
[state-dump] - cumulative published messages: 0
[state-dump] - cumulative processed messages: 0
[state-dump] Channel WORKER_OBJECT_EVICTION
[state-dump] - cumulative subscribe requests: 15
[state-dump] - cumulative unsubscribe requests: 10
[state-dump] - active subscribed publishers: 1
[state-dump] - cumulative published messages: 10
[state-dump] - cumulative processed messages: 10
[state-dump] Channel WORKER_OBJECT_LOCATIONS_CHANNEL
[state-dump] - cumulative subscribe requests: 10
[state-dump] - cumulative unsubscribe requests: 10
[state-dump] - active subscribed publishers: 0
[state-dump] - cumulative published messages: 2
[state-dump] - cumulative processed messages: 2
[state-dump] num async plasma notifications: 0
[state-dump] Remote node managers: 
[state-dump] Event stats:
[state-dump] Global stats: 18359 total (11 active)
[state-dump] Queueing time: mean = 92.770 ms, max = 192.884 s, min = -0.067 s, total = 1703.160 s
[state-dump] Execution time:  mean = 4.592 ms, total = 84.295 s
[state-dump] Event stats:
[state-dump] 	ObjectManager.UpdateAvailableMemory - 3827 total (0 active), CPU time: mean = 936.529 us, total = 3.584 s
[state-dump] 	NodeManagerService.grpc_server.RequestResourceReport - 3387 total (0 active), CPU time: mean = 3.195 ms, total = 10.820 s
[state-dump] 	NodeManagerService.grpc_server.UpdateResourceUsage - 3376 total (0 active), CPU time: mean = 1.916 ms, total = 6.469 s
[state-dump] 	RayletWorkerPool.deadline_timer.kill_idle_workers - 1956 total (1 active), CPU time: mean = 3.608 ms, total = 7.057 s
[state-dump] 	NodeManagerService.grpc_server.GetGcsServerAddress - 1024 total (0 active), CPU time: mean = 1.691 ms, total = 1.732 s
[state-dump] 	NodeManagerService.grpc_server.ReportWorkerBacklog - 1020 total (0 active), CPU time: mean = 2.246 ms, total = 2.291 s
[state-dump] 	CoreWorkerService.grpc_client.GetCoreWorkerStats - 813 total (0 active), CPU time: mean = 3.939 ms, total = 3.202 s
[state-dump] 	NodeManagerService.grpc_server.GetResourceLoad - 459 total (0 active), CPU time: mean = 5.967 ms, total = 2.739 s
[state-dump] 	HeartbeatInfoGcsService.grpc_client.ReportHeartbeat - 426 total (0 active), CPU time: mean = 4.178 ms, total = 1.780 s
[state-dump] 	GcsClient.deadline_timer.check_gcs_connection - 422 total (1 active), CPU time: mean = 3.423 ms, total = 1.445 s
[state-dump] 	UNKNOWN - 422 total (1 active), CPU time: mean = 12.731 ms, total = 5.372 s
[state-dump] 	NodeManager.deadline_timer.flush_free_objects - 421 total (1 active), CPU time: mean = 3.538 ms, total = 1.489 s
[state-dump] 	NodeManagerService.grpc_server.GetNodeStats - 324 total (0 active), CPU time: mean = 38.243 ms, total = 12.391 s
[state-dump] 	ClientConnection.async_read.ReadBufferAsync - 134 total (2 active), CPU time: mean = 17.356 ms, total = 2.326 s
[state-dump] 	NodeManager.deadline_timer.record_metrics - 91 total (1 active), CPU time: mean = 68.744 ms, total = 6.256 s
[state-dump] 	NodeManager.deadline_timer.debug_state_dump - 47 total (1 active), CPU time: mean = 203.863 ms, total = 9.582 s
[state-dump] 	CoreWorkerService.grpc_client.PubsubCommandBatch - 36 total (0 active), CPU time: mean = 697.327 us, total = 25.104 ms
[state-dump] 	ObjectManager.ObjectAdded - 22 total (0 active), CPU time: mean = 58.483 ms, total = 1.287 s
[state-dump] 	CoreWorkerService.grpc_client.PubsubLongPolling - 19 total (1 active), CPU time: mean = 68.074 ms, total = 1.293 s
[state-dump] 	CoreWorkerService.grpc_client.UpdateObjectLocationBatch - 18 total (0 active), CPU time: mean = 4.957 ms, total = 89.227 ms
[state-dump] 	NodeManagerService.grpc_server.PinObjectIDs - 15 total (0 active), CPU time: mean = 46.422 ms, total = 696.329 ms
[state-dump] 	ObjectManager.ObjectDeleted - 12 total (0 active), CPU time: mean = 3.440 ms, total = 41.277 ms
[state-dump] 	Subscriber.HandlePublishedMessage_WORKER_OBJECT_EVICTION - 10 total (0 active), CPU time: mean = 29.138 us, total = 291.380 us
[state-dump] 	NodeManagerService.grpc_server.RequestWorkerLease - 10 total (0 active), CPU time: mean = 32.661 ms, total = 326.614 ms
[state-dump] 	NodeManager.deadline_timer.print_event_loop_stats - 8 total (1 active, 1 running), CPU time: mean = 128.867 ms, total = 1.031 s
[state-dump] 	PeriodicalRunner.RunFnPeriodically - 7 total (0 active), CPU time: mean = 243.532 us, total = 1.705 ms
[state-dump] 	NodeManagerService.grpc_server.GetSystemConfig - 7 total (0 active), CPU time: mean = 4.335 ms, total = 30.345 ms
[state-dump] 	ClientConnection.async_write.DoAsyncWrites - 7 total (0 active), CPU time: mean = 1.404 ms, total = 9.831 ms
[state-dump] 	Subscriber.HandlePublishedMessage_GCS_WORKER_DELTA_CHANNEL - 5 total (0 active), CPU time: mean = 1.076 us, total = 5.379 us
[state-dump] 	RuntimeEnvService.grpc_client.GetOrCreateRuntimeEnv - 5 total (0 active), CPU time: mean = 8.817 ms, total = 44.085 ms
[state-dump] 	CoreWorkerService.grpc_client.DirectActorCallArgWaitComplete - 5 total (0 active), CPU time: mean = 3.011 ms, total = 15.053 ms
[state-dump] 	WorkerInfoGcsService.grpc_client.ReportWorkerFailure - 5 total (0 active), CPU time: mean = 9.030 us, total = 45.152 us
[state-dump] 	InternalPubSubGcsService.grpc_client.GcsSubscriberPoll - 5 total (1 active), CPU time: mean = 59.519 ms, total = 297.595 ms
[state-dump] 	InternalPubSubGcsService.grpc_client.GcsSubscriberCommandBatch - 3 total (0 active), CPU time: mean = 68.436 us, total = 205.309 us
[state-dump] 	Subscriber.HandlePublishedMessage_GCS_JOB_CHANNEL - 2 total (0 active), CPU time: mean = 35.076 ms, total = 70.152 ms
[state-dump] 	Subscriber.HandlePublishedMessage_WORKER_OBJECT_LOCATIONS_CHANNEL - 2 total (0 active), CPU time: mean = 32.551 ms, total = 65.101 ms
[state-dump] 	JobInfoGcsService.grpc_client.AddJob - 2 total (0 active), CPU time: mean = 17.572 ms, total = 35.143 ms
[state-dump] 	AgentManagerService.grpc_server.RegisterAgent - 1 total (0 active), CPU time: mean = 367.585 ms, total = 367.585 ms
[state-dump] 	NodeInfoGcsService.grpc_client.GetInternalConfig - 1 total (0 active), CPU time: mean = 34.694 ms, total = 34.694 ms
[state-dump] 	NodeInfoGcsService.grpc_client.GetAllNodeInfo - 1 total (0 active), CPU time: mean = 85.179 us, total = 85.179 us
[state-dump] 	JobInfoGcsService.grpc_client.GetAllJobInfo - 1 total (0 active), CPU time: mean = 15.018 us, total = 15.018 us
[state-dump] 	NodeInfoGcsService.grpc_client.RegisterNode - 1 total (0 active), CPU time: mean = 486.057 us, total = 486.057 us
[state-dump] DebugString() time ms: 1
[state-dump] 
[state-dump] 
[2022-06-20 22:54:00,808 I 128931 128962] (raylet) store.cc:546: ========== Plasma store: =================
Current usage: 0.0378867 / 200 GB
- num bytes created total: 91567338
0 pending objects of total size 0MB
- objects spillable: 10
- bytes spillable: 37886737
- objects unsealed: 0
- bytes unsealed: 0
- objects in use: 10
- bytes in use: 37886737
- objects evictable: 0
- bytes evictable: 0

- objects created by worker: 10
- bytes created by worker: 37886737
- objects restored: 0
- bytes restored: 0
- objects received: 0
- bytes received: 0
- objects errored: 0
- bytes errored: 0

[2022-06-20 22:54:00,995 I 128931 128931] (raylet) node_manager.cc:538: [state-dump] Event stats:
[state-dump] 
[state-dump] 
[state-dump] Global stats: 21240 total (16 active)
[state-dump] Queueing time: mean = 89.451 ms, max = 192.884 s, min = -0.067 s, total = 1899.944 s
[state-dump] Execution time:  mean = 4.389 ms, total = 93.226 s
[state-dump] Event stats:
[state-dump] 	ObjectManager.UpdateAvailableMemory - 4325 total (0 active), CPU time: mean = 869.365 us, total = 3.760 s
[state-dump] 	NodeManagerService.grpc_server.RequestResourceReport - 3828 total (0 active), CPU time: mean = 3.042 ms, total = 11.643 s
[state-dump] 	NodeManagerService.grpc_server.UpdateResourceUsage - 3815 total (0 active), CPU time: mean = 1.772 ms, total = 6.761 s
[state-dump] 	RayletWorkerPool.deadline_timer.kill_idle_workers - 2212 total (1 active), CPU time: mean = 3.341 ms, total = 7.391 s
[state-dump] 	NodeManagerService.grpc_server.GetGcsServerAddress - 1325 total (0 active), CPU time: mean = 1.514 ms, total = 2.006 s
[state-dump] 	NodeManagerService.grpc_server.ReportWorkerBacklog - 1321 total (0 active), CPU time: mean = 2.207 ms, total = 2.916 s
[state-dump] 	CoreWorkerService.grpc_client.GetCoreWorkerStats - 1052 total (0 active), CPU time: mean = 3.440 ms, total = 3.619 s
[state-dump] 	NodeManagerService.grpc_server.GetResourceLoad - 517 total (0 active), CPU time: mean = 5.437 ms, total = 2.811 s
[state-dump] 	HeartbeatInfoGcsService.grpc_client.ReportHeartbeat - 482 total (0 active), CPU time: mean = 4.009 ms, total = 1.932 s
[state-dump] 	GcsClient.deadline_timer.check_gcs_connection - 476 total (1 active), CPU time: mean = 3.226 ms, total = 1.535 s
[state-dump] 	UNKNOWN - 476 total (1 active), CPU time: mean = 12.170 ms, total = 5.793 s
[state-dump] 	NodeManager.deadline_timer.flush_free_objects - 475 total (1 active), CPU time: mean = 3.328 ms, total = 1.581 s
[state-dump] 	NodeManagerService.grpc_server.GetNodeStats - 371 total (0 active), CPU time: mean = 37.652 ms, total = 13.969 s
[state-dump] 	ClientConnection.async_read.ReadBufferAsync - 179 total (7 active), CPU time: mean = 16.257 ms, total = 2.910 s
[state-dump] 	NodeManager.deadline_timer.record_metrics - 102 total (1 active), CPU time: mean = 68.400 ms, total = 6.977 s
[state-dump] 	NodeManager.deadline_timer.debug_state_dump - 53 total (1 active), CPU time: mean = 220.061 ms, total = 11.663 s
[state-dump] 	CoreWorkerService.grpc_client.PubsubCommandBatch - 36 total (0 active), CPU time: mean = 697.327 us, total = 25.104 ms
[state-dump] 	ObjectManager.ObjectAdded - 27 total (0 active), CPU time: mean = 53.225 ms, total = 1.437 s
[state-dump] 	CoreWorkerService.grpc_client.PubsubLongPolling - 19 total (1 active), CPU time: mean = 68.074 ms, total = 1.293 s
[state-dump] 	CoreWorkerService.grpc_client.UpdateObjectLocationBatch - 18 total (0 active), CPU time: mean = 4.957 ms, total = 89.227 ms
[state-dump] 	ObjectManager.ObjectDeleted - 17 total (0 active), CPU time: mean = 5.083 ms, total = 86.408 ms
[state-dump] 	NodeManagerService.grpc_server.PinObjectIDs - 15 total (0 active), CPU time: mean = 46.422 ms, total = 696.329 ms
[state-dump] 	NodeManagerService.grpc_server.GetSystemConfig - 12 total (0 active), CPU time: mean = 2.580 ms, total = 30.960 ms
[state-dump] 	ClientConnection.async_write.DoAsyncWrites - 12 total (0 active), CPU time: mean = 819.361 us, total = 9.832 ms
[state-dump] 	Subscriber.HandlePublishedMessage_WORKER_OBJECT_EVICTION - 10 total (0 active), CPU time: mean = 29.138 us, total = 291.380 us
[state-dump] 	NodeManagerService.grpc_server.RequestWorkerLease - 10 total (0 active), CPU time: mean = 32.661 ms, total = 326.614 ms
[state-dump] 	NodeManager.deadline_timer.print_event_loop_stats - 9 total (1 active, 1 running), CPU time: mean = 114.738 ms, total = 1.033 s
[state-dump] 	PeriodicalRunner.RunFnPeriodically - 7 total (0 active), CPU time: mean = 243.532 us, total = 1.705 ms
[state-dump] 	Subscriber.HandlePublishedMessage_GCS_WORKER_DELTA_CHANNEL - 5 total (0 active), CPU time: mean = 1.076 us, total = 5.379 us
[state-dump] 	CoreWorkerService.grpc_client.DirectActorCallArgWaitComplete - 5 total (0 active), CPU time: mean = 3.011 ms, total = 15.053 ms
[state-dump] 	RuntimeEnvService.grpc_client.GetOrCreateRuntimeEnv - 5 total (0 active), CPU time: mean = 8.817 ms, total = 44.085 ms
[state-dump] 	WorkerInfoGcsService.grpc_client.ReportWorkerFailure - 5 total (0 active), CPU time: mean = 9.030 us, total = 45.152 us
[state-dump] 	InternalPubSubGcsService.grpc_client.GcsSubscriberPoll - 5 total (1 active), CPU time: mean = 59.519 ms, total = 297.595 ms
[state-dump] 	InternalPubSubGcsService.grpc_client.GcsSubscriberCommandBatch - 3 total (0 active), CPU time: mean = 68.436 us, total = 205.309 us
[state-dump] 	Subscriber.HandlePublishedMessage_GCS_JOB_CHANNEL - 2 total (0 active), CPU time: mean = 35.076 ms, total = 70.152 ms
[state-dump] 	Subscriber.HandlePublishedMessage_WORKER_OBJECT_LOCATIONS_CHANNEL - 2 total (0 active), CPU time: mean = 32.551 ms, total = 65.101 ms
[state-dump] 	JobInfoGcsService.grpc_client.AddJob - 2 total (0 active), CPU time: mean = 17.572 ms, total = 35.143 ms
[state-dump] 	AgentManagerService.grpc_server.RegisterAgent - 1 total (0 active), CPU time: mean = 367.585 ms, total = 367.585 ms
[state-dump] 	NodeInfoGcsService.grpc_client.GetInternalConfig - 1 total (0 active), CPU time: mean = 34.694 ms, total = 34.694 ms
[state-dump] 	NodeInfoGcsService.grpc_client.GetAllNodeInfo - 1 total (0 active), CPU time: mean = 85.179 us, total = 85.179 us
[state-dump] 	JobInfoGcsService.grpc_client.GetAllJobInfo - 1 total (0 active), CPU time: mean = 15.018 us, total = 15.018 us
[state-dump] 	NodeInfoGcsService.grpc_client.RegisterNode - 1 total (0 active), CPU time: mean = 486.057 us, total = 486.057 us
[state-dump] 
[state-dump] NodeManager:
[state-dump] Node ID: 7562cb0081c73f4ed2ac21d1956887bd794b724f1b8c157f4e02d603
[state-dump] Node name: 10.140.1.109
[state-dump] InitialConfigResources: {CPU: 1280000, node:10.140.1.109: 10000, GPU: 80000, object_store_memory: 2000000000000000, memory: 8693891676160000, accelerator_type:A100: 10000}
[state-dump] ClusterTaskManager:
[state-dump] ========== Node: 7562cb0081c73f4ed2ac21d1956887bd794b724f1b8c157f4e02d603 =================
[state-dump] Infeasible queue length: 0
[state-dump] Schedule queue length: 0
[state-dump] Dispatch queue length: 0
[state-dump] num_waiting_for_resource: 0
[state-dump] num_waiting_for_plasma_memory: 0
[state-dump] num_waiting_for_remote_node_resources: 0
[state-dump] num_worker_not_started_by_job_config_not_exist: 0
[state-dump] num_worker_not_started_by_registration_timeout: 0
[state-dump] num_worker_not_started_by_process_rate_limit: 0
[state-dump] num_tasks_waiting_for_workers: 0
[state-dump] num_cancelled_tasks: 0
[state-dump] cluster_resource_scheduler state: 
[state-dump] Local id: -110938788179330527 Local resources: {object_store_memory: [1999810566390000]/[2000000000000000], node:10.140.1.109: [10000]/[10000], memory: [8693891676160000]/[8693891676160000], CPU: [1230000]/[1280000], accelerator_type:A100: [10000]/[10000], GPU: [0, 0, 0, 0, 0, 10000, 10000, 10000]/[10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000]}node id: -110938788179330527{accelerator_type:A100: 10000/10000, node:10.140.1.109: 10000/10000, CPU: 1230000/1280000, GPU: 30000/80000, memory: 8693891676160000/8693891676160000, object_store_memory: 1999810566390000/2000000000000000}
[state-dump] Waiting tasks size: 0
[state-dump] Number of executing tasks: 5
[state-dump] Number of pinned task arguments: 0
[state-dump] Number of total spilled tasks: 0
[state-dump] Number of spilled waiting tasks: 0
[state-dump] Number of spilled unschedulable tasks: 0
[state-dump] Resource usage {
[state-dump]     - (language=PYTHON actor_or_task=HloCostModelProfileWorker.__init__ pid=840): {CPU: 1.000000}, {GPU: 1.000000}
[state-dump]     - (language=PYTHON actor_or_task=HloCostModelProfileWorker.__init__ pid=839): {CPU: 1.000000}, {GPU: 1.000000}
[state-dump]     - (language=PYTHON actor_or_task=HloCostModelProfileWorker.__init__ pid=838): {CPU: 1.000000}, {GPU: 1.000000}
[state-dump]     - (language=PYTHON actor_or_task=HloCostModelProfileWorker.__init__ pid=837): {GPU: 1.000000}, {CPU: 1.000000}
[state-dump]     - (language=PYTHON actor_or_task=HloCostModelProfileWorker.__init__ pid=841): {CPU: 1.000000}, {GPU: 1.000000}
[state-dump] }
[state-dump] Running tasks by scheduling class:
[state-dump]     - {depth=1 function_descriptor={type=PythonFunctionDescriptor, module_name=alpa.pipeline_parallel.stage_profiling, class_name=HloCostModelProfileWorker, function_name=__init__, function_hash=08df8f84e6504bc9bf96a25773d558b4} scheduling_strategy=default_scheduling_strategy {
[state-dump] }
[state-dump]  resource_set={GPU : 1, CPU : 1, }}: 5/128
[state-dump] ==================================================
[state-dump] 
[state-dump] ClusterResources:
[state-dump] LocalObjectManager:
[state-dump] - num pinned objects: 5
[state-dump] - pinned objects size: 18943361
[state-dump] - num objects pending restore: 0
[state-dump] - num objects pending spill: 0
[state-dump] - num bytes pending spill: 0
[state-dump] - cumulative spill requests: 0
[state-dump] - cumulative restore requests: 0
[state-dump] 
[state-dump] ObjectManager:
[state-dump] - num local objects: 10
[state-dump] - num unfulfilled push requests: 0
[state-dump] - num pull requests: 0
[state-dump] - num chunks received total: 0
[state-dump] - num chunks received failed (all): 0
[state-dump] - num chunks received failed / cancelled: 0
[state-dump] - num chunks received failed / plasma error: 0
[state-dump] Event stats:
[state-dump] Global stats: 6 total (0 active)
[state-dump] Queueing time: mean = 17.216 us, max = 19.189 us, min = 15.950 us, total = 103.297 us
[state-dump] Execution time:  mean = 6.995 us, total = 41.972 us
[state-dump] Event stats:
[state-dump] 	ObjectManager.FreeObjects - 6 total (0 active), CPU time: mean = 6.995 us, total = 41.972 us
[state-dump] PushManager:
[state-dump] - num pushes in flight: 0
[state-dump] - num chunks in flight: 0
[state-dump] - num chunks remaining: 0
[state-dump] - max chunks allowed: 409
[state-dump] OwnershipBasedObjectDirectory:
[state-dump] - num listeners: 0
[state-dump] - cumulative location updates: 370
[state-dump] - num location updates per second: 0.000
[state-dump] - num location lookups per second: 0.000
[state-dump] - num locations added per second: 0.000
[state-dump] - num locations removed per second: 0.000
[state-dump] BufferPool:
[state-dump] - create buffer state map size: 0
[state-dump] PullManager:
[state-dump] - num bytes available for pulled objects: 199962113263
[state-dump] - num bytes being pulled (all): 0
[state-dump] - num bytes being pulled / pinned: 0
[state-dump] - num get request bundles: 0
[state-dump] - num wait request bundles: 0
[state-dump] - num task request bundles: 0
[state-dump] - first get request bundle: N/A
[state-dump] - first wait request bundle: N/A
[state-dump] - first task request bundle: N/A
[state-dump] - num objects queued: 0
[state-dump] - num objects actively pulled (all): 0
[state-dump] - num objects actively pulled / pinned: 0
[state-dump] - num bundles being pulled: 0
[state-dump] - num pull retries: 0
[state-dump] - max timeout seconds: 0
[state-dump] - max timeout request is already processed. No entry.
[state-dump] 
[state-dump] WorkerPool:
[state-dump] - registered jobs: 2
[state-dump] - process_failed_job_config_missing: 0
[state-dump] - process_failed_rate_limited: 0
[state-dump] - process_failed_pending_registration: 0
[state-dump] - process_failed_runtime_env_setup_failed: 0
[state-dump] - num JAVA workers: 0
[state-dump] - num JAVA drivers: 0
[state-dump] - num object spill callbacks queued: 0
[state-dump] - num object restore queued: 0
[state-dump] - num util functions queued: 0
[state-dump] - num PYTHON workers: 5
[state-dump] - num PYTHON drivers: 2
[state-dump] - num object spill callbacks queued: 0
[state-dump] - num object restore queued: 0
[state-dump] - num util functions queued: 0
[state-dump] - num idle workers: 0
[state-dump] TaskDependencyManager:
[state-dump] - task deps map size: 0
[state-dump] - get req map size: 0
[state-dump] - wait req map size: 0
[state-dump] - local objects map size: 10
[state-dump] WaitManager:
[state-dump] - num active wait requests: 0
[state-dump] Subscriber:
[state-dump] Channel WORKER_REF_REMOVED_CHANNEL
[state-dump] - cumulative subscribe requests: 0
[state-dump] - cumulative unsubscribe requests: 0
[state-dump] - active subscribed publishers: 0
[state-dump] - cumulative published messages: 0
[state-dump] - cumulative processed messages: 0
[state-dump] Channel WORKER_OBJECT_EVICTION
[state-dump] - cumulative subscribe requests: 15
[state-dump] - cumulative unsubscribe requests: 10
[state-dump] - active subscribed publishers: 1
[state-dump] - cumulative published messages: 10
[state-dump] - cumulative processed messages: 10
[state-dump] Channel WORKER_OBJECT_LOCATIONS_CHANNEL
[state-dump] - cumulative subscribe requests: 10
[state-dump] - cumulative unsubscribe requests: 10
[state-dump] - active subscribed publishers: 0
[state-dump] - cumulative published messages: 2
[state-dump] - cumulative processed messages: 2
[state-dump] num async plasma notifications: 0
[state-dump] Remote node managers: 
[state-dump] Event stats:
[state-dump] Global stats: 21240 total (16 active)
[state-dump] Queueing time: mean = 89.451 ms, max = 192.884 s, min = -0.067 s, total = 1899.944 s
[state-dump] Execution time:  mean = 4.389 ms, total = 93.226 s
[state-dump] Event stats:
[state-dump] 	ObjectManager.UpdateAvailableMemory - 4325 total (0 active), CPU time: mean = 869.365 us, total = 3.760 s
[state-dump] 	NodeManagerService.grpc_server.RequestResourceReport - 3828 total (0 active), CPU time: mean = 3.042 ms, total = 11.643 s
[state-dump] 	NodeManagerService.grpc_server.UpdateResourceUsage - 3815 total (0 active), CPU time: mean = 1.772 ms, total = 6.761 s
[state-dump] 	RayletWorkerPool.deadline_timer.kill_idle_workers - 2212 total (1 active), CPU time: mean = 3.341 ms, total = 7.391 s
[state-dump] 	NodeManagerService.grpc_server.GetGcsServerAddress - 1325 total (0 active), CPU time: mean = 1.514 ms, total = 2.006 s
[state-dump] 	NodeManagerService.grpc_server.ReportWorkerBacklog - 1321 total (0 active), CPU time: mean = 2.207 ms, total = 2.916 s
[state-dump] 	CoreWorkerService.grpc_client.GetCoreWorkerStats - 1052 total (0 active), CPU time: mean = 3.440 ms, total = 3.619 s
[state-dump] 	NodeManagerService.grpc_server.GetResourceLoad - 517 total (0 active), CPU time: mean = 5.437 ms, total = 2.811 s
[state-dump] 	HeartbeatInfoGcsService.grpc_client.ReportHeartbeat - 482 total (0 active), CPU time: mean = 4.009 ms, total = 1.932 s
[state-dump] 	GcsClient.deadline_timer.check_gcs_connection - 476 total (1 active), CPU time: mean = 3.226 ms, total = 1.535 s
[state-dump] 	UNKNOWN - 476 total (1 active), CPU time: mean = 12.170 ms, total = 5.793 s
[state-dump] 	NodeManager.deadline_timer.flush_free_objects - 475 total (1 active), CPU time: mean = 3.328 ms, total = 1.581 s
[state-dump] 	NodeManagerService.grpc_server.GetNodeStats - 371 total (0 active), CPU time: mean = 37.652 ms, total = 13.969 s
[state-dump] 	ClientConnection.async_read.ReadBufferAsync - 179 total (7 active), CPU time: mean = 16.257 ms, total = 2.910 s
[state-dump] 	NodeManager.deadline_timer.record_metrics - 102 total (1 active), CPU time: mean = 68.400 ms, total = 6.977 s
[state-dump] 	NodeManager.deadline_timer.debug_state_dump - 53 total (1 active), CPU time: mean = 220.061 ms, total = 11.663 s
[state-dump] 	CoreWorkerService.grpc_client.PubsubCommandBatch - 36 total (0 active), CPU time: mean = 697.327 us, total = 25.104 ms
[state-dump] 	ObjectManager.ObjectAdded - 27 total (0 active), CPU time: mean = 53.225 ms, total = 1.437 s
[state-dump] 	CoreWorkerService.grpc_client.PubsubLongPolling - 19 total (1 active), CPU time: mean = 68.074 ms, total = 1.293 s
[state-dump] 	CoreWorkerService.grpc_client.UpdateObjectLocationBatch - 18 total (0 active), CPU time: mean = 4.957 ms, total = 89.227 ms
[state-dump] 	ObjectManager.ObjectDeleted - 17 total (0 active), CPU time: mean = 5.083 ms, total = 86.408 ms
[state-dump] 	NodeManagerService.grpc_server.PinObjectIDs - 15 total (0 active), CPU time: mean = 46.422 ms, total = 696.329 ms
[state-dump] 	NodeManagerService.grpc_server.GetSystemConfig - 12 total (0 active), CPU time: mean = 2.580 ms, total = 30.960 ms
[state-dump] 	ClientConnection.async_write.DoAsyncWrites - 12 total (0 active), CPU time: mean = 819.361 us, total = 9.832 ms
[state-dump] 	Subscriber.HandlePublishedMessage_WORKER_OBJECT_EVICTION - 10 total (0 active), CPU time: mean = 29.138 us, total = 291.380 us
[state-dump] 	NodeManagerService.grpc_server.RequestWorkerLease - 10 total (0 active), CPU time: mean = 32.661 ms, total = 326.614 ms
[state-dump] 	NodeManager.deadline_timer.print_event_loop_stats - 9 total (1 active, 1 running), CPU time: mean = 114.738 ms, total = 1.033 s
[state-dump] 	PeriodicalRunner.RunFnPeriodically - 7 total (0 active), CPU time: mean = 243.532 us, total = 1.705 ms
[state-dump] 	Subscriber.HandlePublishedMessage_GCS_WORKER_DELTA_CHANNEL - 5 total (0 active), CPU time: mean = 1.076 us, total = 5.379 us
[state-dump] 	CoreWorkerService.grpc_client.DirectActorCallArgWaitComplete - 5 total (0 active), CPU time: mean = 3.011 ms, total = 15.053 ms
[state-dump] 	RuntimeEnvService.grpc_client.GetOrCreateRuntimeEnv - 5 total (0 active), CPU time: mean = 8.817 ms, total = 44.085 ms
[state-dump] 	WorkerInfoGcsService.grpc_client.ReportWorkerFailure - 5 total (0 active), CPU time: mean = 9.030 us, total = 45.152 us
[state-dump] 	InternalPubSubGcsService.grpc_client.GcsSubscriberPoll - 5 total (1 active), CPU time: mean = 59.519 ms, total = 297.595 ms
[state-dump] 	InternalPubSubGcsService.grpc_client.GcsSubscriberCommandBatch - 3 total (0 active), CPU time: mean = 68.436 us, total = 205.309 us
[state-dump] 	Subscriber.HandlePublishedMessage_GCS_JOB_CHANNEL - 2 total (0 active), CPU time: mean = 35.076 ms, total = 70.152 ms
[state-dump] 	Subscriber.HandlePublishedMessage_WORKER_OBJECT_LOCATIONS_CHANNEL - 2 total (0 active), CPU time: mean = 32.551 ms, total = 65.101 ms
[state-dump] 	JobInfoGcsService.grpc_client.AddJob - 2 total (0 active), CPU time: mean = 17.572 ms, total = 35.143 ms
[state-dump] 	AgentManagerService.grpc_server.RegisterAgent - 1 total (0 active), CPU time: mean = 367.585 ms, total = 367.585 ms
[state-dump] 	NodeInfoGcsService.grpc_client.GetInternalConfig - 1 total (0 active), CPU time: mean = 34.694 ms, total = 34.694 ms
[state-dump] 	NodeInfoGcsService.grpc_client.GetAllNodeInfo - 1 total (0 active), CPU time: mean = 85.179 us, total = 85.179 us
[state-dump] 	JobInfoGcsService.grpc_client.GetAllJobInfo - 1 total (0 active), CPU time: mean = 15.018 us, total = 15.018 us
[state-dump] 	NodeInfoGcsService.grpc_client.RegisterNode - 1 total (0 active), CPU time: mean = 486.057 us, total = 486.057 us
[state-dump] DebugString() time ms: 0
[state-dump] 
[state-dump] 
[2022-06-20 22:55:01,417 I 128931 128931] (raylet) node_manager.cc:652: Sending Python GC request to 7 local workers to clean up Python cyclic references.
[2022-06-20 22:55:01,457 I 128931 128962] (raylet) store.cc:546: ========== Plasma store: =================
Current usage: 0.0378867 / 200 GB
- num bytes created total: 91567338
0 pending objects of total size 0MB
- objects spillable: 10
- bytes spillable: 37886737
- objects unsealed: 0
- bytes unsealed: 0
- objects in use: 10
- bytes in use: 37886737
- objects evictable: 0
- bytes evictable: 0

- objects created by worker: 10
- bytes created by worker: 37886737
- objects restored: 0
- bytes restored: 0
- objects received: 0
- bytes received: 0
- objects errored: 0
- bytes errored: 0

[2022-06-20 22:55:03,744 I 128931 128931] (raylet) node_manager.cc:538: [state-dump] Event stats:
[state-dump] 
[state-dump] 
[state-dump] Global stats: 24238 total (37 active)
[state-dump] Queueing time: mean = 94.180 ms, max = 192.884 s, min = -0.067 s, total = 2282.739 s
[state-dump] Execution time:  mean = 4.423 ms, total = 107.199 s
[state-dump] Event stats:
[state-dump] 	ObjectManager.UpdateAvailableMemory - 4796 total (0 active), CPU time: mean = 886.365 us, total = 4.251 s
[state-dump] 	NodeManagerService.grpc_server.RequestResourceReport - 4254 total (0 active), CPU time: mean = 3.504 ms, total = 14.907 s
[state-dump] 	NodeManagerService.grpc_server.UpdateResourceUsage - 4241 total (0 active), CPU time: mean = 1.660 ms, total = 7.041 s
[state-dump] 	RayletWorkerPool.deadline_timer.kill_idle_workers - 2449 total (1 active), CPU time: mean = 3.501 ms, total = 8.574 s
[state-dump] 	NodeManagerService.grpc_server.GetGcsServerAddress - 1731 total (7 active), CPU time: mean = 1.413 ms, total = 2.445 s
[state-dump] 	NodeManagerService.grpc_server.ReportWorkerBacklog - 1714 total (0 active), CPU time: mean = 1.998 ms, total = 3.425 s
[state-dump] 	CoreWorkerService.grpc_client.GetCoreWorkerStats - 1353 total (7 active), CPU time: mean = 2.908 ms, total = 3.934 s
[state-dump] 	NodeManagerService.grpc_server.GetResourceLoad - 578 total (0 active), CPU time: mean = 5.301 ms, total = 3.064 s
[state-dump] 	HeartbeatInfoGcsService.grpc_client.ReportHeartbeat - 537 total (0 active), CPU time: mean = 4.002 ms, total = 2.149 s
[state-dump] 	UNKNOWN - 527 total (1 active), CPU time: mean = 11.861 ms, total = 6.251 s
[state-dump] 	GcsClient.deadline_timer.check_gcs_connection - 527 total (1 active), CPU time: mean = 3.209 ms, total = 1.691 s
[state-dump] 	NodeManager.deadline_timer.flush_free_objects - 526 total (1 active), CPU time: mean = 3.292 ms, total = 1.732 s
[state-dump] 	NodeManagerService.grpc_server.GetNodeStats - 414 total (0 active), CPU time: mean = 37.705 ms, total = 15.610 s
[state-dump] 	ClientConnection.async_read.ReadBufferAsync - 179 total (7 active), CPU time: mean = 16.257 ms, total = 2.910 s
[state-dump] 	NodeManager.deadline_timer.record_metrics - 114 total (1 active), CPU time: mean = 64.923 ms, total = 7.401 s
[state-dump] 	NodeManager.deadline_timer.debug_state_dump - 59 total (1 active), CPU time: mean = 268.109 ms, total = 15.818 s
[state-dump] 	CoreWorkerService.grpc_client.PubsubCommandBatch - 36 total (0 active), CPU time: mean = 697.327 us, total = 25.104 ms
[state-dump] 	ObjectManager.ObjectAdded - 27 total (0 active), CPU time: mean = 53.225 ms, total = 1.437 s
[state-dump] 	CoreWorkerService.grpc_client.PubsubLongPolling - 19 total (1 active), CPU time: mean = 68.074 ms, total = 1.293 s
[state-dump] 	CoreWorkerService.grpc_client.UpdateObjectLocationBatch - 18 total (0 active), CPU time: mean = 4.957 ms, total = 89.227 ms
[state-dump] 	ObjectManager.ObjectDeleted - 17 total (0 active), CPU time: mean = 5.083 ms, total = 86.408 ms
[state-dump] 	NodeManagerService.grpc_server.PinObjectIDs - 15 total (0 active), CPU time: mean = 46.422 ms, total = 696.329 ms
[state-dump] 	ClientConnection.async_write.DoAsyncWrites - 12 total (0 active), CPU time: mean = 819.361 us, total = 9.832 ms
[state-dump] 	NodeManagerService.grpc_server.GetSystemConfig - 12 total (0 active), CPU time: mean = 2.580 ms, total = 30.960 ms
[state-dump] 	NodeManagerService.grpc_server.RequestWorkerLease - 10 total (0 active), CPU time: mean = 32.661 ms, total = 326.614 ms
[state-dump] 	Subscriber.HandlePublishedMessage_WORKER_OBJECT_EVICTION - 10 total (0 active), CPU time: mean = 29.138 us, total = 291.380 us
[state-dump] 	NodeManager.deadline_timer.print_event_loop_stats - 10 total (1 active, 1 running), CPU time: mean = 106.909 ms, total = 1.069 s
[state-dump] 	PeriodicalRunner.RunFnPeriodically - 7 total (0 active), CPU time: mean = 243.532 us, total = 1.705 ms
[state-dump] 	CoreWorkerService.grpc_client.LocalGC - 7 total (7 active), CPU time: mean = 0.000 s, total = 0.000 s
[state-dump] 	Subscriber.HandlePublishedMessage_GCS_WORKER_DELTA_CHANNEL - 5 total (0 active), CPU time: mean = 1.076 us, total = 5.379 us
[state-dump] 	RuntimeEnvService.grpc_client.GetOrCreateRuntimeEnv - 5 total (0 active), CPU time: mean = 8.817 ms, total = 44.085 ms
[state-dump] 	CoreWorkerService.grpc_client.DirectActorCallArgWaitComplete - 5 total (0 active), CPU time: mean = 3.011 ms, total = 15.053 ms
[state-dump] 	WorkerInfoGcsService.grpc_client.ReportWorkerFailure - 5 total (0 active), CPU time: mean = 9.030 us, total = 45.152 us
[state-dump] 	InternalPubSubGcsService.grpc_client.GcsSubscriberPoll - 5 total (1 active), CPU time: mean = 59.519 ms, total = 297.595 ms
[state-dump] 	InternalPubSubGcsService.grpc_client.GcsSubscriberCommandBatch - 3 total (0 active), CPU time: mean = 68.436 us, total = 205.309 us
[state-dump] 	Subscriber.HandlePublishedMessage_GCS_JOB_CHANNEL - 2 total (0 active), CPU time: mean = 35.076 ms, total = 70.152 ms
[state-dump] 	JobInfoGcsService.grpc_client.AddJob - 2 total (0 active), CPU time: mean = 17.572 ms, total = 35.143 ms
[state-dump] 	Subscriber.HandlePublishedMessage_WORKER_OBJECT_LOCATIONS_CHANNEL - 2 total (0 active), CPU time: mean = 32.551 ms, total = 65.101 ms
[state-dump] 	AgentManagerService.grpc_server.RegisterAgent - 1 total (0 active), CPU time: mean = 367.585 ms, total = 367.585 ms
[state-dump] 	NodeInfoGcsService.grpc_client.RegisterNode - 1 total (0 active), CPU time: mean = 486.057 us, total = 486.057 us
[state-dump] 	NodeInfoGcsService.grpc_client.GetInternalConfig - 1 total (0 active), CPU time: mean = 34.694 ms, total = 34.694 ms
[state-dump] 	NodeInfoGcsService.grpc_client.GetAllNodeInfo - 1 total (0 active), CPU time: mean = 85.179 us, total = 85.179 us
[state-dump] 	JobInfoGcsService.grpc_client.GetAllJobInfo - 1 total (0 active), CPU time: mean = 15.018 us, total = 15.018 us
[state-dump] 
[state-dump] NodeManager:
[state-dump] Node ID: 7562cb0081c73f4ed2ac21d1956887bd794b724f1b8c157f4e02d603
[state-dump] Node name: 10.140.1.109
[state-dump] InitialConfigResources: {CPU: 1280000, node:10.140.1.109: 10000, GPU: 80000, object_store_memory: 2000000000000000, memory: 8693891676160000, accelerator_type:A100: 10000}
[state-dump] ClusterTaskManager:
[state-dump] ========== Node: 7562cb0081c73f4ed2ac21d1956887bd794b724f1b8c157f4e02d603 =================
[state-dump] Infeasible queue length: 0
[state-dump] Schedule queue length: 0
[state-dump] Dispatch queue length: 0
[state-dump] num_waiting_for_resource: 0
[state-dump] num_waiting_for_plasma_memory: 0
[state-dump] num_waiting_for_remote_node_resources: 0
[state-dump] num_worker_not_started_by_job_config_not_exist: 0
[state-dump] num_worker_not_started_by_registration_timeout: 0
[state-dump] num_worker_not_started_by_process_rate_limit: 0
[state-dump] num_tasks_waiting_for_workers: 0
[state-dump] num_cancelled_tasks: 0
[state-dump] cluster_resource_scheduler state: 
[state-dump] Local id: -110938788179330527 Local resources: {object_store_memory: [1999810566390000]/[2000000000000000], node:10.140.1.109: [10000]/[10000], memory: [8693891676160000]/[8693891676160000], CPU: [1230000]/[1280000], accelerator_type:A100: [10000]/[10000], GPU: [0, 0, 0, 0, 0, 10000, 10000, 10000]/[10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000]}node id: -110938788179330527{CPU: 1230000/1280000, accelerator_type:A100: 10000/10000, object_store_memory: 1999810566390000/2000000000000000, memory: 8693891676160000/8693891676160000, GPU: 30000/80000, node:10.140.1.109: 10000/10000}
[state-dump] Waiting tasks size: 0
[state-dump] Number of executing tasks: 5
[state-dump] Number of pinned task arguments: 0
[state-dump] Number of total spilled tasks: 0
[state-dump] Number of spilled waiting tasks: 0
[state-dump] Number of spilled unschedulable tasks: 0
[state-dump] Resource usage {
[state-dump]     - (language=PYTHON actor_or_task=HloCostModelProfileWorker.__init__ pid=840): {CPU: 1.000000}, {GPU: 1.000000}
[state-dump]     - (language=PYTHON actor_or_task=HloCostModelProfileWorker.__init__ pid=839): {CPU: 1.000000}, {GPU: 1.000000}
[state-dump]     - (language=PYTHON actor_or_task=HloCostModelProfileWorker.__init__ pid=838): {CPU: 1.000000}, {GPU: 1.000000}
[state-dump]     - (language=PYTHON actor_or_task=HloCostModelProfileWorker.__init__ pid=837): {GPU: 1.000000}, {CPU: 1.000000}
[state-dump]     - (language=PYTHON actor_or_task=HloCostModelProfileWorker.__init__ pid=841): {CPU: 1.000000}, {GPU: 1.000000}
[state-dump] }
[state-dump] Running tasks by scheduling class:
[state-dump]     - {depth=1 function_descriptor={type=PythonFunctionDescriptor, module_name=alpa.pipeline_parallel.stage_profiling, class_name=HloCostModelProfileWorker, function_name=__init__, function_hash=08df8f84e6504bc9bf96a25773d558b4} scheduling_strategy=default_scheduling_strategy {
[state-dump] }
[state-dump]  resource_set={CPU : 1, GPU : 1, }}: 5/128
[state-dump] ==================================================
[state-dump] 
[state-dump] ClusterResources:
[state-dump] LocalObjectManager:
[state-dump] - num pinned objects: 5
[state-dump] - pinned objects size: 18943361
[state-dump] - num objects pending restore: 0
[state-dump] - num objects pending spill: 0
[state-dump] - num bytes pending spill: 0
[state-dump] - cumulative spill requests: 0
[state-dump] - cumulative restore requests: 0
[state-dump] 
[state-dump] ObjectManager:
[state-dump] - num local objects: 10
[state-dump] - num unfulfilled push requests: 0
[state-dump] - num pull requests: 0
[state-dump] - num chunks received total: 0
[state-dump] - num chunks received failed (all): 0
[state-dump] - num chunks received failed / cancelled: 0
[state-dump] - num chunks received failed / plasma error: 0
[state-dump] Event stats:
[state-dump] Global stats: 6 total (0 active)
[state-dump] Queueing time: mean = 17.216 us, max = 19.189 us, min = 15.950 us, total = 103.297 us
[state-dump] Execution time:  mean = 6.995 us, total = 41.972 us
[state-dump] Event stats:
[state-dump] 	ObjectManager.FreeObjects - 6 total (0 active), CPU time: mean = 6.995 us, total = 41.972 us
[state-dump] PushManager:
[state-dump] - num pushes in flight: 0
[state-dump] - num chunks in flight: 0
[state-dump] - num chunks remaining: 0
[state-dump] - max chunks allowed: 409
[state-dump] OwnershipBasedObjectDirectory:
[state-dump] - num listeners: 0
[state-dump] - cumulative location updates: 370
[state-dump] - num location updates per second: 0.000
[state-dump] - num location lookups per second: 0.000
[state-dump] - num locations added per second: 0.000
[state-dump] - num locations removed per second: 0.000
[state-dump] BufferPool:
[state-dump] - create buffer state map size: 0
[state-dump] PullManager:
[state-dump] - num bytes available for pulled objects: 199962113263
[state-dump] - num bytes being pulled (all): 0
[state-dump] - num bytes being pulled / pinned: 0
[state-dump] - num get request bundles: 0
[state-dump] - num wait request bundles: 0
[state-dump] - num task request bundles: 0
[state-dump] - first get request bundle: N/A
[state-dump] - first wait request bundle: N/A
[state-dump] - first task request bundle: N/A
[state-dump] - num objects queued: 0
[state-dump] - num objects actively pulled (all): 0
[state-dump] - num objects actively pulled / pinned: 0
[state-dump] - num bundles being pulled: 0
[state-dump] - num pull retries: 0
[state-dump] - max timeout seconds: 0
[state-dump] - max timeout request is already processed. No entry.
[state-dump] 
[state-dump] WorkerPool:
[state-dump] - registered jobs: 2
[state-dump] - process_failed_job_config_missing: 0
[state-dump] - process_failed_rate_limited: 0
[state-dump] - process_failed_pending_registration: 0
[state-dump] - process_failed_runtime_env_setup_failed: 0
[state-dump] - num JAVA workers: 0
[state-dump] - num JAVA drivers: 0
[state-dump] - num object spill callbacks queued: 0
[state-dump] - num object restore queued: 0
[state-dump] - num util functions queued: 0
[state-dump] - num PYTHON workers: 5
[state-dump] - num PYTHON drivers: 2
[state-dump] - num object spill callbacks queued: 0
[state-dump] - num object restore queued: 0
[state-dump] - num util functions queued: 0
[state-dump] - num idle workers: 0
[state-dump] TaskDependencyManager:
[state-dump] - task deps map size: 0
[state-dump] - get req map size: 0
[state-dump] - wait req map size: 0
[state-dump] - local objects map size: 10
[state-dump] WaitManager:
[state-dump] - num active wait requests: 0
[state-dump] Subscriber:
[state-dump] Channel WORKER_REF_REMOVED_CHANNEL
[state-dump] - cumulative subscribe requests: 0
[state-dump] - cumulative unsubscribe requests: 0
[state-dump] - active subscribed publishers: 0
[state-dump] - cumulative published messages: 0
[state-dump] - cumulative processed messages: 0
[state-dump] Channel WORKER_OBJECT_EVICTION
[state-dump] - cumulative subscribe requests: 15
[state-dump] - cumulative unsubscribe requests: 10
[state-dump] - active subscribed publishers: 1
[state-dump] - cumulative published messages: 10
[state-dump] - cumulative processed messages: 10
[state-dump] Channel WORKER_OBJECT_LOCATIONS_CHANNEL
[state-dump] - cumulative subscribe requests: 10
[state-dump] - cumulative unsubscribe requests: 10
[state-dump] - active subscribed publishers: 0
[state-dump] - cumulative published messages: 2
[state-dump] - cumulative processed messages: 2
[state-dump] num async plasma notifications: 0
[state-dump] Remote node managers: 
[state-dump] Event stats:
[state-dump] Global stats: 24238 total (37 active)
[state-dump] Queueing time: mean = 94.180 ms, max = 192.884 s, min = -0.067 s, total = 2282.739 s
[state-dump] Execution time:  mean = 4.423 ms, total = 107.199 s
[state-dump] Event stats:
[state-dump] 	ObjectManager.UpdateAvailableMemory - 4796 total (0 active), CPU time: mean = 886.365 us, total = 4.251 s
[state-dump] 	NodeManagerService.grpc_server.RequestResourceReport - 4254 total (0 active), CPU time: mean = 3.504 ms, total = 14.907 s
[state-dump] 	NodeManagerService.grpc_server.UpdateResourceUsage - 4241 total (0 active), CPU time: mean = 1.660 ms, total = 7.041 s
[state-dump] 	RayletWorkerPool.deadline_timer.kill_idle_workers - 2449 total (1 active), CPU time: mean = 3.501 ms, total = 8.574 s
[state-dump] 	NodeManagerService.grpc_server.GetGcsServerAddress - 1731 total (7 active), CPU time: mean = 1.413 ms, total = 2.445 s
[state-dump] 	NodeManagerService.grpc_server.ReportWorkerBacklog - 1714 total (0 active), CPU time: mean = 1.998 ms, total = 3.425 s
[state-dump] 	CoreWorkerService.grpc_client.GetCoreWorkerStats - 1353 total (7 active), CPU time: mean = 2.908 ms, total = 3.934 s
[state-dump] 	NodeManagerService.grpc_server.GetResourceLoad - 578 total (0 active), CPU time: mean = 5.301 ms, total = 3.064 s
[state-dump] 	HeartbeatInfoGcsService.grpc_client.ReportHeartbeat - 537 total (0 active), CPU time: mean = 4.002 ms, total = 2.149 s
[state-dump] 	UNKNOWN - 527 total (1 active), CPU time: mean = 11.861 ms, total = 6.251 s
[state-dump] 	GcsClient.deadline_timer.check_gcs_connection - 527 total (1 active), CPU time: mean = 3.209 ms, total = 1.691 s
[state-dump] 	NodeManager.deadline_timer.flush_free_objects - 526 total (1 active), CPU time: mean = 3.292 ms, total = 1.732 s
[state-dump] 	NodeManagerService.grpc_server.GetNodeStats - 414 total (0 active), CPU time: mean = 37.705 ms, total = 15.610 s
[state-dump] 	ClientConnection.async_read.ReadBufferAsync - 179 total (7 active), CPU time: mean = 16.257 ms, total = 2.910 s
[state-dump] 	NodeManager.deadline_timer.record_metrics - 114 total (1 active), CPU time: mean = 64.923 ms, total = 7.401 s
[state-dump] 	NodeManager.deadline_timer.debug_state_dump - 59 total (1 active), CPU time: mean = 268.109 ms, total = 15.818 s
[state-dump] 	CoreWorkerService.grpc_client.PubsubCommandBatch - 36 total (0 active), CPU time: mean = 697.327 us, total = 25.104 ms
[state-dump] 	ObjectManager.ObjectAdded - 27 total (0 active), CPU time: mean = 53.225 ms, total = 1.437 s
[state-dump] 	CoreWorkerService.grpc_client.PubsubLongPolling - 19 total (1 active), CPU time: mean = 68.074 ms, total = 1.293 s
[state-dump] 	CoreWorkerService.grpc_client.UpdateObjectLocationBatch - 18 total (0 active), CPU time: mean = 4.957 ms, total = 89.227 ms
[state-dump] 	ObjectManager.ObjectDeleted - 17 total (0 active), CPU time: mean = 5.083 ms, total = 86.408 ms
[state-dump] 	NodeManagerService.grpc_server.PinObjectIDs - 15 total (0 active), CPU time: mean = 46.422 ms, total = 696.329 ms
[state-dump] 	ClientConnection.async_write.DoAsyncWrites - 12 total (0 active), CPU time: mean = 819.361 us, total = 9.832 ms
[state-dump] 	NodeManagerService.grpc_server.GetSystemConfig - 12 total (0 active), CPU time: mean = 2.580 ms, total = 30.960 ms
[state-dump] 	NodeManagerService.grpc_server.RequestWorkerLease - 10 total (0 active), CPU time: mean = 32.661 ms, total = 326.614 ms
[state-dump] 	Subscriber.HandlePublishedMessage_WORKER_OBJECT_EVICTION - 10 total (0 active), CPU time: mean = 29.138 us, total = 291.380 us
[state-dump] 	NodeManager.deadline_timer.print_event_loop_stats - 10 total (1 active, 1 running), CPU time: mean = 106.909 ms, total = 1.069 s
[state-dump] 	PeriodicalRunner.RunFnPeriodically - 7 total (0 active), CPU time: mean = 243.532 us, total = 1.705 ms
[state-dump] 	CoreWorkerService.grpc_client.LocalGC - 7 total (7 active), CPU time: mean = 0.000 s, total = 0.000 s
[state-dump] 	Subscriber.HandlePublishedMessage_GCS_WORKER_DELTA_CHANNEL - 5 total (0 active), CPU time: mean = 1.076 us, total = 5.379 us
[state-dump] 	RuntimeEnvService.grpc_client.GetOrCreateRuntimeEnv - 5 total (0 active), CPU time: mean = 8.817 ms, total = 44.085 ms
[state-dump] 	CoreWorkerService.grpc_client.DirectActorCallArgWaitComplete - 5 total (0 active), CPU time: mean = 3.011 ms, total = 15.053 ms
[state-dump] 	WorkerInfoGcsService.grpc_client.ReportWorkerFailure - 5 total (0 active), CPU time: mean = 9.030 us, total = 45.152 us
[state-dump] 	InternalPubSubGcsService.grpc_client.GcsSubscriberPoll - 5 total (1 active), CPU time: mean = 59.519 ms, total = 297.595 ms
[state-dump] 	InternalPubSubGcsService.grpc_client.GcsSubscriberCommandBatch - 3 total (0 active), CPU time: mean = 68.436 us, total = 205.309 us
[state-dump] 	Subscriber.HandlePublishedMessage_GCS_JOB_CHANNEL - 2 total (0 active), CPU time: mean = 35.076 ms, total = 70.152 ms
[state-dump] 	JobInfoGcsService.grpc_client.AddJob - 2 total (0 active), CPU time: mean = 17.572 ms, total = 35.143 ms
[state-dump] 	Subscriber.HandlePublishedMessage_WORKER_OBJECT_LOCATIONS_CHANNEL - 2 total (0 active), CPU time: mean = 32.551 ms, total = 65.101 ms
[state-dump] 	AgentManagerService.grpc_server.RegisterAgent - 1 total (0 active), CPU time: mean = 367.585 ms, total = 367.585 ms
[state-dump] 	NodeInfoGcsService.grpc_client.RegisterNode - 1 total (0 active), CPU time: mean = 486.057 us, total = 486.057 us
[state-dump] 	NodeInfoGcsService.grpc_client.GetInternalConfig - 1 total (0 active), CPU time: mean = 34.694 ms, total = 34.694 ms
[state-dump] 	NodeInfoGcsService.grpc_client.GetAllNodeInfo - 1 total (0 active), CPU time: mean = 85.179 us, total = 85.179 us
[state-dump] 	JobInfoGcsService.grpc_client.GetAllJobInfo - 1 total (0 active), CPU time: mean = 15.018 us, total = 15.018 us
[state-dump] DebugString() time ms: 0
[state-dump] 
[state-dump] 
[2022-06-20 22:56:01,884 I 128931 128962] (raylet) store.cc:546: ========== Plasma store: =================
Current usage: 0.0378867 / 200 GB
- num bytes created total: 91567338
0 pending objects of total size 0MB
- objects spillable: 5
- bytes spillable: 18943376
- objects unsealed: 0
- bytes unsealed: 0
- objects in use: 10
- bytes in use: 37886737
- objects evictable: 0
- bytes evictable: 0

- objects created by worker: 10
- bytes created by worker: 37886737
- objects restored: 0
- bytes restored: 0
- objects received: 0
- bytes received: 0
- objects errored: 0
- bytes errored: 0

[2022-06-20 22:56:03,746 I 128931 128931] (raylet) node_manager.cc:538: [state-dump] Event stats:
[state-dump] 
[state-dump] 
[state-dump] Global stats: 27562 total (16 active)
[state-dump] Queueing time: mean = 103.511 ms, max = 192.884 s, min = -0.067 s, total = 2852.969 s
[state-dump] Execution time:  mean = 3.989 ms, total = 109.944 s
[state-dump] Event stats:
[state-dump] 	ObjectManager.UpdateAvailableMemory - 5368 total (0 active), CPU time: mean = 806.313 us, total = 4.328 s
[state-dump] 	NodeManagerService.grpc_server.RequestResourceReport - 4757 total (0 active), CPU time: mean = 3.173 ms, total = 15.093 s
[state-dump] 	NodeManagerService.grpc_server.UpdateResourceUsage - 4744 total (0 active), CPU time: mean = 1.492 ms, total = 7.078 s
[state-dump] 	RayletWorkerPool.deadline_timer.kill_idle_workers - 2739 total (1 active), CPU time: mean = 3.190 ms, total = 8.737 s
[state-dump] 	NodeManagerService.grpc_server.GetGcsServerAddress - 2102 total (0 active), CPU time: mean = 1.183 ms, total = 2.488 s
[state-dump] 	NodeManagerService.grpc_server.ReportWorkerBacklog - 2078 total (0 active), CPU time: mean = 1.800 ms, total = 3.740 s
[state-dump] 	CoreWorkerService.grpc_client.GetCoreWorkerStats - 1668 total (0 active), CPU time: mean = 2.513 ms, total = 4.192 s
[state-dump] 	NodeManagerService.grpc_server.GetResourceLoad - 635 total (0 active), CPU time: mean = 4.875 ms, total = 3.096 s
[state-dump] 	HeartbeatInfoGcsService.grpc_client.ReportHeartbeat - 596 total (0 active), CPU time: mean = 3.649 ms, total = 2.175 s
[state-dump] 	GcsClient.deadline_timer.check_gcs_connection - 586 total (1 active), CPU time: mean = 2.946 ms, total = 1.726 s
[state-dump] 	UNKNOWN - 586 total (1 active), CPU time: mean = 10.824 ms, total = 6.343 s
[state-dump] 	NodeManager.deadline_timer.flush_free_objects - 585 total (1 active), CPU time: mean = 3.015 ms, total = 1.764 s
[state-dump] 	NodeManagerService.grpc_server.GetNodeStats - 459 total (0 active), CPU time: mean = 34.682 ms, total = 15.919 s
[state-dump] 	ClientConnection.async_read.ReadBufferAsync - 219 total (7 active), CPU time: mean = 15.788 ms, total = 3.458 s
[state-dump] 	NodeManager.deadline_timer.record_metrics - 126 total (1 active), CPU time: mean = 59.150 ms, total = 7.453 s
[state-dump] 	NodeManager.deadline_timer.debug_state_dump - 65 total (1 active), CPU time: mean = 245.592 ms, total = 15.963 s
[state-dump] 	CoreWorkerService.grpc_client.PubsubCommandBatch - 38 total (0 active), CPU time: mean = 9.437 ms, total = 358.589 ms
[state-dump] 	ObjectManager.ObjectAdded - 27 total (0 active), CPU time: mean = 53.225 ms, total = 1.437 s
[state-dump] 	CoreWorkerService.grpc_client.PubsubLongPolling - 21 total (1 active), CPU time: mean = 62.297 ms, total = 1.308 s
[state-dump] 	CoreWorkerService.grpc_client.UpdateObjectLocationBatch - 18 total (0 active), CPU time: mean = 4.957 ms, total = 89.227 ms
[state-dump] 	ObjectManager.ObjectDeleted - 17 total (0 active), CPU time: mean = 5.083 ms, total = 86.408 ms
[state-dump] 	NodeManagerService.grpc_server.PinObjectIDs - 15 total (0 active), CPU time: mean = 46.422 ms, total = 696.329 ms
[state-dump] 	ClientConnection.async_write.DoAsyncWrites - 12 total (0 active), CPU time: mean = 819.361 us, total = 9.832 ms
[state-dump] 	NodeManagerService.grpc_server.GetSystemConfig - 12 total (0 active), CPU time: mean = 2.580 ms, total = 30.960 ms
[state-dump] 	NodeManager.deadline_timer.print_event_loop_stats - 11 total (1 active, 1 running), CPU time: mean = 99.034 ms, total = 1.089 s
[state-dump] 	CoreWorkerService.grpc_client.DirectActorCallArgWaitComplete - 10 total (0 active), CPU time: mean = 1.508 ms, total = 15.075 ms
[state-dump] 	NodeManagerService.grpc_server.RequestWorkerLease - 10 total (0 active), CPU time: mean = 32.661 ms, total = 326.614 ms
[state-dump] 	Subscriber.HandlePublishedMessage_WORKER_OBJECT_EVICTION - 10 total (0 active), CPU time: mean = 29.138 us, total = 291.380 us
[state-dump] 	PeriodicalRunner.RunFnPeriodically - 7 total (0 active), CPU time: mean = 243.532 us, total = 1.705 ms
[state-dump] 	CoreWorkerService.grpc_client.LocalGC - 7 total (0 active), CPU time: mean = 3.693 ms, total = 25.848 ms
[state-dump] 	Subscriber.HandlePublishedMessage_GCS_WORKER_DELTA_CHANNEL - 5 total (0 active), CPU time: mean = 1.076 us, total = 5.379 us
[state-dump] 	RuntimeEnvService.grpc_client.GetOrCreateRuntimeEnv - 5 total (0 active), CPU time: mean = 8.817 ms, total = 44.085 ms
[state-dump] 	WorkerInfoGcsService.grpc_client.ReportWorkerFailure - 5 total (0 active), CPU time: mean = 9.030 us, total = 45.152 us
[state-dump] 	InternalPubSubGcsService.grpc_client.GcsSubscriberPoll - 5 total (1 active), CPU time: mean = 59.519 ms, total = 297.595 ms
[state-dump] 	InternalPubSubGcsService.grpc_client.GcsSubscriberCommandBatch - 3 total (0 active), CPU time: mean = 68.436 us, total = 205.309 us
[state-dump] 	Subscriber.HandlePublishedMessage_GCS_JOB_CHANNEL - 2 total (0 active), CPU time: mean = 35.076 ms, total = 70.152 ms
[state-dump] 	JobInfoGcsService.grpc_client.AddJob - 2 total (0 active), CPU time: mean = 17.572 ms, total = 35.143 ms
[state-dump] 	Subscriber.HandlePublishedMessage_WORKER_OBJECT_LOCATIONS_CHANNEL - 2 total (0 active), CPU time: mean = 32.551 ms, total = 65.101 ms
[state-dump] 	AgentManagerService.grpc_server.RegisterAgent - 1 total (0 active), CPU time: mean = 367.585 ms, total = 367.585 ms
[state-dump] 	NodeInfoGcsService.grpc_client.RegisterNode - 1 total (0 active), CPU time: mean = 486.057 us, total = 486.057 us
[state-dump] 	NodeInfoGcsService.grpc_client.GetInternalConfig - 1 total (0 active), CPU time: mean = 34.694 ms, total = 34.694 ms
[state-dump] 	NodeInfoGcsService.grpc_client.GetAllNodeInfo - 1 total (0 active), CPU time: mean = 85.179 us, total = 85.179 us
[state-dump] 	JobInfoGcsService.grpc_client.GetAllJobInfo - 1 total (0 active), CPU time: mean = 15.018 us, total = 15.018 us
[state-dump] 
[state-dump] NodeManager:
[state-dump] Node ID: 7562cb0081c73f4ed2ac21d1956887bd794b724f1b8c157f4e02d603
[state-dump] Node name: 10.140.1.109
[state-dump] InitialConfigResources: {CPU: 1280000, node:10.140.1.109: 10000, GPU: 80000, object_store_memory: 2000000000000000, memory: 8693891676160000, accelerator_type:A100: 10000}
[state-dump] ClusterTaskManager:
[state-dump] ========== Node: 7562cb0081c73f4ed2ac21d1956887bd794b724f1b8c157f4e02d603 =================
[state-dump] Infeasible queue length: 0
[state-dump] Schedule queue length: 0
[state-dump] Dispatch queue length: 0
[state-dump] num_waiting_for_resource: 0
[state-dump] num_waiting_for_plasma_memory: 0
[state-dump] num_waiting_for_remote_node_resources: 0
[state-dump] num_worker_not_started_by_job_config_not_exist: 0
[state-dump] num_worker_not_started_by_registration_timeout: 0
[state-dump] num_worker_not_started_by_process_rate_limit: 0
[state-dump] num_tasks_waiting_for_workers: 0
[state-dump] num_cancelled_tasks: 0
[state-dump] cluster_resource_scheduler state: 
[state-dump] Local id: -110938788179330527 Local resources: {object_store_memory: [1999810566390000]/[2000000000000000], node:10.140.1.109: [10000]/[10000], memory: [8693891676160000]/[8693891676160000], CPU: [1230000]/[1280000], accelerator_type:A100: [10000]/[10000], GPU: [0, 0, 0, 0, 0, 10000, 10000, 10000]/[10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000]}node id: -110938788179330527{memory: 8693891676160000/8693891676160000, GPU: 30000/80000, object_store_memory: 1999810566390000/2000000000000000, accelerator_type:A100: 10000/10000, node:10.140.1.109: 10000/10000, CPU: 1230000/1280000}
[state-dump] Waiting tasks size: 0
[state-dump] Number of executing tasks: 0
[state-dump] Number of pinned task arguments: 0
[state-dump] Number of total spilled tasks: 0
[state-dump] Number of spilled waiting tasks: 0
[state-dump] Number of spilled unschedulable tasks: 0
[state-dump] Resource usage {
[state-dump]     - (language=PYTHON actor_or_task=HloCostModelProfileWorker.__init__ pid=840): {CPU: 1.000000}, {GPU: 1.000000}
[state-dump]     - (language=PYTHON actor_or_task=HloCostModelProfileWorker.__init__ pid=839): {CPU: 1.000000}, {GPU: 1.000000}
[state-dump]     - (language=PYTHON actor_or_task=HloCostModelProfileWorker.__init__ pid=838): {CPU: 1.000000}, {GPU: 1.000000}
[state-dump]     - (language=PYTHON actor_or_task=HloCostModelProfileWorker.__init__ pid=837): {GPU: 1.000000}, {CPU: 1.000000}
[state-dump]     - (language=PYTHON actor_or_task=HloCostModelProfileWorker.__init__ pid=841): {CPU: 1.000000}, {GPU: 1.000000}
[state-dump] }
[state-dump] Running tasks by scheduling class:
[state-dump] ==================================================
[state-dump] 
[state-dump] ClusterResources:
[state-dump] LocalObjectManager:
[state-dump] - num pinned objects: 5
[state-dump] - pinned objects size: 18943361
[state-dump] - num objects pending restore: 0
[state-dump] - num objects pending spill: 0
[state-dump] - num bytes pending spill: 0
[state-dump] - cumulative spill requests: 0
[state-dump] - cumulative restore requests: 0
[state-dump] 
[state-dump] ObjectManager:
[state-dump] - num local objects: 10
[state-dump] - num unfulfilled push requests: 0
[state-dump] - num pull requests: 0
[state-dump] - num chunks received total: 0
[state-dump] - num chunks received failed (all): 0
[state-dump] - num chunks received failed / cancelled: 0
[state-dump] - num chunks received failed / plasma error: 0
[state-dump] Event stats:
[state-dump] Global stats: 6 total (0 active)
[state-dump] Queueing time: mean = 17.216 us, max = 19.189 us, min = 15.950 us, total = 103.297 us
[state-dump] Execution time:  mean = 6.995 us, total = 41.972 us
[state-dump] Event stats:
[state-dump] 	ObjectManager.FreeObjects - 6 total (0 active), CPU time: mean = 6.995 us, total = 41.972 us
[state-dump] PushManager:
[state-dump] - num pushes in flight: 0
[state-dump] - num chunks in flight: 0
[state-dump] - num chunks remaining: 0
[state-dump] - max chunks allowed: 409
[state-dump] OwnershipBasedObjectDirectory:
[state-dump] - num listeners: 0
[state-dump] - cumulative location updates: 370
[state-dump] - num location updates per second: 0.000
[state-dump] - num location lookups per second: 0.000
[state-dump] - num locations added per second: 0.000
[state-dump] - num locations removed per second: 0.000
[state-dump] BufferPool:
[state-dump] - create buffer state map size: 0
[state-dump] PullManager:
[state-dump] - num bytes available for pulled objects: 199962113263
[state-dump] - num bytes being pulled (all): 0
[state-dump] - num bytes being pulled / pinned: 0
[state-dump] - num get request bundles: 0
[state-dump] - num wait request bundles: 0
[state-dump] - num task request bundles: 0
[state-dump] - first get request bundle: N/A
[state-dump] - first wait request bundle: N/A
[state-dump] - first task request bundle: N/A
[state-dump] - num objects queued: 0
[state-dump] - num objects actively pulled (all): 0
[state-dump] - num objects actively pulled / pinned: 0
[state-dump] - num bundles being pulled: 0
[state-dump] - num pull retries: 0
[state-dump] - max timeout seconds: 0
[state-dump] - max timeout request is already processed. No entry.
[state-dump] 
[state-dump] WorkerPool:
[state-dump] - registered jobs: 2
[state-dump] - process_failed_job_config_missing: 0
[state-dump] - process_failed_rate_limited: 0
[state-dump] - process_failed_pending_registration: 0
[state-dump] - process_failed_runtime_env_setup_failed: 0
[state-dump] - num JAVA workers: 0
[state-dump] - num JAVA drivers: 0
[state-dump] - num object spill callbacks queued: 0
[state-dump] - num object restore queued: 0
[state-dump] - num util functions queued: 0
[state-dump] - num PYTHON workers: 5
[state-dump] - num PYTHON drivers: 2
[state-dump] - num object spill callbacks queued: 0
[state-dump] - num object restore queued: 0
[state-dump] - num util functions queued: 0
[state-dump] - num idle workers: 0
[state-dump] TaskDependencyManager:
[state-dump] - task deps map size: 0
[state-dump] - get req map size: 0
[state-dump] - wait req map size: 0
[state-dump] - local objects map size: 10
[state-dump] WaitManager:
[state-dump] - num active wait requests: 0
[state-dump] Subscriber:
[state-dump] Channel WORKER_REF_REMOVED_CHANNEL
[state-dump] - cumulative subscribe requests: 0
[state-dump] - cumulative unsubscribe requests: 0
[state-dump] - active subscribed publishers: 0
[state-dump] - cumulative published messages: 0
[state-dump] - cumulative processed messages: 0
[state-dump] Channel WORKER_OBJECT_EVICTION
[state-dump] - cumulative subscribe requests: 15
[state-dump] - cumulative unsubscribe requests: 10
[state-dump] - active subscribed publishers: 1
[state-dump] - cumulative published messages: 10
[state-dump] - cumulative processed messages: 10
[state-dump] Channel WORKER_OBJECT_LOCATIONS_CHANNEL
[state-dump] - cumulative subscribe requests: 15
[state-dump] - cumulative unsubscribe requests: 15
[state-dump] - active subscribed publishers: 0
[state-dump] - cumulative published messages: 2
[state-dump] - cumulative processed messages: 2
[state-dump] num async plasma notifications: 0
[state-dump] Remote node managers: 
[state-dump] Event stats:
[state-dump] Global stats: 27562 total (16 active)
[state-dump] Queueing time: mean = 103.511 ms, max = 192.884 s, min = -0.067 s, total = 2852.969 s
[state-dump] Execution time:  mean = 3.989 ms, total = 109.944 s
[state-dump] Event stats:
[state-dump] 	ObjectManager.UpdateAvailableMemory - 5368 total (0 active), CPU time: mean = 806.313 us, total = 4.328 s
[state-dump] 	NodeManagerService.grpc_server.RequestResourceReport - 4757 total (0 active), CPU time: mean = 3.173 ms, total = 15.093 s
[state-dump] 	NodeManagerService.grpc_server.UpdateResourceUsage - 4744 total (0 active), CPU time: mean = 1.492 ms, total = 7.078 s
[state-dump] 	RayletWorkerPool.deadline_timer.kill_idle_workers - 2739 total (1 active), CPU time: mean = 3.190 ms, total = 8.737 s
[state-dump] 	NodeManagerService.grpc_server.GetGcsServerAddress - 2102 total (0 active), CPU time: mean = 1.183 ms, total = 2.488 s
[state-dump] 	NodeManagerService.grpc_server.ReportWorkerBacklog - 2078 total (0 active), CPU time: mean = 1.800 ms, total = 3.740 s
[state-dump] 	CoreWorkerService.grpc_client.GetCoreWorkerStats - 1668 total (0 active), CPU time: mean = 2.513 ms, total = 4.192 s
[state-dump] 	NodeManagerService.grpc_server.GetResourceLoad - 635 total (0 active), CPU time: mean = 4.875 ms, total = 3.096 s
[state-dump] 	HeartbeatInfoGcsService.grpc_client.ReportHeartbeat - 596 total (0 active), CPU time: mean = 3.649 ms, total = 2.175 s
[state-dump] 	GcsClient.deadline_timer.check_gcs_connection - 586 total (1 active), CPU time: mean = 2.946 ms, total = 1.726 s
[state-dump] 	UNKNOWN - 586 total (1 active), CPU time: mean = 10.824 ms, total = 6.343 s
[state-dump] 	NodeManager.deadline_timer.flush_free_objects - 585 total (1 active), CPU time: mean = 3.015 ms, total = 1.764 s
[state-dump] 	NodeManagerService.grpc_server.GetNodeStats - 459 total (0 active), CPU time: mean = 34.682 ms, total = 15.919 s
[state-dump] 	ClientConnection.async_read.ReadBufferAsync - 219 total (7 active), CPU time: mean = 15.788 ms, total = 3.458 s
[state-dump] 	NodeManager.deadline_timer.record_metrics - 126 total (1 active), CPU time: mean = 59.150 ms, total = 7.453 s
[state-dump] 	NodeManager.deadline_timer.debug_state_dump - 65 total (1 active), CPU time: mean = 245.592 ms, total = 15.963 s
[state-dump] 	CoreWorkerService.grpc_client.PubsubCommandBatch - 38 total (0 active), CPU time: mean = 9.437 ms, total = 358.589 ms
[state-dump] 	ObjectManager.ObjectAdded - 27 total (0 active), CPU time: mean = 53.225 ms, total = 1.437 s
[state-dump] 	CoreWorkerService.grpc_client.PubsubLongPolling - 21 total (1 active), CPU time: mean = 62.297 ms, total = 1.308 s
[state-dump] 	CoreWorkerService.grpc_client.UpdateObjectLocationBatch - 18 total (0 active), CPU time: mean = 4.957 ms, total = 89.227 ms
[state-dump] 	ObjectManager.ObjectDeleted - 17 total (0 active), CPU time: mean = 5.083 ms, total = 86.408 ms
[state-dump] 	NodeManagerService.grpc_server.PinObjectIDs - 15 total (0 active), CPU time: mean = 46.422 ms, total = 696.329 ms
[state-dump] 	ClientConnection.async_write.DoAsyncWrites - 12 total (0 active), CPU time: mean = 819.361 us, total = 9.832 ms
[state-dump] 	NodeManagerService.grpc_server.GetSystemConfig - 12 total (0 active), CPU time: mean = 2.580 ms, total = 30.960 ms
[state-dump] 	NodeManager.deadline_timer.print_event_loop_stats - 11 total (1 active, 1 running), CPU time: mean = 99.034 ms, total = 1.089 s
[state-dump] 	CoreWorkerService.grpc_client.DirectActorCallArgWaitComplete - 10 total (0 active), CPU time: mean = 1.508 ms, total = 15.075 ms
[state-dump] 	NodeManagerService.grpc_server.RequestWorkerLease - 10 total (0 active), CPU time: mean = 32.661 ms, total = 326.614 ms
[state-dump] 	Subscriber.HandlePublishedMessage_WORKER_OBJECT_EVICTION - 10 total (0 active), CPU time: mean = 29.138 us, total = 291.380 us
[state-dump] 	PeriodicalRunner.RunFnPeriodically - 7 total (0 active), CPU time: mean = 243.532 us, total = 1.705 ms
[state-dump] 	CoreWorkerService.grpc_client.LocalGC - 7 total (0 active), CPU time: mean = 3.693 ms, total = 25.848 ms
[state-dump] 	Subscriber.HandlePublishedMessage_GCS_WORKER_DELTA_CHANNEL - 5 total (0 active), CPU time: mean = 1.076 us, total = 5.379 us
[state-dump] 	RuntimeEnvService.grpc_client.GetOrCreateRuntimeEnv - 5 total (0 active), CPU time: mean = 8.817 ms, total = 44.085 ms
[state-dump] 	WorkerInfoGcsService.grpc_client.ReportWorkerFailure - 5 total (0 active), CPU time: mean = 9.030 us, total = 45.152 us
[state-dump] 	InternalPubSubGcsService.grpc_client.GcsSubscriberPoll - 5 total (1 active), CPU time: mean = 59.519 ms, total = 297.595 ms
[state-dump] 	InternalPubSubGcsService.grpc_client.GcsSubscriberCommandBatch - 3 total (0 active), CPU time: mean = 68.436 us, total = 205.309 us
[state-dump] 	Subscriber.HandlePublishedMessage_GCS_JOB_CHANNEL - 2 total (0 active), CPU time: mean = 35.076 ms, total = 70.152 ms
[state-dump] 	JobInfoGcsService.grpc_client.AddJob - 2 total (0 active), CPU time: mean = 17.572 ms, total = 35.143 ms
[state-dump] 	Subscriber.HandlePublishedMessage_WORKER_OBJECT_LOCATIONS_CHANNEL - 2 total (0 active), CPU time: mean = 32.551 ms, total = 65.101 ms
[state-dump] 	AgentManagerService.grpc_server.RegisterAgent - 1 total (0 active), CPU time: mean = 367.585 ms, total = 367.585 ms
[state-dump] 	NodeInfoGcsService.grpc_client.RegisterNode - 1 total (0 active), CPU time: mean = 486.057 us, total = 486.057 us
[state-dump] 	NodeInfoGcsService.grpc_client.GetInternalConfig - 1 total (0 active), CPU time: mean = 34.694 ms, total = 34.694 ms
[state-dump] 	NodeInfoGcsService.grpc_client.GetAllNodeInfo - 1 total (0 active), CPU time: mean = 85.179 us, total = 85.179 us
[state-dump] 	JobInfoGcsService.grpc_client.GetAllJobInfo - 1 total (0 active), CPU time: mean = 15.018 us, total = 15.018 us
[state-dump] DebugString() time ms: 0
[state-dump] 
[state-dump] 
[2022-06-20 22:56:13,486 I 128931 128931] (raylet) node_manager.cc:1343: NodeManager::DisconnectClient, disconnect_type=1, has creation task exception = 0
[2022-06-20 22:56:13,747 I 128931 128931] (raylet) node_manager.cc:1343: NodeManager::DisconnectClient, disconnect_type=1, has creation task exception = 0
[2022-06-20 22:56:13,747 I 128931 128931] (raylet) node_manager.cc:1343: NodeManager::DisconnectClient, disconnect_type=1, has creation task exception = 0
[2022-06-20 22:56:13,762 I 128931 128931] (raylet) node_manager.cc:1343: NodeManager::DisconnectClient, disconnect_type=1, has creation task exception = 0
[2022-06-20 22:56:13,762 I 128931 128931] (raylet) node_manager.cc:1343: NodeManager::DisconnectClient, disconnect_type=1, has creation task exception = 0
[2022-06-20 22:57:01,469 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 4611, the token 10
[2022-06-20 22:57:01,541 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 4612, the token 11
[2022-06-20 22:57:01,543 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 4613, the token 12
[2022-06-20 22:57:01,545 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 4614, the token 13
[2022-06-20 22:57:01,547 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 4615, the token 14
[2022-06-20 22:57:01,548 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 4616, the token 15
[2022-06-20 22:57:01,550 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 4617, the token 16
[2022-06-20 22:57:01,552 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 4618, the token 17
[2022-06-20 22:57:01,554 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 4619, the token 18
[2022-06-20 22:57:01,555 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 4620, the token 19
[2022-06-20 22:57:01,557 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 4621, the token 20
[2022-06-20 22:57:01,559 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 4622, the token 21
[2022-06-20 22:57:01,560 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 4623, the token 22
[2022-06-20 22:57:01,562 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 4624, the token 23
[2022-06-20 22:57:01,564 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 4625, the token 24
[2022-06-20 22:57:01,565 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 4626, the token 25
[2022-06-20 22:57:01,567 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 4627, the token 26
[2022-06-20 22:57:01,569 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 4628, the token 27
[2022-06-20 22:57:01,571 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 4629, the token 28
[2022-06-20 22:57:01,573 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 4630, the token 29
[2022-06-20 22:57:01,574 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 4631, the token 30
[2022-06-20 22:57:01,576 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 4640, the token 31
[2022-06-20 22:57:01,578 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 4641, the token 32
[2022-06-20 22:57:01,579 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 4642, the token 33
[2022-06-20 22:57:01,581 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 4643, the token 34
[2022-06-20 22:57:01,583 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 4645, the token 35
[2022-06-20 22:57:01,584 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 4647, the token 36
[2022-06-20 22:57:01,586 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 4648, the token 37
[2022-06-20 22:57:01,588 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 4651, the token 38
[2022-06-20 22:57:01,590 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 4652, the token 39
[2022-06-20 22:57:01,591 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 4653, the token 40
[2022-06-20 22:57:01,593 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 4654, the token 41
[2022-06-20 22:57:01,595 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 4655, the token 42
[2022-06-20 22:57:01,596 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 4656, the token 43
[2022-06-20 22:57:01,598 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 4657, the token 44
[2022-06-20 22:57:01,600 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 4658, the token 45
[2022-06-20 22:57:01,601 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 4659, the token 46
[2022-06-20 22:57:01,603 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 4660, the token 47
[2022-06-20 22:57:01,605 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 4661, the token 48
[2022-06-20 22:57:01,606 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 4662, the token 49
[2022-06-20 22:57:01,608 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 4663, the token 50
[2022-06-20 22:57:01,610 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 4664, the token 51
[2022-06-20 22:57:01,611 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 4665, the token 52
[2022-06-20 22:57:01,613 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 4666, the token 53
[2022-06-20 22:57:01,615 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 4669, the token 54
[2022-06-20 22:57:01,616 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 4670, the token 55
[2022-06-20 22:57:01,618 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 4671, the token 56
[2022-06-20 22:57:01,620 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 4672, the token 57
[2022-06-20 22:57:01,621 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 4673, the token 58
[2022-06-20 22:57:01,623 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 4674, the token 59
[2022-06-20 22:57:01,625 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 4675, the token 60
[2022-06-20 22:57:01,627 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 4677, the token 61
[2022-06-20 22:57:01,628 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 4678, the token 62
[2022-06-20 22:57:01,630 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 4680, the token 63
[2022-06-20 22:57:01,631 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 4681, the token 64
[2022-06-20 22:57:01,633 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 4682, the token 65
[2022-06-20 22:57:01,635 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 4683, the token 66
[2022-06-20 22:57:01,636 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 4684, the token 67
[2022-06-20 22:57:01,638 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 4685, the token 68
[2022-06-20 22:57:01,640 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 4686, the token 69
[2022-06-20 22:57:01,642 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 4687, the token 70
[2022-06-20 22:57:01,643 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 4688, the token 71
[2022-06-20 22:57:01,645 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 4689, the token 72
[2022-06-20 22:57:01,646 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 4690, the token 73
[2022-06-20 22:57:01,924 I 128931 128962] (raylet) store.cc:546: ========== Plasma store: =================
Current usage: 0.422377 / 200 GB
- num bytes created total: 513944626
0 pending objects of total size 0MB
- objects spillable: 64
- bytes spillable: 422377288
- objects unsealed: 0
- bytes unsealed: 0
- objects in use: 64
- bytes in use: 422377288
- objects evictable: 0
- bytes evictable: 0

- objects created by worker: 64
- bytes created by worker: 422377288
- objects restored: 0
- bytes restored: 0
- objects received: 0
- bytes received: 0
- objects errored: 0
- bytes errored: 0

[2022-06-20 22:57:03,756 I 128931 128931] (raylet) node_manager.cc:538: [state-dump] Event stats:
[state-dump] 
[state-dump] 
[state-dump] Global stats: 30330 total (11 active)
[state-dump] Queueing time: mean = 113.591 ms, max = 218.067 s, min = -0.067 s, total = 3445.211 s
[state-dump] Execution time:  mean = 3.905 ms, total = 118.446 s
[state-dump] Event stats:
[state-dump] 	ObjectManager.UpdateAvailableMemory - 5876 total (0 active), CPU time: mean = 811.286 us, total = 4.767 s
[state-dump] 	NodeManagerService.grpc_server.RequestResourceReport - 5211 total (0 active), CPU time: mean = 3.036 ms, total = 15.820 s
[state-dump] 	NodeManagerService.grpc_server.UpdateResourceUsage - 5197 total (0 active), CPU time: mean = 1.561 ms, total = 8.114 s
[state-dump] 	RayletWorkerPool.deadline_timer.kill_idle_workers - 2998 total (1 active), CPU time: mean = 3.080 ms, total = 9.233 s
[state-dump] 	NodeManagerService.grpc_server.GetGcsServerAddress - 2260 total (0 active), CPU time: mean = 1.160 ms, total = 2.622 s
[state-dump] 	NodeManagerService.grpc_server.ReportWorkerBacklog - 2231 total (0 active), CPU time: mean = 1.726 ms, total = 3.850 s
[state-dump] 	CoreWorkerService.grpc_client.GetCoreWorkerStats - 1797 total (0 active), CPU time: mean = 2.430 ms, total = 4.367 s
[state-dump] 	NodeManagerService.grpc_server.GetResourceLoad - 690 total (0 active), CPU time: mean = 5.414 ms, total = 3.735 s
[state-dump] 	HeartbeatInfoGcsService.grpc_client.ReportHeartbeat - 652 total (0 active), CPU time: mean = 3.453 ms, total = 2.251 s
[state-dump] 	GcsClient.deadline_timer.check_gcs_connection - 641 total (1 active), CPU time: mean = 2.984 ms, total = 1.913 s
[state-dump] 	UNKNOWN - 641 total (1 active), CPU time: mean = 10.773 ms, total = 6.905 s
[state-dump] 	NodeManager.deadline_timer.flush_free_objects - 640 total (1 active), CPU time: mean = 3.503 ms, total = 2.242 s
[state-dump] 	NodeManagerService.grpc_server.GetNodeStats - 506 total (0 active), CPU time: mean = 32.822 ms, total = 16.608 s
[state-dump] 	ClientConnection.async_read.ReadBufferAsync - 234 total (2 active), CPU time: mean = 16.469 ms, total = 3.854 s
[state-dump] 	NodeManager.deadline_timer.record_metrics - 137 total (1 active), CPU time: mean = 58.376 ms, total = 7.998 s
[state-dump] 	ObjectManager.ObjectAdded - 91 total (0 active), CPU time: mean = 18.608 ms, total = 1.693 s
[state-dump] 	NodeManagerService.grpc_server.PinObjectIDs - 79 total (0 active), CPU time: mean = 10.851 ms, total = 857.207 ms
[state-dump] 	NodeManagerService.grpc_server.RequestWorkerLease - 74 total (0 active), CPU time: mean = 8.458 ms, total = 625.856 ms
[state-dump] 	NodeManager.deadline_timer.debug_state_dump - 71 total (1 active), CPU time: mean = 234.310 ms, total = 16.636 s
[state-dump] 	CoreWorkerService.grpc_client.PubsubCommandBatch - 70 total (0 active), CPU time: mean = 5.127 ms, total = 358.859 ms
[state-dump] 	CoreWorkerService.grpc_client.UpdateObjectLocationBatch - 55 total (0 active), CPU time: mean = 2.084 ms, total = 114.636 ms
[state-dump] 	ObjectManager.ObjectDeleted - 27 total (0 active), CPU time: mean = 5.988 ms, total = 161.678 ms
[state-dump] 	CoreWorkerService.grpc_client.PubsubLongPolling - 25 total (1 active), CPU time: mean = 56.347 ms, total = 1.409 s
[state-dump] 	Subscriber.HandlePublishedMessage_WORKER_OBJECT_EVICTION - 15 total (0 active), CPU time: mean = 12.834 ms, total = 192.511 ms
[state-dump] 	ClientConnection.async_write.DoAsyncWrites - 12 total (0 active), CPU time: mean = 819.361 us, total = 9.832 ms
[state-dump] 	NodeManagerService.grpc_server.GetSystemConfig - 12 total (0 active), CPU time: mean = 2.580 ms, total = 30.960 ms
[state-dump] 	NodeManager.deadline_timer.print_event_loop_stats - 12 total (1 active, 1 running), CPU time: mean = 90.891 ms, total = 1.091 s
[state-dump] 	Subscriber.HandlePublishedMessage_GCS_WORKER_DELTA_CHANNEL - 10 total (0 active), CPU time: mean = 1.460 ms, total = 14.602 ms
[state-dump] 	WorkerInfoGcsService.grpc_client.ReportWorkerFailure - 10 total (0 active), CPU time: mean = 7.370 us, total = 73.704 us
[state-dump] 	CoreWorkerService.grpc_client.DirectActorCallArgWaitComplete - 10 total (0 active), CPU time: mean = 1.508 ms, total = 15.075 ms
[state-dump] 	InternalPubSubGcsService.grpc_client.GcsSubscriberPoll - 8 total (1 active), CPU time: mean = 37.221 ms, total = 297.767 ms
[state-dump] 	CoreWorkerService.grpc_client.LocalGC - 7 total (0 active), CPU time: mean = 3.693 ms, total = 25.848 ms
[state-dump] 	PeriodicalRunner.RunFnPeriodically - 7 total (0 active), CPU time: mean = 243.532 us, total = 1.705 ms
[state-dump] 	RuntimeEnvService.grpc_client.DeleteRuntimeEnvIfPossible - 5 total (0 active), CPU time: mean = 2.907 ms, total = 14.536 ms
[state-dump] 	RuntimeEnvService.grpc_client.GetOrCreateRuntimeEnv - 5 total (0 active), CPU time: mean = 8.817 ms, total = 44.085 ms
[state-dump] 	InternalPubSubGcsService.grpc_client.GcsSubscriberCommandBatch - 3 total (0 active), CPU time: mean = 68.436 us, total = 205.309 us
[state-dump] 	Subscriber.HandlePublishedMessage_WORKER_OBJECT_LOCATIONS_CHANNEL - 2 total (0 active), CPU time: mean = 32.551 ms, total = 65.101 ms
[state-dump] 	Subscriber.HandlePublishedMessage_GCS_JOB_CHANNEL - 2 total (0 active), CPU time: mean = 35.076 ms, total = 70.152 ms
[state-dump] 	JobInfoGcsService.grpc_client.AddJob - 2 total (0 active), CPU time: mean = 17.572 ms, total = 35.143 ms
[state-dump] 	AgentManagerService.grpc_server.RegisterAgent - 1 total (0 active), CPU time: mean = 367.585 ms, total = 367.585 ms
[state-dump] 	NodeInfoGcsService.grpc_client.GetInternalConfig - 1 total (0 active), CPU time: mean = 34.694 ms, total = 34.694 ms
[state-dump] 	NodeInfoGcsService.grpc_client.GetAllNodeInfo - 1 total (0 active), CPU time: mean = 85.179 us, total = 85.179 us
[state-dump] 	JobInfoGcsService.grpc_client.GetAllJobInfo - 1 total (0 active), CPU time: mean = 15.018 us, total = 15.018 us
[state-dump] 	NodeInfoGcsService.grpc_client.RegisterNode - 1 total (0 active), CPU time: mean = 486.057 us, total = 486.057 us
[state-dump] 
[state-dump] NodeManager:
[state-dump] Node ID: 7562cb0081c73f4ed2ac21d1956887bd794b724f1b8c157f4e02d603
[state-dump] Node name: 10.140.1.109
[state-dump] InitialConfigResources: {CPU: 1280000, node:10.140.1.109: 10000, GPU: 80000, object_store_memory: 2000000000000000, memory: 8693891676160000, accelerator_type:A100: 10000}
[state-dump] ClusterTaskManager:
[state-dump] ========== Node: 7562cb0081c73f4ed2ac21d1956887bd794b724f1b8c157f4e02d603 =================
[state-dump] Infeasible queue length: 0
[state-dump] Schedule queue length: 0
[state-dump] Dispatch queue length: 64
[state-dump] num_waiting_for_resource: 0
[state-dump] num_waiting_for_plasma_memory: 0
[state-dump] num_waiting_for_remote_node_resources: 0
[state-dump] num_worker_not_started_by_job_config_not_exist: 0
[state-dump] num_worker_not_started_by_registration_timeout: 0
[state-dump] num_worker_not_started_by_process_rate_limit: 0
[state-dump] num_tasks_waiting_for_workers: 64
[state-dump] num_cancelled_tasks: 0
[state-dump] cluster_resource_scheduler state: 
[state-dump] Local id: -110938788179330527 Local resources: {object_store_memory: [1995776227120000]/[2000000000000000], node:10.140.1.109: [10000]/[10000], memory: [8693891676160000]/[8693891676160000], CPU: [1280000]/[1280000], accelerator_type:A100: [10000]/[10000], GPU: [10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000]/[10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000]}node id: -110938788179330527{object_store_memory: 1995776227120000/2000000000000000, node:10.140.1.109: 10000/10000, CPU: 1280000/1280000, GPU: 80000/80000, memory: 8693891676160000/8693891676160000, accelerator_type:A100: 10000/10000}
[state-dump] Waiting tasks size: 0
[state-dump] Number of executing tasks: 64
[state-dump] Number of pinned task arguments: 0
[state-dump] Number of total spilled tasks: 0
[state-dump] Number of spilled waiting tasks: 0
[state-dump] Number of spilled unschedulable tasks: 0
[state-dump] Resource usage {
[state-dump] }
[state-dump] Running tasks by scheduling class:
[state-dump]     - {depth=1 function_descriptor={type=PythonFunctionDescriptor, module_name=alpa.pipeline_parallel.stage_profiling, class_name=CompileWorker, function_name=__init__, function_hash=302a90773645490481304537a41d5618} scheduling_strategy=default_scheduling_strategy {
[state-dump] }
[state-dump]  resource_set={}}: 64/18446744073709551615
[state-dump] ==================================================
[state-dump] 
[state-dump] ClusterResources:
[state-dump] LocalObjectManager:
[state-dump] - num pinned objects: 64
[state-dump] - pinned objects size: 422377288
[state-dump] - num objects pending restore: 0
[state-dump] - num objects pending spill: 0
[state-dump] - num bytes pending spill: 0
[state-dump] - cumulative spill requests: 0
[state-dump] - cumulative restore requests: 0
[state-dump] 
[state-dump] ObjectManager:
[state-dump] - num local objects: 64
[state-dump] - num unfulfilled push requests: 0
[state-dump] - num pull requests: 0
[state-dump] - num chunks received total: 0
[state-dump] - num chunks received failed (all): 0
[state-dump] - num chunks received failed / cancelled: 0
[state-dump] - num chunks received failed / plasma error: 0
[state-dump] Event stats:
[state-dump] Global stats: 9 total (0 active)
[state-dump] Queueing time: mean = 22.924 us, max = 45.245 us, min = 15.950 us, total = 206.318 us
[state-dump] Execution time:  mean = 3.903 ms, total = 35.129 ms
[state-dump] Event stats:
[state-dump] 	ObjectManager.FreeObjects - 9 total (0 active), CPU time: mean = 3.903 ms, total = 35.129 ms
[state-dump] PushManager:
[state-dump] - num pushes in flight: 0
[state-dump] - num chunks in flight: 0
[state-dump] - num chunks remaining: 0
[state-dump] - max chunks allowed: 409
[state-dump] OwnershipBasedObjectDirectory:
[state-dump] - num listeners: 0
[state-dump] - cumulative location updates: 370
[state-dump] - num location updates per second: 0.000
[state-dump] - num location lookups per second: 0.000
[state-dump] - num locations added per second: 0.000
[state-dump] - num locations removed per second: 0.000
[state-dump] BufferPool:
[state-dump] - create buffer state map size: 0
[state-dump] PullManager:
[state-dump] - num bytes available for pulled objects: 199577622712
[state-dump] - num bytes being pulled (all): 0
[state-dump] - num bytes being pulled / pinned: 0
[state-dump] - num get request bundles: 0
[state-dump] - num wait request bundles: 0
[state-dump] - num task request bundles: 0
[state-dump] - first get request bundle: N/A
[state-dump] - first wait request bundle: N/A
[state-dump] - first task request bundle: N/A
[state-dump] - num objects queued: 0
[state-dump] - num objects actively pulled (all): 0
[state-dump] - num objects actively pulled / pinned: 0
[state-dump] - num bundles being pulled: 0
[state-dump] - num pull retries: 0
[state-dump] - max timeout seconds: 0
[state-dump] - max timeout request is already processed. No entry.
[state-dump] 
[state-dump] WorkerPool:
[state-dump] - registered jobs: 2
[state-dump] - process_failed_job_config_missing: 0
[state-dump] - process_failed_rate_limited: 0
[state-dump] - process_failed_pending_registration: 0
[state-dump] - process_failed_runtime_env_setup_failed: 0
[state-dump] - num JAVA workers: 0
[state-dump] - num JAVA drivers: 0
[state-dump] - num object spill callbacks queued: 0
[state-dump] - num object restore queued: 0
[state-dump] - num util functions queued: 0
[state-dump] - num PYTHON workers: 0
[state-dump] - num PYTHON drivers: 2
[state-dump] - num object spill callbacks queued: 0
[state-dump] - num object restore queued: 0
[state-dump] - num util functions queued: 0
[state-dump] - num idle workers: 0
[state-dump] TaskDependencyManager:
[state-dump] - task deps map size: 0
[state-dump] - get req map size: 0
[state-dump] - wait req map size: 0
[state-dump] - local objects map size: 64
[state-dump] WaitManager:
[state-dump] - num active wait requests: 0
[state-dump] Subscriber:
[state-dump] Channel WORKER_REF_REMOVED_CHANNEL
[state-dump] - cumulative subscribe requests: 0
[state-dump] - cumulative unsubscribe requests: 0
[state-dump] - active subscribed publishers: 0
[state-dump] - cumulative published messages: 0
[state-dump] - cumulative processed messages: 0
[state-dump] Channel WORKER_OBJECT_EVICTION
[state-dump] - cumulative subscribe requests: 79
[state-dump] - cumulative unsubscribe requests: 15
[state-dump] - active subscribed publishers: 1
[state-dump] - cumulative published messages: 15
[state-dump] - cumulative processed messages: 15
[state-dump] Channel WORKER_OBJECT_LOCATIONS_CHANNEL
[state-dump] - cumulative subscribe requests: 15
[state-dump] - cumulative unsubscribe requests: 15
[state-dump] - active subscribed publishers: 0
[state-dump] - cumulative published messages: 2
[state-dump] - cumulative processed messages: 2
[state-dump] num async plasma notifications: 0
[state-dump] Remote node managers: 
[state-dump] Event stats:
[state-dump] Global stats: 30330 total (11 active)
[state-dump] Queueing time: mean = 113.591 ms, max = 218.067 s, min = -0.067 s, total = 3445.211 s
[state-dump] Execution time:  mean = 3.905 ms, total = 118.446 s
[state-dump] Event stats:
[state-dump] 	ObjectManager.UpdateAvailableMemory - 5876 total (0 active), CPU time: mean = 811.286 us, total = 4.767 s
[state-dump] 	NodeManagerService.grpc_server.RequestResourceReport - 5211 total (0 active), CPU time: mean = 3.036 ms, total = 15.820 s
[state-dump] 	NodeManagerService.grpc_server.UpdateResourceUsage - 5197 total (0 active), CPU time: mean = 1.561 ms, total = 8.114 s
[state-dump] 	RayletWorkerPool.deadline_timer.kill_idle_workers - 2998 total (1 active), CPU time: mean = 3.080 ms, total = 9.233 s
[state-dump] 	NodeManagerService.grpc_server.GetGcsServerAddress - 2260 total (0 active), CPU time: mean = 1.160 ms, total = 2.622 s
[state-dump] 	NodeManagerService.grpc_server.ReportWorkerBacklog - 2231 total (0 active), CPU time: mean = 1.726 ms, total = 3.850 s
[state-dump] 	CoreWorkerService.grpc_client.GetCoreWorkerStats - 1797 total (0 active), CPU time: mean = 2.430 ms, total = 4.367 s
[state-dump] 	NodeManagerService.grpc_server.GetResourceLoad - 690 total (0 active), CPU time: mean = 5.414 ms, total = 3.735 s
[state-dump] 	HeartbeatInfoGcsService.grpc_client.ReportHeartbeat - 652 total (0 active), CPU time: mean = 3.453 ms, total = 2.251 s
[state-dump] 	GcsClient.deadline_timer.check_gcs_connection - 641 total (1 active), CPU time: mean = 2.984 ms, total = 1.913 s
[state-dump] 	UNKNOWN - 641 total (1 active), CPU time: mean = 10.773 ms, total = 6.905 s
[state-dump] 	NodeManager.deadline_timer.flush_free_objects - 640 total (1 active), CPU time: mean = 3.503 ms, total = 2.242 s
[state-dump] 	NodeManagerService.grpc_server.GetNodeStats - 506 total (0 active), CPU time: mean = 32.822 ms, total = 16.608 s
[state-dump] 	ClientConnection.async_read.ReadBufferAsync - 234 total (2 active), CPU time: mean = 16.469 ms, total = 3.854 s
[state-dump] 	NodeManager.deadline_timer.record_metrics - 137 total (1 active), CPU time: mean = 58.376 ms, total = 7.998 s
[state-dump] 	ObjectManager.ObjectAdded - 91 total (0 active), CPU time: mean = 18.608 ms, total = 1.693 s
[state-dump] 	NodeManagerService.grpc_server.PinObjectIDs - 79 total (0 active), CPU time: mean = 10.851 ms, total = 857.207 ms
[state-dump] 	NodeManagerService.grpc_server.RequestWorkerLease - 74 total (0 active), CPU time: mean = 8.458 ms, total = 625.856 ms
[state-dump] 	NodeManager.deadline_timer.debug_state_dump - 71 total (1 active), CPU time: mean = 234.310 ms, total = 16.636 s
[state-dump] 	CoreWorkerService.grpc_client.PubsubCommandBatch - 70 total (0 active), CPU time: mean = 5.127 ms, total = 358.859 ms
[state-dump] 	CoreWorkerService.grpc_client.UpdateObjectLocationBatch - 55 total (0 active), CPU time: mean = 2.084 ms, total = 114.636 ms
[state-dump] 	ObjectManager.ObjectDeleted - 27 total (0 active), CPU time: mean = 5.988 ms, total = 161.678 ms
[state-dump] 	CoreWorkerService.grpc_client.PubsubLongPolling - 25 total (1 active), CPU time: mean = 56.347 ms, total = 1.409 s
[state-dump] 	Subscriber.HandlePublishedMessage_WORKER_OBJECT_EVICTION - 15 total (0 active), CPU time: mean = 12.834 ms, total = 192.511 ms
[state-dump] 	ClientConnection.async_write.DoAsyncWrites - 12 total (0 active), CPU time: mean = 819.361 us, total = 9.832 ms
[state-dump] 	NodeManagerService.grpc_server.GetSystemConfig - 12 total (0 active), CPU time: mean = 2.580 ms, total = 30.960 ms
[state-dump] 	NodeManager.deadline_timer.print_event_loop_stats - 12 total (1 active, 1 running), CPU time: mean = 90.891 ms, total = 1.091 s
[state-dump] 	Subscriber.HandlePublishedMessage_GCS_WORKER_DELTA_CHANNEL - 10 total (0 active), CPU time: mean = 1.460 ms, total = 14.602 ms
[state-dump] 	WorkerInfoGcsService.grpc_client.ReportWorkerFailure - 10 total (0 active), CPU time: mean = 7.370 us, total = 73.704 us
[state-dump] 	CoreWorkerService.grpc_client.DirectActorCallArgWaitComplete - 10 total (0 active), CPU time: mean = 1.508 ms, total = 15.075 ms
[state-dump] 	InternalPubSubGcsService.grpc_client.GcsSubscriberPoll - 8 total (1 active), CPU time: mean = 37.221 ms, total = 297.767 ms
[state-dump] 	CoreWorkerService.grpc_client.LocalGC - 7 total (0 active), CPU time: mean = 3.693 ms, total = 25.848 ms
[state-dump] 	PeriodicalRunner.RunFnPeriodically - 7 total (0 active), CPU time: mean = 243.532 us, total = 1.705 ms
[state-dump] 	RuntimeEnvService.grpc_client.DeleteRuntimeEnvIfPossible - 5 total (0 active), CPU time: mean = 2.907 ms, total = 14.536 ms
[state-dump] 	RuntimeEnvService.grpc_client.GetOrCreateRuntimeEnv - 5 total (0 active), CPU time: mean = 8.817 ms, total = 44.085 ms
[state-dump] 	InternalPubSubGcsService.grpc_client.GcsSubscriberCommandBatch - 3 total (0 active), CPU time: mean = 68.436 us, total = 205.309 us
[state-dump] 	Subscriber.HandlePublishedMessage_WORKER_OBJECT_LOCATIONS_CHANNEL - 2 total (0 active), CPU time: mean = 32.551 ms, total = 65.101 ms
[state-dump] 	Subscriber.HandlePublishedMessage_GCS_JOB_CHANNEL - 2 total (0 active), CPU time: mean = 35.076 ms, total = 70.152 ms
[state-dump] 	JobInfoGcsService.grpc_client.AddJob - 2 total (0 active), CPU time: mean = 17.572 ms, total = 35.143 ms
[state-dump] 	AgentManagerService.grpc_server.RegisterAgent - 1 total (0 active), CPU time: mean = 367.585 ms, total = 367.585 ms
[state-dump] 	NodeInfoGcsService.grpc_client.GetInternalConfig - 1 total (0 active), CPU time: mean = 34.694 ms, total = 34.694 ms
[state-dump] 	NodeInfoGcsService.grpc_client.GetAllNodeInfo - 1 total (0 active), CPU time: mean = 85.179 us, total = 85.179 us
[state-dump] 	JobInfoGcsService.grpc_client.GetAllJobInfo - 1 total (0 active), CPU time: mean = 15.018 us, total = 15.018 us
[state-dump] 	NodeInfoGcsService.grpc_client.RegisterNode - 1 total (0 active), CPU time: mean = 486.057 us, total = 486.057 us
[state-dump] DebugString() time ms: 0
[state-dump] 
[state-dump] 
[2022-06-20 22:58:01,554 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(4611) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:58:01,702 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5005, the token 74
[2022-06-20 22:58:01,729 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(4612) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:58:01,731 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5006, the token 75
[2022-06-20 22:58:01,731 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(4613) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:58:01,733 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5007, the token 76
[2022-06-20 22:58:01,733 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(4614) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:58:01,735 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5008, the token 77
[2022-06-20 22:58:01,735 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(4615) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:58:01,737 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5009, the token 78
[2022-06-20 22:58:01,737 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(4616) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:58:01,738 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5010, the token 79
[2022-06-20 22:58:01,739 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(4617) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:58:01,741 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5011, the token 80
[2022-06-20 22:58:01,741 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(4618) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:58:01,742 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5012, the token 81
[2022-06-20 22:58:01,742 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(4619) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:58:01,744 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5013, the token 82
[2022-06-20 22:58:01,744 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(4620) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:58:01,746 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5014, the token 83
[2022-06-20 22:58:01,746 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(4621) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:58:01,748 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5015, the token 84
[2022-06-20 22:58:01,748 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(4622) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:58:01,750 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5016, the token 85
[2022-06-20 22:58:01,751 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(4623) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:58:01,752 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5017, the token 86
[2022-06-20 22:58:01,753 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(4624) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:58:01,755 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5018, the token 87
[2022-06-20 22:58:01,755 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(4625) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:58:01,757 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5019, the token 88
[2022-06-20 22:58:01,757 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(4626) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:58:01,759 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5020, the token 89
[2022-06-20 22:58:01,759 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(4627) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:58:01,761 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5021, the token 90
[2022-06-20 22:58:01,761 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(4628) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:58:01,763 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5022, the token 91
[2022-06-20 22:58:01,763 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(4629) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:58:01,765 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5023, the token 92
[2022-06-20 22:58:01,765 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(4630) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:58:01,767 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5024, the token 93
[2022-06-20 22:58:01,767 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(4631) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:58:01,769 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5025, the token 94
[2022-06-20 22:58:01,770 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(4640) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:58:01,772 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5026, the token 95
[2022-06-20 22:58:01,772 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(4641) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:58:01,774 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5027, the token 96
[2022-06-20 22:58:01,774 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(4642) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:58:01,777 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5028, the token 97
[2022-06-20 22:58:01,777 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(4643) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:58:01,779 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5029, the token 98
[2022-06-20 22:58:01,779 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(4645) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:58:01,780 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5030, the token 99
[2022-06-20 22:58:01,781 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(4647) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:58:01,782 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5031, the token 100
[2022-06-20 22:58:01,782 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(4648) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:58:01,784 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5032, the token 101
[2022-06-20 22:58:01,784 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(4651) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:58:01,786 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5033, the token 102
[2022-06-20 22:58:01,786 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(4652) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:58:01,788 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5034, the token 103
[2022-06-20 22:58:01,788 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(4653) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:58:01,791 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5035, the token 104
[2022-06-20 22:58:01,791 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(4654) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:58:01,793 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5036, the token 105
[2022-06-20 22:58:01,793 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(4655) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:58:01,795 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5037, the token 106
[2022-06-20 22:58:01,795 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(4656) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:58:01,798 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5038, the token 107
[2022-06-20 22:58:01,798 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(4657) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:58:01,800 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5039, the token 108
[2022-06-20 22:58:01,800 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(4658) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:58:01,807 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5040, the token 109
[2022-06-20 22:58:01,807 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(4659) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:58:01,815 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5041, the token 110
[2022-06-20 22:58:01,815 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(4660) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:58:01,820 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5042, the token 111
[2022-06-20 22:58:01,820 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(4661) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:58:01,825 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5043, the token 112
[2022-06-20 22:58:01,825 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(4662) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:58:01,830 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5046, the token 113
[2022-06-20 22:58:01,830 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(4663) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:58:01,835 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5047, the token 114
[2022-06-20 22:58:01,835 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(4664) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:58:01,838 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5048, the token 115
[2022-06-20 22:58:01,838 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(4665) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:58:01,840 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5049, the token 116
[2022-06-20 22:58:01,840 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(4666) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:58:01,842 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5050, the token 117
[2022-06-20 22:58:01,842 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(4669) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:58:01,844 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5051, the token 118
[2022-06-20 22:58:01,844 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(4670) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:58:01,845 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5052, the token 119
[2022-06-20 22:58:01,845 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(4671) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:58:01,847 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5053, the token 120
[2022-06-20 22:58:01,847 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(4672) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:58:01,848 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5054, the token 121
[2022-06-20 22:58:01,848 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(4673) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:58:01,849 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5055, the token 122
[2022-06-20 22:58:01,850 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(4674) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:58:01,851 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5056, the token 123
[2022-06-20 22:58:01,851 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(4675) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:58:01,852 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5057, the token 124
[2022-06-20 22:58:01,853 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(4677) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:58:01,854 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5058, the token 125
[2022-06-20 22:58:01,854 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(4678) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:58:01,856 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5059, the token 126
[2022-06-20 22:58:01,856 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(4680) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:58:01,858 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5060, the token 127
[2022-06-20 22:58:01,858 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(4681) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:58:01,860 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5061, the token 128
[2022-06-20 22:58:01,860 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(4682) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:58:01,862 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5062, the token 129
[2022-06-20 22:58:01,862 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(4683) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:58:01,864 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5063, the token 130
[2022-06-20 22:58:01,864 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(4684) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:58:01,866 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5064, the token 131
[2022-06-20 22:58:01,866 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(4685) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:58:01,869 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5065, the token 132
[2022-06-20 22:58:01,869 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(4686) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:58:01,871 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5066, the token 133
[2022-06-20 22:58:01,871 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(4687) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:58:01,872 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5067, the token 134
[2022-06-20 22:58:01,872 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(4688) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:58:01,875 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5068, the token 135
[2022-06-20 22:58:01,875 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(4689) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:58:01,877 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5070, the token 136
[2022-06-20 22:58:01,877 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(4690) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:58:01,879 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5071, the token 137
[2022-06-20 22:58:01,981 I 128931 128962] (raylet) store.cc:546: ========== Plasma store: =================
Current usage: 0.422377 / 200 GB
- num bytes created total: 513944626
0 pending objects of total size 0MB
- objects spillable: 64
- bytes spillable: 422377288
- objects unsealed: 0
- bytes unsealed: 0
- objects in use: 64
- bytes in use: 422377288
- objects evictable: 0
- bytes evictable: 0

- objects created by worker: 64
- bytes created by worker: 422377288
- objects restored: 0
- bytes restored: 0
- objects received: 0
- bytes received: 0
- objects errored: 0
- bytes errored: 0

[2022-06-20 22:58:03,757 I 128931 128931] (raylet) node_manager.cc:538: [state-dump] Event stats:
[state-dump] 
[state-dump] 
[state-dump] Global stats: 32787 total (11 active)
[state-dump] Queueing time: mean = 106.295 ms, max = 218.067 s, min = -0.067 s, total = 3485.083 s
[state-dump] Execution time:  mean = 3.784 ms, total = 124.058 s
[state-dump] Event stats:
[state-dump] 	ObjectManager.UpdateAvailableMemory - 6413 total (0 active), CPU time: mean = 776.558 us, total = 4.980 s
[state-dump] 	NodeManagerService.grpc_server.RequestResourceReport - 5698 total (0 active), CPU time: mean = 2.877 ms, total = 16.394 s
[state-dump] 	NodeManagerService.grpc_server.UpdateResourceUsage - 5681 total (0 active), CPU time: mean = 1.443 ms, total = 8.196 s
[state-dump] 	RayletWorkerPool.deadline_timer.kill_idle_workers - 3271 total (1 active), CPU time: mean = 2.987 ms, total = 9.770 s
[state-dump] 	NodeManagerService.grpc_server.GetGcsServerAddress - 2376 total (0 active), CPU time: mean = 1.190 ms, total = 2.828 s
[state-dump] 	NodeManagerService.grpc_server.ReportWorkerBacklog - 2347 total (0 active), CPU time: mean = 1.713 ms, total = 4.019 s
[state-dump] 	CoreWorkerService.grpc_client.GetCoreWorkerStats - 1891 total (0 active), CPU time: mean = 2.423 ms, total = 4.582 s
[state-dump] 	NodeManagerService.grpc_server.GetResourceLoad - 747 total (0 active), CPU time: mean = 5.393 ms, total = 4.029 s
[state-dump] 	HeartbeatInfoGcsService.grpc_client.ReportHeartbeat - 708 total (0 active), CPU time: mean = 3.274 ms, total = 2.318 s
[state-dump] 	GcsClient.deadline_timer.check_gcs_connection - 698 total (1 active), CPU time: mean = 2.906 ms, total = 2.028 s
[state-dump] 	UNKNOWN - 698 total (1 active), CPU time: mean = 10.624 ms, total = 7.416 s
[state-dump] 	NodeManager.deadline_timer.flush_free_objects - 697 total (1 active), CPU time: mean = 3.397 ms, total = 2.368 s
[state-dump] 	NodeManagerService.grpc_server.GetNodeStats - 553 total (0 active), CPU time: mean = 32.645 ms, total = 18.053 s
[state-dump] 	ClientConnection.async_read.ReadBufferAsync - 234 total (2 active), CPU time: mean = 16.469 ms, total = 3.854 s
[state-dump] 	NodeManager.deadline_timer.record_metrics - 149 total (1 active), CPU time: mean = 55.078 ms, total = 8.207 s
[state-dump] 	ObjectManager.ObjectAdded - 91 total (0 active), CPU time: mean = 18.608 ms, total = 1.693 s
[state-dump] 	NodeManagerService.grpc_server.PinObjectIDs - 79 total (0 active), CPU time: mean = 10.851 ms, total = 857.207 ms
[state-dump] 	NodeManager.deadline_timer.debug_state_dump - 77 total (1 active), CPU time: mean = 226.964 ms, total = 17.476 s
[state-dump] 	NodeManagerService.grpc_server.RequestWorkerLease - 74 total (0 active), CPU time: mean = 8.458 ms, total = 625.856 ms
[state-dump] 	CoreWorkerService.grpc_client.PubsubCommandBatch - 70 total (0 active), CPU time: mean = 5.127 ms, total = 358.859 ms
[state-dump] 	CoreWorkerService.grpc_client.UpdateObjectLocationBatch - 55 total (0 active), CPU time: mean = 2.084 ms, total = 114.636 ms
[state-dump] 	ObjectManager.ObjectDeleted - 27 total (0 active), CPU time: mean = 5.988 ms, total = 161.678 ms
[state-dump] 	CoreWorkerService.grpc_client.PubsubLongPolling - 25 total (1 active), CPU time: mean = 56.347 ms, total = 1.409 s
[state-dump] 	Subscriber.HandlePublishedMessage_WORKER_OBJECT_EVICTION - 15 total (0 active), CPU time: mean = 12.834 ms, total = 192.511 ms
[state-dump] 	NodeManager.deadline_timer.print_event_loop_stats - 13 total (1 active, 1 running), CPU time: mean = 84.694 ms, total = 1.101 s
[state-dump] 	ClientConnection.async_write.DoAsyncWrites - 12 total (0 active), CPU time: mean = 819.361 us, total = 9.832 ms
[state-dump] 	NodeManagerService.grpc_server.GetSystemConfig - 12 total (0 active), CPU time: mean = 2.580 ms, total = 30.960 ms
[state-dump] 	Subscriber.HandlePublishedMessage_GCS_WORKER_DELTA_CHANNEL - 10 total (0 active), CPU time: mean = 1.460 ms, total = 14.602 ms
[state-dump] 	WorkerInfoGcsService.grpc_client.ReportWorkerFailure - 10 total (0 active), CPU time: mean = 7.370 us, total = 73.704 us
[state-dump] 	CoreWorkerService.grpc_client.DirectActorCallArgWaitComplete - 10 total (0 active), CPU time: mean = 1.508 ms, total = 15.075 ms
[state-dump] 	InternalPubSubGcsService.grpc_client.GcsSubscriberPoll - 8 total (1 active), CPU time: mean = 37.221 ms, total = 297.767 ms
[state-dump] 	CoreWorkerService.grpc_client.LocalGC - 7 total (0 active), CPU time: mean = 3.693 ms, total = 25.848 ms
[state-dump] 	PeriodicalRunner.RunFnPeriodically - 7 total (0 active), CPU time: mean = 243.532 us, total = 1.705 ms
[state-dump] 	RuntimeEnvService.grpc_client.DeleteRuntimeEnvIfPossible - 5 total (0 active), CPU time: mean = 2.907 ms, total = 14.536 ms
[state-dump] 	RuntimeEnvService.grpc_client.GetOrCreateRuntimeEnv - 5 total (0 active), CPU time: mean = 8.817 ms, total = 44.085 ms
[state-dump] 	InternalPubSubGcsService.grpc_client.GcsSubscriberCommandBatch - 3 total (0 active), CPU time: mean = 68.436 us, total = 205.309 us
[state-dump] 	Subscriber.HandlePublishedMessage_WORKER_OBJECT_LOCATIONS_CHANNEL - 2 total (0 active), CPU time: mean = 32.551 ms, total = 65.101 ms
[state-dump] 	Subscriber.HandlePublishedMessage_GCS_JOB_CHANNEL - 2 total (0 active), CPU time: mean = 35.076 ms, total = 70.152 ms
[state-dump] 	JobInfoGcsService.grpc_client.AddJob - 2 total (0 active), CPU time: mean = 17.572 ms, total = 35.143 ms
[state-dump] 	AgentManagerService.grpc_server.RegisterAgent - 1 total (0 active), CPU time: mean = 367.585 ms, total = 367.585 ms
[state-dump] 	NodeInfoGcsService.grpc_client.GetInternalConfig - 1 total (0 active), CPU time: mean = 34.694 ms, total = 34.694 ms
[state-dump] 	NodeInfoGcsService.grpc_client.GetAllNodeInfo - 1 total (0 active), CPU time: mean = 85.179 us, total = 85.179 us
[state-dump] 	JobInfoGcsService.grpc_client.GetAllJobInfo - 1 total (0 active), CPU time: mean = 15.018 us, total = 15.018 us
[state-dump] 	NodeInfoGcsService.grpc_client.RegisterNode - 1 total (0 active), CPU time: mean = 486.057 us, total = 486.057 us
[state-dump] 
[state-dump] NodeManager:
[state-dump] Node ID: 7562cb0081c73f4ed2ac21d1956887bd794b724f1b8c157f4e02d603
[state-dump] Node name: 10.140.1.109
[state-dump] InitialConfigResources: {CPU: 1280000, node:10.140.1.109: 10000, GPU: 80000, object_store_memory: 2000000000000000, memory: 8693891676160000, accelerator_type:A100: 10000}
[state-dump] ClusterTaskManager:
[state-dump] ========== Node: 7562cb0081c73f4ed2ac21d1956887bd794b724f1b8c157f4e02d603 =================
[state-dump] Infeasible queue length: 0
[state-dump] Schedule queue length: 0
[state-dump] Dispatch queue length: 64
[state-dump] num_waiting_for_resource: 0
[state-dump] num_waiting_for_plasma_memory: 0
[state-dump] num_waiting_for_remote_node_resources: 0
[state-dump] num_worker_not_started_by_job_config_not_exist: 0
[state-dump] num_worker_not_started_by_registration_timeout: 0
[state-dump] num_worker_not_started_by_process_rate_limit: 0
[state-dump] num_tasks_waiting_for_workers: 64
[state-dump] num_cancelled_tasks: 0
[state-dump] cluster_resource_scheduler state: 
[state-dump] Local id: -110938788179330527 Local resources: {object_store_memory: [1995776227120000]/[2000000000000000], node:10.140.1.109: [10000]/[10000], memory: [8693891676160000]/[8693891676160000], CPU: [1280000]/[1280000], accelerator_type:A100: [10000]/[10000], GPU: [10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000]/[10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000]}node id: -110938788179330527{object_store_memory: 1995776227120000/2000000000000000, accelerator_type:A100: 10000/10000, node:10.140.1.109: 10000/10000, memory: 8693891676160000/8693891676160000, CPU: 1280000/1280000, GPU: 80000/80000}
[state-dump] Waiting tasks size: 0
[state-dump] Number of executing tasks: 64
[state-dump] Number of pinned task arguments: 0
[state-dump] Number of total spilled tasks: 0
[state-dump] Number of spilled waiting tasks: 0
[state-dump] Number of spilled unschedulable tasks: 0
[state-dump] Resource usage {
[state-dump] }
[state-dump] Running tasks by scheduling class:
[state-dump]     - {depth=1 function_descriptor={type=PythonFunctionDescriptor, module_name=alpa.pipeline_parallel.stage_profiling, class_name=CompileWorker, function_name=__init__, function_hash=302a90773645490481304537a41d5618} scheduling_strategy=default_scheduling_strategy {
[state-dump] }
[state-dump]  resource_set={}}: 64/18446744073709551615
[state-dump] ==================================================
[state-dump] 
[state-dump] ClusterResources:
[state-dump] LocalObjectManager:
[state-dump] - num pinned objects: 64
[state-dump] - pinned objects size: 422377288
[state-dump] - num objects pending restore: 0
[state-dump] - num objects pending spill: 0
[state-dump] - num bytes pending spill: 0
[state-dump] - cumulative spill requests: 0
[state-dump] - cumulative restore requests: 0
[state-dump] 
[state-dump] ObjectManager:
[state-dump] - num local objects: 64
[state-dump] - num unfulfilled push requests: 0
[state-dump] - num pull requests: 0
[state-dump] - num chunks received total: 0
[state-dump] - num chunks received failed (all): 0
[state-dump] - num chunks received failed / cancelled: 0
[state-dump] - num chunks received failed / plasma error: 0
[state-dump] Event stats:
[state-dump] Global stats: 9 total (0 active)
[state-dump] Queueing time: mean = 22.924 us, max = 45.245 us, min = 15.950 us, total = 206.318 us
[state-dump] Execution time:  mean = 3.903 ms, total = 35.129 ms
[state-dump] Event stats:
[state-dump] 	ObjectManager.FreeObjects - 9 total (0 active), CPU time: mean = 3.903 ms, total = 35.129 ms
[state-dump] PushManager:
[state-dump] - num pushes in flight: 0
[state-dump] - num chunks in flight: 0
[state-dump] - num chunks remaining: 0
[state-dump] - max chunks allowed: 409
[state-dump] OwnershipBasedObjectDirectory:
[state-dump] - num listeners: 0
[state-dump] - cumulative location updates: 370
[state-dump] - num location updates per second: 0.000
[state-dump] - num location lookups per second: 0.000
[state-dump] - num locations added per second: 0.000
[state-dump] - num locations removed per second: 0.000
[state-dump] BufferPool:
[state-dump] - create buffer state map size: 0
[state-dump] PullManager:
[state-dump] - num bytes available for pulled objects: 199577622712
[state-dump] - num bytes being pulled (all): 0
[state-dump] - num bytes being pulled / pinned: 0
[state-dump] - num get request bundles: 0
[state-dump] - num wait request bundles: 0
[state-dump] - num task request bundles: 0
[state-dump] - first get request bundle: N/A
[state-dump] - first wait request bundle: N/A
[state-dump] - first task request bundle: N/A
[state-dump] - num objects queued: 0
[state-dump] - num objects actively pulled (all): 0
[state-dump] - num objects actively pulled / pinned: 0
[state-dump] - num bundles being pulled: 0
[state-dump] - num pull retries: 0
[state-dump] - max timeout seconds: 0
[state-dump] - max timeout request is already processed. No entry.
[state-dump] 
[state-dump] WorkerPool:
[state-dump] - registered jobs: 2
[state-dump] - process_failed_job_config_missing: 0
[state-dump] - process_failed_rate_limited: 0
[state-dump] - process_failed_pending_registration: 64
[state-dump] - process_failed_runtime_env_setup_failed: 0
[state-dump] - num JAVA workers: 0
[state-dump] - num JAVA drivers: 0
[state-dump] - num object spill callbacks queued: 0
[state-dump] - num object restore queued: 0
[state-dump] - num util functions queued: 0
[state-dump] - num PYTHON workers: 0
[state-dump] - num PYTHON drivers: 2
[state-dump] - num object spill callbacks queued: 0
[state-dump] - num object restore queued: 0
[state-dump] - num util functions queued: 0
[state-dump] - num idle workers: 0
[state-dump] TaskDependencyManager:
[state-dump] - task deps map size: 0
[state-dump] - get req map size: 0
[state-dump] - wait req map size: 0
[state-dump] - local objects map size: 64
[state-dump] WaitManager:
[state-dump] - num active wait requests: 0
[state-dump] Subscriber:
[state-dump] Channel WORKER_REF_REMOVED_CHANNEL
[state-dump] - cumulative subscribe requests: 0
[state-dump] - cumulative unsubscribe requests: 0
[state-dump] - active subscribed publishers: 0
[state-dump] - cumulative published messages: 0
[state-dump] - cumulative processed messages: 0
[state-dump] Channel WORKER_OBJECT_EVICTION
[state-dump] - cumulative subscribe requests: 79
[state-dump] - cumulative unsubscribe requests: 15
[state-dump] - active subscribed publishers: 1
[state-dump] - cumulative published messages: 15
[state-dump] - cumulative processed messages: 15
[state-dump] Channel WORKER_OBJECT_LOCATIONS_CHANNEL
[state-dump] - cumulative subscribe requests: 15
[state-dump] - cumulative unsubscribe requests: 15
[state-dump] - active subscribed publishers: 0
[state-dump] - cumulative published messages: 2
[state-dump] - cumulative processed messages: 2
[state-dump] num async plasma notifications: 0
[state-dump] Remote node managers: 
[state-dump] Event stats:
[state-dump] Global stats: 32787 total (11 active)
[state-dump] Queueing time: mean = 106.295 ms, max = 218.067 s, min = -0.067 s, total = 3485.083 s
[state-dump] Execution time:  mean = 3.784 ms, total = 124.058 s
[state-dump] Event stats:
[state-dump] 	ObjectManager.UpdateAvailableMemory - 6413 total (0 active), CPU time: mean = 776.558 us, total = 4.980 s
[state-dump] 	NodeManagerService.grpc_server.RequestResourceReport - 5698 total (0 active), CPU time: mean = 2.877 ms, total = 16.394 s
[state-dump] 	NodeManagerService.grpc_server.UpdateResourceUsage - 5681 total (0 active), CPU time: mean = 1.443 ms, total = 8.196 s
[state-dump] 	RayletWorkerPool.deadline_timer.kill_idle_workers - 3271 total (1 active), CPU time: mean = 2.987 ms, total = 9.770 s
[state-dump] 	NodeManagerService.grpc_server.GetGcsServerAddress - 2376 total (0 active), CPU time: mean = 1.190 ms, total = 2.828 s
[state-dump] 	NodeManagerService.grpc_server.ReportWorkerBacklog - 2347 total (0 active), CPU time: mean = 1.713 ms, total = 4.019 s
[state-dump] 	CoreWorkerService.grpc_client.GetCoreWorkerStats - 1891 total (0 active), CPU time: mean = 2.423 ms, total = 4.582 s
[state-dump] 	NodeManagerService.grpc_server.GetResourceLoad - 747 total (0 active), CPU time: mean = 5.393 ms, total = 4.029 s
[state-dump] 	HeartbeatInfoGcsService.grpc_client.ReportHeartbeat - 708 total (0 active), CPU time: mean = 3.274 ms, total = 2.318 s
[state-dump] 	GcsClient.deadline_timer.check_gcs_connection - 698 total (1 active), CPU time: mean = 2.906 ms, total = 2.028 s
[state-dump] 	UNKNOWN - 698 total (1 active), CPU time: mean = 10.624 ms, total = 7.416 s
[state-dump] 	NodeManager.deadline_timer.flush_free_objects - 697 total (1 active), CPU time: mean = 3.397 ms, total = 2.368 s
[state-dump] 	NodeManagerService.grpc_server.GetNodeStats - 553 total (0 active), CPU time: mean = 32.645 ms, total = 18.053 s
[state-dump] 	ClientConnection.async_read.ReadBufferAsync - 234 total (2 active), CPU time: mean = 16.469 ms, total = 3.854 s
[state-dump] 	NodeManager.deadline_timer.record_metrics - 149 total (1 active), CPU time: mean = 55.078 ms, total = 8.207 s
[state-dump] 	ObjectManager.ObjectAdded - 91 total (0 active), CPU time: mean = 18.608 ms, total = 1.693 s
[state-dump] 	NodeManagerService.grpc_server.PinObjectIDs - 79 total (0 active), CPU time: mean = 10.851 ms, total = 857.207 ms
[state-dump] 	NodeManager.deadline_timer.debug_state_dump - 77 total (1 active), CPU time: mean = 226.964 ms, total = 17.476 s
[state-dump] 	NodeManagerService.grpc_server.RequestWorkerLease - 74 total (0 active), CPU time: mean = 8.458 ms, total = 625.856 ms
[state-dump] 	CoreWorkerService.grpc_client.PubsubCommandBatch - 70 total (0 active), CPU time: mean = 5.127 ms, total = 358.859 ms
[state-dump] 	CoreWorkerService.grpc_client.UpdateObjectLocationBatch - 55 total (0 active), CPU time: mean = 2.084 ms, total = 114.636 ms
[state-dump] 	ObjectManager.ObjectDeleted - 27 total (0 active), CPU time: mean = 5.988 ms, total = 161.678 ms
[state-dump] 	CoreWorkerService.grpc_client.PubsubLongPolling - 25 total (1 active), CPU time: mean = 56.347 ms, total = 1.409 s
[state-dump] 	Subscriber.HandlePublishedMessage_WORKER_OBJECT_EVICTION - 15 total (0 active), CPU time: mean = 12.834 ms, total = 192.511 ms
[state-dump] 	NodeManager.deadline_timer.print_event_loop_stats - 13 total (1 active, 1 running), CPU time: mean = 84.694 ms, total = 1.101 s
[state-dump] 	ClientConnection.async_write.DoAsyncWrites - 12 total (0 active), CPU time: mean = 819.361 us, total = 9.832 ms
[state-dump] 	NodeManagerService.grpc_server.GetSystemConfig - 12 total (0 active), CPU time: mean = 2.580 ms, total = 30.960 ms
[state-dump] 	Subscriber.HandlePublishedMessage_GCS_WORKER_DELTA_CHANNEL - 10 total (0 active), CPU time: mean = 1.460 ms, total = 14.602 ms
[state-dump] 	WorkerInfoGcsService.grpc_client.ReportWorkerFailure - 10 total (0 active), CPU time: mean = 7.370 us, total = 73.704 us
[state-dump] 	CoreWorkerService.grpc_client.DirectActorCallArgWaitComplete - 10 total (0 active), CPU time: mean = 1.508 ms, total = 15.075 ms
[state-dump] 	InternalPubSubGcsService.grpc_client.GcsSubscriberPoll - 8 total (1 active), CPU time: mean = 37.221 ms, total = 297.767 ms
[state-dump] 	CoreWorkerService.grpc_client.LocalGC - 7 total (0 active), CPU time: mean = 3.693 ms, total = 25.848 ms
[state-dump] 	PeriodicalRunner.RunFnPeriodically - 7 total (0 active), CPU time: mean = 243.532 us, total = 1.705 ms
[state-dump] 	RuntimeEnvService.grpc_client.DeleteRuntimeEnvIfPossible - 5 total (0 active), CPU time: mean = 2.907 ms, total = 14.536 ms
[state-dump] 	RuntimeEnvService.grpc_client.GetOrCreateRuntimeEnv - 5 total (0 active), CPU time: mean = 8.817 ms, total = 44.085 ms
[state-dump] 	InternalPubSubGcsService.grpc_client.GcsSubscriberCommandBatch - 3 total (0 active), CPU time: mean = 68.436 us, total = 205.309 us
[state-dump] 	Subscriber.HandlePublishedMessage_WORKER_OBJECT_LOCATIONS_CHANNEL - 2 total (0 active), CPU time: mean = 32.551 ms, total = 65.101 ms
[state-dump] 	Subscriber.HandlePublishedMessage_GCS_JOB_CHANNEL - 2 total (0 active), CPU time: mean = 35.076 ms, total = 70.152 ms
[state-dump] 	JobInfoGcsService.grpc_client.AddJob - 2 total (0 active), CPU time: mean = 17.572 ms, total = 35.143 ms
[state-dump] 	AgentManagerService.grpc_server.RegisterAgent - 1 total (0 active), CPU time: mean = 367.585 ms, total = 367.585 ms
[state-dump] 	NodeInfoGcsService.grpc_client.GetInternalConfig - 1 total (0 active), CPU time: mean = 34.694 ms, total = 34.694 ms
[state-dump] 	NodeInfoGcsService.grpc_client.GetAllNodeInfo - 1 total (0 active), CPU time: mean = 85.179 us, total = 85.179 us
[state-dump] 	JobInfoGcsService.grpc_client.GetAllJobInfo - 1 total (0 active), CPU time: mean = 15.018 us, total = 15.018 us
[state-dump] 	NodeInfoGcsService.grpc_client.RegisterNode - 1 total (0 active), CPU time: mean = 486.057 us, total = 486.057 us
[state-dump] DebugString() time ms: 0
[state-dump] 
[state-dump] 
[2022-06-20 22:59:01,747 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(5005) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:59:01,893 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5347, the token 138
[2022-06-20 22:59:01,919 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(5006) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:59:01,921 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5348, the token 139
[2022-06-20 22:59:01,921 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(5007) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:59:01,923 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5351, the token 140
[2022-06-20 22:59:01,923 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(5008) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:59:01,925 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5352, the token 141
[2022-06-20 22:59:01,925 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(5009) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:59:01,927 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5353, the token 142
[2022-06-20 22:59:01,927 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(5010) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:59:01,929 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5354, the token 143
[2022-06-20 22:59:01,929 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(5011) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:59:01,932 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5355, the token 144
[2022-06-20 22:59:01,932 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(5012) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:59:01,934 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5356, the token 145
[2022-06-20 22:59:01,934 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(5013) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:59:01,936 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5357, the token 146
[2022-06-20 22:59:01,936 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(5014) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:59:01,938 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5358, the token 147
[2022-06-20 22:59:01,938 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(5015) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:59:01,940 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5359, the token 148
[2022-06-20 22:59:01,940 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(5016) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:59:01,941 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5360, the token 149
[2022-06-20 22:59:01,942 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(5017) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:59:01,944 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5361, the token 150
[2022-06-20 22:59:01,944 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(5018) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:59:01,946 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5362, the token 151
[2022-06-20 22:59:01,946 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(5019) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:59:01,948 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5363, the token 152
[2022-06-20 22:59:01,949 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(5020) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:59:01,950 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5364, the token 153
[2022-06-20 22:59:01,950 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(5021) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:59:01,952 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5365, the token 154
[2022-06-20 22:59:01,953 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(5022) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:59:01,955 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5366, the token 155
[2022-06-20 22:59:01,955 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(5023) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:59:01,957 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5367, the token 156
[2022-06-20 22:59:01,957 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(5024) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:59:01,959 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5368, the token 157
[2022-06-20 22:59:01,959 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(5025) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:59:01,961 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5369, the token 158
[2022-06-20 22:59:01,961 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(5026) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:59:01,963 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5370, the token 159
[2022-06-20 22:59:01,963 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(5027) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:59:01,966 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5371, the token 160
[2022-06-20 22:59:01,966 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(5028) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:59:01,968 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5372, the token 161
[2022-06-20 22:59:01,968 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(5029) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:59:01,970 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5373, the token 162
[2022-06-20 22:59:01,970 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(5030) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:59:01,973 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5374, the token 163
[2022-06-20 22:59:01,973 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(5031) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:59:01,975 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5375, the token 164
[2022-06-20 22:59:01,975 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(5032) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:59:01,978 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5376, the token 165
[2022-06-20 22:59:01,978 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(5033) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:59:01,980 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5377, the token 166
[2022-06-20 22:59:01,981 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(5034) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:59:01,983 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5378, the token 167
[2022-06-20 22:59:01,983 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(5035) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:59:01,985 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5379, the token 168
[2022-06-20 22:59:01,985 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(5036) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:59:01,987 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5380, the token 169
[2022-06-20 22:59:01,987 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(5037) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:59:01,988 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5381, the token 170
[2022-06-20 22:59:01,988 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(5038) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:59:01,991 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5382, the token 171
[2022-06-20 22:59:01,991 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(5039) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:59:01,993 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5383, the token 172
[2022-06-20 22:59:01,993 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(5040) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:59:01,995 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5384, the token 173
[2022-06-20 22:59:01,995 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(5041) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:59:01,997 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5385, the token 174
[2022-06-20 22:59:01,998 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(5042) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:59:02,000 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5386, the token 175
[2022-06-20 22:59:02,000 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(5043) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:59:02,002 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5387, the token 176
[2022-06-20 22:59:02,002 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(5046) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:59:02,005 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5388, the token 177
[2022-06-20 22:59:02,006 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(5047) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:59:02,010 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5389, the token 178
[2022-06-20 22:59:02,010 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(5048) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:59:02,015 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5390, the token 179
[2022-06-20 22:59:02,015 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(5049) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:59:02,020 I 128931 128962] (raylet) store.cc:546: ========== Plasma store: =================
Current usage: 0.422377 / 200 GB
- num bytes created total: 513944626
0 pending objects of total size 0MB
- objects spillable: 64
- bytes spillable: 422377288
- objects unsealed: 0
- bytes unsealed: 0
- objects in use: 64
- bytes in use: 422377288
- objects evictable: 0
- bytes evictable: 0

- objects created by worker: 64
- bytes created by worker: 422377288
- objects restored: 0
- bytes restored: 0
- objects received: 0
- bytes received: 0
- objects errored: 0
- bytes errored: 0

[2022-06-20 22:59:02,020 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5391, the token 180
[2022-06-20 22:59:02,020 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(5050) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:59:02,026 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5394, the token 181
[2022-06-20 22:59:02,026 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(5051) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:59:02,031 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5395, the token 182
[2022-06-20 22:59:02,031 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(5052) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:59:02,033 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5396, the token 183
[2022-06-20 22:59:02,033 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(5053) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:59:02,035 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5397, the token 184
[2022-06-20 22:59:02,036 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(5054) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:59:02,038 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5398, the token 185
[2022-06-20 22:59:02,038 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(5055) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:59:02,041 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5399, the token 186
[2022-06-20 22:59:02,041 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(5056) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:59:02,043 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5400, the token 187
[2022-06-20 22:59:02,043 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(5057) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:59:02,046 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5401, the token 188
[2022-06-20 22:59:02,046 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(5058) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:59:02,048 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5402, the token 189
[2022-06-20 22:59:02,048 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(5059) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:59:02,050 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5403, the token 190
[2022-06-20 22:59:02,050 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(5060) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:59:02,060 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5404, the token 191
[2022-06-20 22:59:02,060 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(5061) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:59:02,075 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5405, the token 192
[2022-06-20 22:59:02,075 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(5062) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:59:02,080 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5406, the token 193
[2022-06-20 22:59:02,080 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(5063) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:59:02,086 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5407, the token 194
[2022-06-20 22:59:02,086 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(5064) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:59:02,090 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5408, the token 195
[2022-06-20 22:59:02,090 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(5065) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:59:02,096 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5414, the token 196
[2022-06-20 22:59:02,096 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(5066) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:59:02,101 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5415, the token 197
[2022-06-20 22:59:02,101 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(5067) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:59:02,103 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5416, the token 198
[2022-06-20 22:59:02,103 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(5068) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:59:02,105 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5417, the token 199
[2022-06-20 22:59:02,105 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(5070) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:59:02,107 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5418, the token 200
[2022-06-20 22:59:02,107 E 128931 128931] (raylet) worker_pool.cc:502: Some workers of the worker process(5071) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2022-06-20 22:59:02,110 I 128931 128931] (raylet) worker_pool.cc:470: Started worker process of 1 worker(s) with pid 5419, the token 201
[2022-06-20 22:59:03,758 I 128931 128931] (raylet) node_manager.cc:538: [state-dump] Event stats:
[state-dump] 
[state-dump] 
[state-dump] Global stats: 35120 total (11 active)
[state-dump] Queueing time: mean = 101.303 ms, max = 218.067 s, min = -0.067 s, total = 3557.750 s
[state-dump] Execution time:  mean = 3.761 ms, total = 132.073 s
[state-dump] Event stats:
[state-dump] 	ObjectManager.UpdateAvailableMemory - 6922 total (0 active), CPU time: mean = 758.174 us, total = 5.248 s
[state-dump] 	NodeManagerService.grpc_server.RequestResourceReport - 6145 total (0 active), CPU time: mean = 2.830 ms, total = 17.393 s
[state-dump] 	NodeManagerService.grpc_server.UpdateResourceUsage - 6128 total (0 active), CPU time: mean = 1.352 ms, total = 8.288 s
[state-dump] 	RayletWorkerPool.deadline_timer.kill_idle_workers - 3532 total (1 active), CPU time: mean = 2.936 ms, total = 10.370 s
[state-dump] 	NodeManagerService.grpc_server.GetGcsServerAddress - 2494 total (0 active), CPU time: mean = 1.183 ms, total = 2.951 s
[state-dump] 	NodeManagerService.grpc_server.ReportWorkerBacklog - 2465 total (0 active), CPU time: mean = 2.001 ms, total = 4.933 s
[state-dump] 	CoreWorkerService.grpc_client.GetCoreWorkerStats - 1983 total (0 active), CPU time: mean = 2.557 ms, total = 5.070 s
[state-dump] 	NodeManagerService.grpc_server.GetResourceLoad - 803 total (0 active), CPU time: mean = 5.569 ms, total = 4.472 s
[state-dump] 	HeartbeatInfoGcsService.grpc_client.ReportHeartbeat - 764 total (0 active), CPU time: mean = 3.140 ms, total = 2.399 s
[state-dump] 	GcsClient.deadline_timer.check_gcs_connection - 753 total (1 active), CPU time: mean = 2.889 ms, total = 2.176 s
[state-dump] 	NodeManager.deadline_timer.flush_free_objects - 752 total (1 active), CPU time: mean = 3.324 ms, total = 2.500 s
[state-dump] 	UNKNOWN - 752 total (1 active), CPU time: mean = 10.576 ms, total = 7.953 s
[state-dump] 	NodeManagerService.grpc_server.GetNodeStats - 599 total (0 active), CPU time: mean = 32.855 ms, total = 19.680 s
[state-dump] 	ClientConnection.async_read.ReadBufferAsync - 234 total (2 active), CPU time: mean = 16.469 ms, total = 3.854 s
[state-dump] 	NodeManager.deadline_timer.record_metrics - 161 total (1 active), CPU time: mean = 54.290 ms, total = 8.741 s
[state-dump] 	ObjectManager.ObjectAdded - 91 total (0 active), CPU time: mean = 18.608 ms, total = 1.693 s
[state-dump] 	NodeManager.deadline_timer.debug_state_dump - 83 total (1 active), CPU time: mean = 222.929 ms, total = 18.503 s
[state-dump] 	NodeManagerService.grpc_server.PinObjectIDs - 79 total (0 active), CPU time: mean = 10.851 ms, total = 857.207 ms
[state-dump] 	NodeManagerService.grpc_server.RequestWorkerLease - 74 total (0 active), CPU time: mean = 8.458 ms, total = 625.856 ms
[state-dump] 	CoreWorkerService.grpc_client.PubsubCommandBatch - 70 total (0 active), CPU time: mean = 5.127 ms, total = 358.859 ms
[state-dump] 	CoreWorkerService.grpc_client.UpdateObjectLocationBatch - 55 total (0 active), CPU time: mean = 2.084 ms, total = 114.636 ms
[state-dump] 	ObjectManager.ObjectDeleted - 27 total (0 active), CPU time: mean = 5.988 ms, total = 161.678 ms
[state-dump] 	CoreWorkerService.grpc_client.PubsubLongPolling - 25 total (1 active), CPU time: mean = 56.347 ms, total = 1.409 s
[state-dump] 	Subscriber.HandlePublishedMessage_WORKER_OBJECT_EVICTION - 15 total (0 active), CPU time: mean = 12.834 ms, total = 192.511 ms
[state-dump] 	NodeManager.deadline_timer.print_event_loop_stats - 14 total (1 active, 1 running), CPU time: mean = 78.716 ms, total = 1.102 s
[state-dump] 	ClientConnection.async_write.DoAsyncWrites - 12 total (0 active), CPU time: mean = 819.361 us, total = 9.832 ms
[state-dump] 	NodeManagerService.grpc_server.GetSystemConfig - 12 total (0 active), CPU time: mean = 2.580 ms, total = 30.960 ms
[state-dump] 	Subscriber.HandlePublishedMessage_GCS_WORKER_DELTA_CHANNEL - 10 total (0 active), CPU time: mean = 1.460 ms, total = 14.602 ms
[state-dump] 	WorkerInfoGcsService.grpc_client.ReportWorkerFailure - 10 total (0 active), CPU time: mean = 7.370 us, total = 73.704 us
[state-dump] 	CoreWorkerService.grpc_client.DirectActorCallArgWaitComplete - 10 total (0 active), CPU time: mean = 1.508 ms, total = 15.075 ms
[state-dump] 	InternalPubSubGcsService.grpc_client.GcsSubscriberPoll - 8 total (1 active), CPU time: mean = 37.221 ms, total = 297.767 ms
[state-dump] 	PeriodicalRunner.RunFnPeriodically - 7 total (0 active), CPU time: mean = 243.532 us, total = 1.705 ms
[state-dump] 	CoreWorkerService.grpc_client.LocalGC - 7 total (0 active), CPU time: mean = 3.693 ms, total = 25.848 ms
[state-dump] 	RuntimeEnvService.grpc_client.DeleteRuntimeEnvIfPossible - 5 total (0 active), CPU time: mean = 2.907 ms, total = 14.536 ms
[state-dump] 	RuntimeEnvService.grpc_client.GetOrCreateRuntimeEnv - 5 total (0 active), CPU time: mean = 8.817 ms, total = 44.085 ms
[state-dump] 	InternalPubSubGcsService.grpc_client.GcsSubscriberCommandBatch - 3 total (0 active), CPU time: mean = 68.436 us, total = 205.309 us
[state-dump] 	Subscriber.HandlePublishedMessage_WORKER_OBJECT_LOCATIONS_CHANNEL - 2 total (0 active), CPU time: mean = 32.551 ms, total = 65.101 ms
[state-dump] 	Subscriber.HandlePublishedMessage_GCS_JOB_CHANNEL - 2 total (0 active), CPU time: mean = 35.076 ms, total = 70.152 ms
[state-dump] 	JobInfoGcsService.grpc_client.AddJob - 2 total (0 active), CPU time: mean = 17.572 ms, total = 35.143 ms
[state-dump] 	AgentManagerService.grpc_server.RegisterAgent - 1 total (0 active), CPU time: mean = 367.585 ms, total = 367.585 ms
[state-dump] 	NodeInfoGcsService.grpc_client.GetInternalConfig - 1 total (0 active), CPU time: mean = 34.694 ms, total = 34.694 ms
[state-dump] 	NodeInfoGcsService.grpc_client.GetAllNodeInfo - 1 total (0 active), CPU time: mean = 85.179 us, total = 85.179 us
[state-dump] 	JobInfoGcsService.grpc_client.GetAllJobInfo - 1 total (0 active), CPU time: mean = 15.018 us, total = 15.018 us
[state-dump] 	NodeInfoGcsService.grpc_client.RegisterNode - 1 total (0 active), CPU time: mean = 486.057 us, total = 486.057 us
[state-dump] 
[state-dump] NodeManager:
[state-dump] Node ID: 7562cb0081c73f4ed2ac21d1956887bd794b724f1b8c157f4e02d603
[state-dump] Node name: 10.140.1.109
[state-dump] InitialConfigResources: {CPU: 1280000, node:10.140.1.109: 10000, GPU: 80000, object_store_memory: 2000000000000000, memory: 8693891676160000, accelerator_type:A100: 10000}
[state-dump] ClusterTaskManager:
[state-dump] ========== Node: 7562cb0081c73f4ed2ac21d1956887bd794b724f1b8c157f4e02d603 =================
[state-dump] Infeasible queue length: 0
[state-dump] Schedule queue length: 0
[state-dump] Dispatch queue length: 64
[state-dump] num_waiting_for_resource: 0
[state-dump] num_waiting_for_plasma_memory: 0
[state-dump] num_waiting_for_remote_node_resources: 0
[state-dump] num_worker_not_started_by_job_config_not_exist: 0
[state-dump] num_worker_not_started_by_registration_timeout: 0
[state-dump] num_worker_not_started_by_process_rate_limit: 0
[state-dump] num_tasks_waiting_for_workers: 64
[state-dump] num_cancelled_tasks: 0
[state-dump] cluster_resource_scheduler state: 
[state-dump] Local id: -110938788179330527 Local resources: {object_store_memory: [1995776227120000]/[2000000000000000], node:10.140.1.109: [10000]/[10000], memory: [8693891676160000]/[8693891676160000], CPU: [1280000]/[1280000], accelerator_type:A100: [10000]/[10000], GPU: [10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000]/[10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000]}node id: -110938788179330527{memory: 8693891676160000/8693891676160000, GPU: 80000/80000, object_store_memory: 1995776227120000/2000000000000000, accelerator_type:A100: 10000/10000, node:10.140.1.109: 10000/10000, CPU: 1280000/1280000}
[state-dump] Waiting tasks size: 0
[state-dump] Number of executing tasks: 64
[state-dump] Number of pinned task arguments: 0
[state-dump] Number of total spilled tasks: 0
[state-dump] Number of spilled waiting tasks: 0
[state-dump] Number of spilled unschedulable tasks: 0
[state-dump] Resource usage {
[state-dump] }
[state-dump] Running tasks by scheduling class:
[state-dump]     - {depth=1 function_descriptor={type=PythonFunctionDescriptor, module_name=alpa.pipeline_parallel.stage_profiling, class_name=CompileWorker, function_name=__init__, function_hash=302a90773645490481304537a41d5618} scheduling_strategy=default_scheduling_strategy {
[state-dump] }
[state-dump]  resource_set={}}: 64/18446744073709551615
[state-dump] ==================================================
[state-dump] 
[state-dump] ClusterResources:
[state-dump] LocalObjectManager:
[state-dump] - num pinned objects: 64
[state-dump] - pinned objects size: 422377288
[state-dump] - num objects pending restore: 0
[state-dump] - num objects pending spill: 0
[state-dump] - num bytes pending spill: 0
[state-dump] - cumulative spill requests: 0
[state-dump] - cumulative restore requests: 0
[state-dump] 
[state-dump] ObjectManager:
[state-dump] - num local objects: 64
[state-dump] - num unfulfilled push requests: 0
[state-dump] - num pull requests: 0
[state-dump] - num chunks received total: 0
[state-dump] - num chunks received failed (all): 0
[state-dump] - num chunks received failed / cancelled: 0
[state-dump] - num chunks received failed / plasma error: 0
[state-dump] Event stats:
[state-dump] Global stats: 9 total (0 active)
[state-dump] Queueing time: mean = 22.924 us, max = 45.245 us, min = 15.950 us, total = 206.318 us
[state-dump] Execution time:  mean = 3.903 ms, total = 35.129 ms
[state-dump] Event stats:
[state-dump] 	ObjectManager.FreeObjects - 9 total (0 active), CPU time: mean = 3.903 ms, total = 35.129 ms
[state-dump] PushManager:
[state-dump] - num pushes in flight: 0
[state-dump] - num chunks in flight: 0
[state-dump] - num chunks remaining: 0
[state-dump] - max chunks allowed: 409
[state-dump] OwnershipBasedObjectDirectory:
[state-dump] - num listeners: 0
[state-dump] - cumulative location updates: 370
[state-dump] - num location updates per second: 0.000
[state-dump] - num location lookups per second: 0.000
[state-dump] - num locations added per second: 0.000
[state-dump] - num locations removed per second: 0.000
[state-dump] BufferPool:
[state-dump] - create buffer state map size: 0
[state-dump] PullManager:
[state-dump] - num bytes available for pulled objects: 199577622712
[state-dump] - num bytes being pulled (all): 0
[state-dump] - num bytes being pulled / pinned: 0
[state-dump] - num get request bundles: 0
[state-dump] - num wait request bundles: 0
[state-dump] - num task request bundles: 0
[state-dump] - first get request bundle: N/A
[state-dump] - first wait request bundle: N/A
[state-dump] - first task request bundle: N/A
[state-dump] - num objects queued: 0
[state-dump] - num objects actively pulled (all): 0
[state-dump] - num objects actively pulled / pinned: 0
[state-dump] - num bundles being pulled: 0
[state-dump] - num pull retries: 0
[state-dump] - max timeout seconds: 0
[state-dump] - max timeout request is already processed. No entry.
[state-dump] 
[state-dump] WorkerPool:
[state-dump] - registered jobs: 2
[state-dump] - process_failed_job_config_missing: 0
[state-dump] - process_failed_rate_limited: 0
[state-dump] - process_failed_pending_registration: 128
[state-dump] - process_failed_runtime_env_setup_failed: 0
[state-dump] - num JAVA workers: 0
[state-dump] - num JAVA drivers: 0
[state-dump] - num object spill callbacks queued: 0
[state-dump] - num object restore queued: 0
[state-dump] - num util functions queued: 0
[state-dump] - num PYTHON workers: 0
[state-dump] - num PYTHON drivers: 2
[state-dump] - num object spill callbacks queued: 0
[state-dump] - num object restore queued: 0
[state-dump] - num util functions queued: 0
[state-dump] - num idle workers: 0
[state-dump] TaskDependencyManager:
[state-dump] - task deps map size: 0
[state-dump] - get req map size: 0
[state-dump] - wait req map size: 0
[state-dump] - local objects map size: 64
[state-dump] WaitManager:
[state-dump] - num active wait requests: 0
[state-dump] Subscriber:
[state-dump] Channel WORKER_REF_REMOVED_CHANNEL
[state-dump] - cumulative subscribe requests: 0
[state-dump] - cumulative unsubscribe requests: 0
[state-dump] - active subscribed publishers: 0
[state-dump] - cumulative published messages: 0
[state-dump] - cumulative processed messages: 0
[state-dump] Channel WORKER_OBJECT_EVICTION
[state-dump] - cumulative subscribe requests: 79
[state-dump] - cumulative unsubscribe requests: 15
[state-dump] - active subscribed publishers: 1
[state-dump] - cumulative published messages: 15
[state-dump] - cumulative processed messages: 15
[state-dump] Channel WORKER_OBJECT_LOCATIONS_CHANNEL
[state-dump] - cumulative subscribe requests: 15
[state-dump] - cumulative unsubscribe requests: 15
[state-dump] - active subscribed publishers: 0
[state-dump] - cumulative published messages: 2
[state-dump] - cumulative processed messages: 2
[state-dump] num async plasma notifications: 0
[state-dump] Remote node managers: 
[state-dump] Event stats:
[state-dump] Global stats: 35120 total (11 active)
[state-dump] Queueing time: mean = 101.303 ms, max = 218.067 s, min = -0.067 s, total = 3557.750 s
[state-dump] Execution time:  mean = 3.761 ms, total = 132.073 s
[state-dump] Event stats:
[state-dump] 	ObjectManager.UpdateAvailableMemory - 6922 total (0 active), CPU time: mean = 758.174 us, total = 5.248 s
[state-dump] 	NodeManagerService.grpc_server.RequestResourceReport - 6145 total (0 active), CPU time: mean = 2.830 ms, total = 17.393 s
[state-dump] 	NodeManagerService.grpc_server.UpdateResourceUsage - 6128 total (0 active), CPU time: mean = 1.352 ms, total = 8.288 s
[state-dump] 	RayletWorkerPool.deadline_timer.kill_idle_workers - 3532 total (1 active), CPU time: mean = 2.936 ms, total = 10.370 s
[state-dump] 	NodeManagerService.grpc_server.GetGcsServerAddress - 2494 total (0 active), CPU time: mean = 1.183 ms, total = 2.951 s
[state-dump] 	NodeManagerService.grpc_server.ReportWorkerBacklog - 2465 total (0 active), CPU time: mean = 2.001 ms, total = 4.933 s
[state-dump] 	CoreWorkerService.grpc_client.GetCoreWorkerStats - 1983 total (0 active), CPU time: mean = 2.557 ms, total = 5.070 s
[state-dump] 	NodeManagerService.grpc_server.GetResourceLoad - 803 total (0 active), CPU time: mean = 5.569 ms, total = 4.472 s
[state-dump] 	HeartbeatInfoGcsService.grpc_client.ReportHeartbeat - 764 total (0 active), CPU time: mean = 3.140 ms, total = 2.399 s
[state-dump] 	GcsClient.deadline_timer.check_gcs_connection - 753 total (1 active), CPU time: mean = 2.889 ms, total = 2.176 s
[state-dump] 	NodeManager.deadline_timer.flush_free_objects - 752 total (1 active), CPU time: mean = 3.324 ms, total = 2.500 s
[state-dump] 	UNKNOWN - 752 total (1 active), CPU time: mean = 10.576 ms, total = 7.953 s
[state-dump] 	NodeManagerService.grpc_server.GetNodeStats - 599 total (0 active), CPU time: mean = 32.855 ms, total = 19.680 s
[state-dump] 	ClientConnection.async_read.ReadBufferAsync - 234 total (2 active), CPU time: mean = 16.469 ms, total = 3.854 s
[state-dump] 	NodeManager.deadline_timer.record_metrics - 161 total (1 active), CPU time: mean = 54.290 ms, total = 8.741 s
[state-dump] 	ObjectManager.ObjectAdded - 91 total (0 active), CPU time: mean = 18.608 ms, total = 1.693 s
[state-dump] 	NodeManager.deadline_timer.debug_state_dump - 83 total (1 active), CPU time: mean = 222.929 ms, total = 18.503 s
[state-dump] 	NodeManagerService.grpc_server.PinObjectIDs - 79 total (0 active), CPU time: mean = 10.851 ms, total = 857.207 ms
[state-dump] 	NodeManagerService.grpc_server.RequestWorkerLease - 74 total (0 active), CPU time: mean = 8.458 ms, total = 625.856 ms
[state-dump] 	CoreWorkerService.grpc_client.PubsubCommandBatch - 70 total (0 active), CPU time: mean = 5.127 ms, total = 358.859 ms
[state-dump] 	CoreWorkerService.grpc_client.UpdateObjectLocationBatch - 55 total (0 active), CPU time: mean = 2.084 ms, total = 114.636 ms
[state-dump] 	ObjectManager.ObjectDeleted - 27 total (0 active), CPU time: mean = 5.988 ms, total = 161.678 ms
[state-dump] 	CoreWorkerService.grpc_client.PubsubLongPolling - 25 total (1 active), CPU time: mean = 56.347 ms, total = 1.409 s
[state-dump] 	Subscriber.HandlePublishedMessage_WORKER_OBJECT_EVICTION - 15 total (0 active), CPU time: mean = 12.834 ms, total = 192.511 ms
[state-dump] 	NodeManager.deadline_timer.print_event_loop_stats - 14 total (1 active, 1 running), CPU time: mean = 78.716 ms, total = 1.102 s
[state-dump] 	ClientConnection.async_write.DoAsyncWrites - 12 total (0 active), CPU time: mean = 819.361 us, total = 9.832 ms
[state-dump] 	NodeManagerService.grpc_server.GetSystemConfig - 12 total (0 active), CPU time: mean = 2.580 ms, total = 30.960 ms
[state-dump] 	Subscriber.HandlePublishedMessage_GCS_WORKER_DELTA_CHANNEL - 10 total (0 active), CPU time: mean = 1.460 ms, total = 14.602 ms
[state-dump] 	WorkerInfoGcsService.grpc_client.ReportWorkerFailure - 10 total (0 active), CPU time: mean = 7.370 us, total = 73.704 us
[state-dump] 	CoreWorkerService.grpc_client.DirectActorCallArgWaitComplete - 10 total (0 active), CPU time: mean = 1.508 ms, total = 15.075 ms
[state-dump] 	InternalPubSubGcsService.grpc_client.GcsSubscriberPoll - 8 total (1 active), CPU time: mean = 37.221 ms, total = 297.767 ms
[state-dump] 	PeriodicalRunner.RunFnPeriodically - 7 total (0 active), CPU time: mean = 243.532 us, total = 1.705 ms
[state-dump] 	CoreWorkerService.grpc_client.LocalGC - 7 total (0 active), CPU time: mean = 3.693 ms, total = 25.848 ms
[state-dump] 	RuntimeEnvService.grpc_client.DeleteRuntimeEnvIfPossible - 5 total (0 active), CPU time: mean = 2.907 ms, total = 14.536 ms
[state-dump] 	RuntimeEnvService.grpc_client.GetOrCreateRuntimeEnv - 5 total (0 active), CPU time: mean = 8.817 ms, total = 44.085 ms
[state-dump] 	InternalPubSubGcsService.grpc_client.GcsSubscriberCommandBatch - 3 total (0 active), CPU time: mean = 68.436 us, total = 205.309 us
[state-dump] 	Subscriber.HandlePublishedMessage_WORKER_OBJECT_LOCATIONS_CHANNEL - 2 total (0 active), CPU time: mean = 32.551 ms, total = 65.101 ms
[state-dump] 	Subscriber.HandlePublishedMessage_GCS_JOB_CHANNEL - 2 total (0 active), CPU time: mean = 35.076 ms, total = 70.152 ms
[state-dump] 	JobInfoGcsService.grpc_client.AddJob - 2 total (0 active), CPU time: mean = 17.572 ms, total = 35.143 ms
[state-dump] 	AgentManagerService.grpc_server.RegisterAgent - 1 total (0 active), CPU time: mean = 367.585 ms, total = 367.585 ms
[state-dump] 	NodeInfoGcsService.grpc_client.GetInternalConfig - 1 total (0 active), CPU time: mean = 34.694 ms, total = 34.694 ms
[state-dump] 	NodeInfoGcsService.grpc_client.GetAllNodeInfo - 1 total (0 active), CPU time: mean = 85.179 us, total = 85.179 us
[state-dump] 	JobInfoGcsService.grpc_client.GetAllJobInfo - 1 total (0 active), CPU time: mean = 15.018 us, total = 15.018 us
[state-dump] 	NodeInfoGcsService.grpc_client.RegisterNode - 1 total (0 active), CPU time: mean = 486.057 us, total = 486.057 us
[state-dump] DebugString() time ms: 1
[state-dump] 
[state-dump] 
